---
title: Punto ed eseguire il commit con le mani
description: Panoramica del modello di input punto ed eseguire il commit
author: caseymeekhof
ms.author: cmeekhof
ms.date: 04/05/2019
ms.topic: article
ms.localizationpriority: high
keywords: Mista realtà, l'interazione, progettazione, hololens, indicatori, a questo momento, scegliere ed eseguire il commit
ms.openlocfilehash: 30f85d2bb455abab3a533e0a829b4fba8cea0a7a
ms.sourcegitcommit: 5b4292ef786447549c0199003e041ca48bb454cd
ms.translationtype: MT
ms.contentlocale: it-IT
ms.lasthandoff: 05/30/2019
ms.locfileid: "66402376"
---
# <a name="point-and-commit-with-hands"></a><span data-ttu-id="d6592-104">Punto ed eseguire il commit con le mani</span><span class="sxs-lookup"><span data-stu-id="d6592-104">Point and commit with hands</span></span>
<span data-ttu-id="d6592-105">Punto ed eseguire il commit con le mani è un modello di input che consente agli utenti di destinazione, selezionare e manipolare oggetti 3D e contenuti 2D della distanza.</span><span class="sxs-lookup"><span data-stu-id="d6592-105">Point and commit with hands is an input model that enables users to target, select and manipulate 2D content and 3D objects in the distance.</span></span> <span data-ttu-id="d6592-106">Questa tecnica di interazione "molto" è univoca per realtà mista e non gli esseri umani un modo naturale intereact con tutto il mondo reale.</span><span class="sxs-lookup"><span data-stu-id="d6592-106">This "far" interaction technique is unique to mixed reality and is not a way humans naturally intereact with the real world.</span></span> <span data-ttu-id="d6592-107">Ad esempio, in questo film eroe *X-uomini*, il carattere [Magneto](https://en.wikipedia.org/wiki/Magneto_(comics)) è in grado di raggiungere e la modifica di un oggetto decisamente la distanza con il suo mani.</span><span class="sxs-lookup"><span data-stu-id="d6592-107">For example, in the super hero movie *X-Men*, the character [Magneto](https://en.wikipedia.org/wiki/Magneto_(comics)) is capable of reaching out and manipulating a far object in the distance with his hands.</span></span> <span data-ttu-id="d6592-108">Ciò non gli esseri umani eseguibili in realtà.</span><span class="sxs-lookup"><span data-stu-id="d6592-108">This is not something humans can do in reality.</span></span> <span data-ttu-id="d6592-109">In HoloLens (AR) e realtà mista (VR), abbiamo dotare gli utenti con questo power magico scrivendo, il vincolo fisico del mondo reale non solo avere un'esperienza eccellente ai con contenuto holographic ma anche per rendere l'interazione più efficace ed efficiente di rilievo.</span><span class="sxs-lookup"><span data-stu-id="d6592-109">In both HoloLens (AR) and Mixed Reality (VR), we equip users with this magical power, breaking the physical constraint of the real world not only to have a delightful experience with holographic contents but also to make the interaction more effective and efficient.</span></span>

## <a name="device-support"></a><span data-ttu-id="d6592-110">Supporto di dispositivi</span><span class="sxs-lookup"><span data-stu-id="d6592-110">Device support</span></span>

<span data-ttu-id="d6592-111">Modello di input</span><span class="sxs-lookup"><span data-stu-id="d6592-111">Input model</span></span> | [<span data-ttu-id="d6592-112">HoloLens (dal 1 ° generazione)</span><span class="sxs-lookup"><span data-stu-id="d6592-112">HoloLens (1st gen)</span></span>](https://docs.microsoft.com/en-us/windows/mixed-reality/hololens-hardware-details) | <span data-ttu-id="d6592-113">HoloLens 2</span><span class="sxs-lookup"><span data-stu-id="d6592-113">HoloLens 2</span></span> | [<span data-ttu-id="d6592-114">Auricolari coinvolgenti</span><span class="sxs-lookup"><span data-stu-id="d6592-114">Immersive headsets</span></span>](https://docs.microsoft.com/en-us/windows/mixed-reality/immersive-headset-hardware-details) |
| ---------| -----| ----- | ---------|
<span data-ttu-id="d6592-115">Punto ed eseguire il commit con le mani</span><span class="sxs-lookup"><span data-stu-id="d6592-115">Point and commit with hands</span></span> | <span data-ttu-id="d6592-116">❌ Non supportato</span><span class="sxs-lookup"><span data-stu-id="d6592-116">❌ Not supported</span></span> | <span data-ttu-id="d6592-117">✔️ Consigliato</span><span class="sxs-lookup"><span data-stu-id="d6592-117">✔️ Recommended</span></span> | <span data-ttu-id="d6592-118">✔️ Consigliato</span><span class="sxs-lookup"><span data-stu-id="d6592-118">✔️ Recommended</span></span>

<span data-ttu-id="d6592-119">Punto e commit, noto anche come mani a questo momento, è una delle nuove funzionalità che utilizza il nuovo sistema di rilevamento delle modifiche manuale articolato.</span><span class="sxs-lookup"><span data-stu-id="d6592-119">Point and commit, also known as hands far, is one of the new features that utilizes the new articulated hand-tracking system.</span></span> <span data-ttu-id="d6592-120">Questo modello di input è anche il modello di input primario su immersive auricolari tramite l'uso di controller di movimento.</span><span class="sxs-lookup"><span data-stu-id="d6592-120">This input model is also the primary input model on immersive headsets through the use of motion controllers.</span></span>

## <a name="hand-rays"></a><span data-ttu-id="d6592-121">Raggi mano</span><span class="sxs-lookup"><span data-stu-id="d6592-121">Hand rays</span></span>

<span data-ttu-id="d6592-122">In 2 HoloLens, abbiamo creato un raggio di parte che emette dal centro di un dispositivo.</span><span class="sxs-lookup"><span data-stu-id="d6592-122">On HoloLens 2, we created a hand ray that shoots out from the center of a palm.</span></span> <span data-ttu-id="d6592-123">Questo ray viene considerato come un'estensione della lancetta.</span><span class="sxs-lookup"><span data-stu-id="d6592-123">This ray is treated as an extension of the hand.</span></span> <span data-ttu-id="d6592-124">Un cursore a forma di grafico ad anello è collegato alla fine del raggio per indicare il percorso in cui il raggio si interseca con un oggetto di destinazione.</span><span class="sxs-lookup"><span data-stu-id="d6592-124">A donut-shaped cursor is attached to the end of the ray to indicate the location where the ray intersects with a target object.</span></span> <span data-ttu-id="d6592-125">L'oggetto che apre il cursore può quindi ricevere comandi gestuali dall'icona della mano.</span><span class="sxs-lookup"><span data-stu-id="d6592-125">The object that the cursor lands on can then receive gestural commands from the hand.</span></span>

<span data-ttu-id="d6592-126">Questo comando gestuali base viene avviato usando il controllo thumb e con un dito indice per eseguire l'azione indice puntato.</span><span class="sxs-lookup"><span data-stu-id="d6592-126">This basic gestural command is triggered by using the thumb and index finger to perform the air-tap action.</span></span> <span data-ttu-id="d6592-127">Tramite il raggio di mano per puntare e puntare al commit, gli utenti possono attivare un pulsante o un collegamento ipertestuale in un contenuto web.</span><span class="sxs-lookup"><span data-stu-id="d6592-127">By using the hand ray to point and air tap to commit, users can activate a button or a hyperlink on a web content.</span></span> <span data-ttu-id="d6592-128">Con gesti composite più, gli utenti sono in grado di esplorazione del contenuto web e la modifica di oggetti 3D da una distanza.</span><span class="sxs-lookup"><span data-stu-id="d6592-128">With more composite gestures, users are capable of navigating web content and manipulating 3D objects from a distance.</span></span> <span data-ttu-id="d6592-129">La progettazione visiva del raggio mano anche deve reagire in questi stati punto ed eseguire il commit, come descritto e illustrato di seguito:</span><span class="sxs-lookup"><span data-stu-id="d6592-129">The visual design of the hand ray should also react to these point and commit states, as described and shown below:</span></span> 

* <span data-ttu-id="d6592-130">Nel *puntando* lo stato, il raggio è una linea tratteggiata e il cursore si trova una forma di grafico ad anello.</span><span class="sxs-lookup"><span data-stu-id="d6592-130">In the *pointing* state, the ray is a dash line and the cursor is a donut shape.</span></span>
* <span data-ttu-id="d6592-131">Nel *commit* lo stato, il raggio si trasforma in una linea continua e il cursore viene ridotta a un punto.</span><span class="sxs-lookup"><span data-stu-id="d6592-131">In the *commit* state, the ray turns into a solid line and the cursor shrinks to a dot.</span></span>

![](images/Hand-Rays-720px.jpg)

## <a name="transition-between-near-and-far"></a><span data-ttu-id="d6592-132">Eseguire la transizione tra vicino e lontano</span><span class="sxs-lookup"><span data-stu-id="d6592-132">Transition between near and far</span></span>

<span data-ttu-id="d6592-133">Invece di usare movimenti specifici, ad esempio "punta verso con dito indice" per indirizzare il raggio, abbiamo progettato il raggio presto out dal centro del palmo, rilasciando e riservare le cinque dita per movimenti manipulative altre, ad esempio avvicinare le dita e prendo.</span><span class="sxs-lookup"><span data-stu-id="d6592-133">Instead of using specific gesture, such as "pointing with index finger" to direct the ray, we designed the ray coming out from the center of the palm, releasing and reserving the five fingers for more manipulative gestures, such as pinch and grab.</span></span> <span data-ttu-id="d6592-134">Con questa struttura, creiamo un unico modello mentale, esattamente lo stesso insieme di movimenti della mano di supporto per l'interazione sia vicino.</span><span class="sxs-lookup"><span data-stu-id="d6592-134">With this design, we create only one mental model, supporting exactly the same set of hand gestures for both near and far interaction.</span></span> <span data-ttu-id="d6592-135">È possibile usare la stessa combinazione di quadratini di ridimensionamento per manipolare gli oggetti alle distanze diverse.</span><span class="sxs-lookup"><span data-stu-id="d6592-135">You can use the same grab gesture to manipulate objects at different distances.</span></span> <span data-ttu-id="d6592-136">La chiamata di raggi è automatico e basati su prossimità:</span><span class="sxs-lookup"><span data-stu-id="d6592-136">The invocation of the rays is automatic and proximity based:</span></span>

*  <span data-ttu-id="d6592-137">Quando un oggetto all'interno di Azure Resource Manager raggiunto distanza (all'incirca 50 cm), sono disattivati incoraggiando automaticamente per l'interazione con quasi raggi.</span><span class="sxs-lookup"><span data-stu-id="d6592-137">When an object is within arm reached distance (roughly 50 cm), the rays are turned off automatically encouraging for near interaction.</span></span>
*  <span data-ttu-id="d6592-138">Quando l'oggetto è un cm 50, i raggi siano accesi.</span><span class="sxs-lookup"><span data-stu-id="d6592-138">When the object is farther than 50 cm, the rays are turned on.</span></span> <span data-ttu-id="d6592-139">La transizione deve essere diretto e immediato.</span><span class="sxs-lookup"><span data-stu-id="d6592-139">The transition should be smooth and seamless.</span></span>

![](images/Transition-Between-Near-And-Far-720px.jpg)

## <a name="2d-slate-interaction"></a><span data-ttu-id="d6592-140">Interazione dello slate 2D</span><span class="sxs-lookup"><span data-stu-id="d6592-140">2D slate interaction</span></span>

<span data-ttu-id="d6592-141">Uno Slate 2D è un contenitore holographic hosting di contenuto dell'app 2D, ad esempio web browser.</span><span class="sxs-lookup"><span data-stu-id="d6592-141">A 2D Slate is a holographic container hosting 2D app contents, such as web browser.</span></span> <span data-ttu-id="d6592-142">Il concetto di progettazione di gran lunga l'interazione con uno slate 2D consiste nell'usare rays mano a tap air e di destinazione da selezionare.</span><span class="sxs-lookup"><span data-stu-id="d6592-142">The design concept for far interacting with a 2D slate is to use hand rays to target and air tap to select.</span></span> <span data-ttu-id="d6592-143">Dopo la destinazione con un raggio di mano, gli utenti possono puntare l'indice per attivare un collegamento ipertestuale o un pulsante.</span><span class="sxs-lookup"><span data-stu-id="d6592-143">After targeting with a hand ray, users can air tap to trigger a hyperlink or a button.</span></span> <span data-ttu-id="d6592-144">Un lato possono usare per "aria tocco e trascinare" scorrere un contenuto dello slate e ridurre le prestazioni.</span><span class="sxs-lookup"><span data-stu-id="d6592-144">They can use one hand to "air tap and drag" to scroll a slate content up and down.</span></span> <span data-ttu-id="d6592-145">Il movimento relativo dell'utilizzo di due mani all'aria tocco e trascinare per ingrandire e il contenuto dello slate.</span><span class="sxs-lookup"><span data-stu-id="d6592-145">The relative motion of using two hands to air tap and drag can zoom in and out the slate content.</span></span>

<span data-ttu-id="d6592-146">Come destinazione il raggio mano nel bordo e angoli rivela la più vicina intuitività di manipolazione.</span><span class="sxs-lookup"><span data-stu-id="d6592-146">Targeting the hand ray at the corners and edges reveals the closest manipulation affordance.</span></span> <span data-ttu-id="d6592-147">Per "quadratini di ridimensionamento e trascinare" affordance la manipolazione, gli utenti possono eseguire uniform scalabilità tramite i affordance angolo e ridisporre il lo slate tramite i affordance edge.</span><span class="sxs-lookup"><span data-stu-id="d6592-147">By "grab and drag" the manipulation affordances, users can perform uniform scaling through the corner affordances and can reflow the slate via the edge affordances.</span></span> <span data-ttu-id="d6592-148">Selezionandola e trascinando la holobar nella parte superiore dello slate 2D gli utenti possono spostare lo slate intero.</span><span class="sxs-lookup"><span data-stu-id="d6592-148">Grabbing and dragging the holobar at the top of the 2D slate can users move the whole slate.</span></span>

![](images/2D-Slate-Interaction-Far-720px.jpg)

<span data-ttu-id="d6592-149">Per la manipolazione 2D ardesia stesso:</span><span class="sxs-lookup"><span data-stu-id="d6592-149">For manipulating the 2D slate itself:</span></span><br>

* <span data-ttu-id="d6592-150">Gli utenti puntano raggio mano negli angoli o bordi per rivelare il più vicino intuitività di manipolazione.</span><span class="sxs-lookup"><span data-stu-id="d6592-150">Users point the hand ray at the corners or edges to reveal the closest manipulation affordance.</span></span> 
* <span data-ttu-id="d6592-151">Applicando un movimento di manipolazione nell'intuitività, gli utenti possono eseguire la scalabilità uniforme tramite intuitività l'angolo e ridisporre il lo slate tramite l'intuitività edge.</span><span class="sxs-lookup"><span data-stu-id="d6592-151">By applying a manipulation gesture on the affordance, users can perform uniform scaling through the corner affordance and can reflow the slate via the edge affordance.</span></span> 
* <span data-ttu-id="d6592-152">Applicando un movimento di manipolazione nel holobar nella parte superiore dello slate 2D, gli utenti possono spostare lo slate intero.</span><span class="sxs-lookup"><span data-stu-id="d6592-152">By applying a manipulation gesture on the holobar at the top of the 2D slate, users can move the whole slate.</span></span><br>

<br>

## <a name="3d-object-manipulation"></a><span data-ttu-id="d6592-153">Modifica di oggetti 3D</span><span class="sxs-lookup"><span data-stu-id="d6592-153">3D object manipulation</span></span>

<span data-ttu-id="d6592-154">Manipolazione diretta, esistono due modi agli utenti di modificare oggetti 3D, basato su intuitività manipolazione e la modifica in base non intuitività.</span><span class="sxs-lookup"><span data-stu-id="d6592-154">In direct manipulation, there are two ways for users to manipulate 3D object, affordance-based manipulation and non-affordance based manipulation.</span></span> <span data-ttu-id="d6592-155">Nel modello di punto e il commit, gli utenti sono in grado di raggiungere esattamente le stesse attività tramite i raggi di mano.</span><span class="sxs-lookup"><span data-stu-id="d6592-155">In the point and commit model, users are capable of achieving exactly the same tasks through the hand rays.</span></span> <span data-ttu-id="d6592-156">Non è necessaria alcuna conoscenza più approfondita.</span><span class="sxs-lookup"><span data-stu-id="d6592-156">No additional learning is needed.</span></span><br>

### <a name="affordance-based-manipulation"></a><span data-ttu-id="d6592-157">Basato su intuitività manipulation</span><span class="sxs-lookup"><span data-stu-id="d6592-157">Affordance-based manipulation</span></span>
<span data-ttu-id="d6592-158">Gli utenti usare rays mano per puntare e individuare il riquadro delimitatore e affordance manipolazione.</span><span class="sxs-lookup"><span data-stu-id="d6592-158">Users use hand rays to point and reveal the bounding box and manipulation affordances.</span></span> <span data-ttu-id="d6592-159">Gli utenti possono applicare il movimento di manipolazione nel rettangolo di selezione per spostare l'intero oggetto, sul affordance bordo per ruotare e di coner affordance ridimensionare in modo uniforme.</span><span class="sxs-lookup"><span data-stu-id="d6592-159">Users can apply the manipulation gesture on the bounding box to move the whole object, on the edge affordances to rotate and on the coner affordances to scale uniformly.</span></span> <br>

![](images/3D-Object-Manipulation-Far-720px.jpg) <br>


### <a name="non-affordance-based-manipulation"></a><span data-ttu-id="d6592-160">Manipolazione di base non intuitività</span><span class="sxs-lookup"><span data-stu-id="d6592-160">Non-affordance based manipulation</span></span>
<span data-ttu-id="d6592-161">Gli utenti punto con rays mano per rivelare il rettangolo di selezione e quindi applicare direttamente i movimenti di manipolazione su di esso.</span><span class="sxs-lookup"><span data-stu-id="d6592-161">Users point with hand rays to reveal the bounding box then directly apply manipulation gestures on it.</span></span> <span data-ttu-id="d6592-162">A un lato, la traslazione e rotazione dell'oggetto sono associati al movimento e l'orientamento della lancetta.</span><span class="sxs-lookup"><span data-stu-id="d6592-162">With one hand, the translation and rotation of the object are associated to motion and orientation of the hand.</span></span> <span data-ttu-id="d6592-163">Con due mani, gli utenti possono traslare, ridimensionare e ruotarla in base al relativi movimenti di due mani.</span><span class="sxs-lookup"><span data-stu-id="d6592-163">With two hands, users can translate, scale and rotate it according to relative motions of two hands.</span></span><br>

<br>

## <a name="instinctual-gesturers"></a><span data-ttu-id="d6592-164">Gesturers instinctual</span><span class="sxs-lookup"><span data-stu-id="d6592-164">Instinctual gesturers</span></span>
<span data-ttu-id="d6592-165">Il concetto di movimenti instinctual per punto e il commit è simile a quella di manipolazione diretta.</span><span class="sxs-lookup"><span data-stu-id="d6592-165">The concept of instinctual gestures for point and commit is similar to that for direct manipulation.</span></span> <span data-ttu-id="d6592-166">Per impostazione predefinita di affordance dell'interfaccia utente vengono indirizzati i movimenti che gli utenti dovranno per eseguire su un oggetto 3D.</span><span class="sxs-lookup"><span data-stu-id="d6592-166">The gestures users are suppose to perform on a 3D object are guided by the design of UI affordances.</span></span> <span data-ttu-id="d6592-167">Ad esempio, un punto di controllo di piccole dimensioni potrebbe motivare agli utenti di eseguire il movimento con dito indice e controllo thumb mentre un utente potrebbe voler recuperare un oggetto più grande con tutte le 5 dita.</span><span class="sxs-lookup"><span data-stu-id="d6592-167">For example, a small control point might motivate users to pinch with their thumb and index finger, while a user might want to grab a larger object using all 5 fingers.</span></span>

![](images/Instinctual-Gestures-Far-720px.jpg)<br>

## <a name="symmetric-design-between-hands-and-6-dof-controller"></a><span data-ttu-id="d6592-168">Progettazione simmetrica tra le mani e controller di gradi di libertà 6</span><span class="sxs-lookup"><span data-stu-id="d6592-168">Symmetric design between hands and 6 DoF controller</span></span> 
<span data-ttu-id="d6592-169">Il concetto di punto e il commit per l'interazione con estrema è stato inizialmente creato e definito per il misto realtà portale (MRP), in cui un utente ha un visore VR immersivi e interagisce con oggetti 3D tramite controller di movimento.</span><span class="sxs-lookup"><span data-stu-id="d6592-169">The concept of point and commit for far interaction was initially created and defined for the Mixed Reality Portal (MRP), where a user wears an immersive headset and interacts with 3D objects via motion controllers.</span></span> <span data-ttu-id="d6592-170">I controller di movimento relativi out rays per sta puntando e manipolare oggetti distante.</span><span class="sxs-lookup"><span data-stu-id="d6592-170">The motion controllers shoot out rays for pointing and manipulating far objects.</span></span> <span data-ttu-id="d6592-171">Sono disponibili pulsanti sui controller per ulteriormente il commit delle azioni diverse.</span><span class="sxs-lookup"><span data-stu-id="d6592-171">There are buttons on the controllers for further committing different actions.</span></span> <span data-ttu-id="d6592-172">Abbiamo sfruttare il modello di interazione di raggi e li collegato a entrambe le mani.</span><span class="sxs-lookup"><span data-stu-id="d6592-172">We leverage the interaction model of rays and attached them to both hands.</span></span> <span data-ttu-id="d6592-173">Con questa struttura simmetrica, gli utenti che hanno familiari con MRP non sarà necessario per informazioni su un altro modello di interazione per la modifica e che puntano a questo momento, quando vengono usate 2 HoloLen e viceversa.</span><span class="sxs-lookup"><span data-stu-id="d6592-173">With this symmetric design, users who are familiar with MRP won't need to learn another interaction model for far pointing and manipulation when they use HoloLen 2, and vice versa.</span></span>    

![](images/Symmetric-Design-For-Rays-720px.jpg)<br>

## <a name="instinctual-gestures"></a><span data-ttu-id="d6592-174">Movimenti instinctual</span><span class="sxs-lookup"><span data-stu-id="d6592-174">Instinctual gestures</span></span>

![](images/Instinctual-Gestures-Far-720px.jpg)

## <a name="see-also"></a><span data-ttu-id="d6592-175">Vedere anche</span><span class="sxs-lookup"><span data-stu-id="d6592-175">See also</span></span>
* [<span data-ttu-id="d6592-176">Puntamento con la testa e commit</span><span class="sxs-lookup"><span data-stu-id="d6592-176">Head-gaze and commit</span></span>](gaze-and-commit.md)
* [<span data-ttu-id="d6592-177">Manipolazione diretta con le mani</span><span class="sxs-lookup"><span data-stu-id="d6592-177">Direct manipulation with hands</span></span>](direct-manipulation.md)
* [<span data-ttu-id="d6592-178">Interazioni istintive</span><span class="sxs-lookup"><span data-stu-id="d6592-178">Instinctual interactions</span></span>](interaction-fundamentals.md)

