---
title: Head-sguardo ed eseguire il commit
description: Panoramica del modello di input sguardo di inizio e commit
author: caseymeekhof
ms.author: cmeekhof
ms.date: 03/31/2019
ms.topic: article
ms.localizationpriority: high
keywords: Progettare sguardo, sguardo targeting, interazione, realtà mista
ms.openlocfilehash: a84465de3479bf3da2131b94dd522539cd7de6e9
ms.sourcegitcommit: c20563b8195c0c374a927b96708d958b127ffc8f
ms.translationtype: MT
ms.contentlocale: it-IT
ms.lasthandoff: 05/21/2019
ms.locfileid: "65974871"
---
# <a name="head-gaze-and-commit"></a><span data-ttu-id="4cf88-104">Head-sguardo ed eseguire il commit</span><span class="sxs-lookup"><span data-stu-id="4cf88-104">Head-gaze and commit</span></span>
<span data-ttu-id="4cf88-105">Head-sguardo ed eseguire il commit è un modello di input che coinvolge destinato a un oggetto con direzione di inizio in avanti che punta (head-direction) e quindi agisce su di esso con una replica secondaria di input, ad il movimento mano Air toccare o voce di comando "Select".</span><span class="sxs-lookup"><span data-stu-id="4cf88-105">Head-gaze and commit is an input model that involves targeting an object with the direction of your head pointing forward (head-direction), and then acting on it with a secondary input such as the hand gesture Air Tap or the voice command “Select”.</span></span> <span data-ttu-id="4cf88-106">Viene considerato un modello di input "molto" con manipolazione indiretta, ovvero che viene utilizzato meglio per l'interazione con contenuto che è di là arms raggiungere.</span><span class="sxs-lookup"><span data-stu-id="4cf88-106">It is considered a "far" input model with indirect manipulation, meaning it is best used for interacting with content that is beyond arms reach.</span></span>

## <a name="device-support"></a><span data-ttu-id="4cf88-107">Supporto di dispositivi</span><span class="sxs-lookup"><span data-stu-id="4cf88-107">Device support</span></span>

<table>
    <colgroup>
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    </colgroup>
    <tr>
        <td><span data-ttu-id="4cf88-108"><strong>Modello di input</strong></span><span class="sxs-lookup"><span data-stu-id="4cf88-108"><strong>Input model</strong></span></span></td>
        <td><span data-ttu-id="4cf88-109"><a href="hololens-hardware-details.md"><strong>HoloLens (dal 1 ° generazione)</strong></a></span><span class="sxs-lookup"><span data-stu-id="4cf88-109"><a href="hololens-hardware-details.md"><strong>HoloLens (1st gen)</strong></a></span></span></td>
        <td><span data-ttu-id="4cf88-110"><strong>HoloLens 2</strong></span><span class="sxs-lookup"><span data-stu-id="4cf88-110"><strong>HoloLens 2</strong></span></span></td>
        <td><span data-ttu-id="4cf88-111"><a href="immersive-headset-hardware-details.md"><strong>Auricolari coinvolgenti</strong></a></span><span class="sxs-lookup"><span data-stu-id="4cf88-111"><a href="immersive-headset-hardware-details.md"><strong>Immersive headsets</strong></a></span></span></td>
    </tr>
     <tr>
        <td><span data-ttu-id="4cf88-112">Head-sguardo ed eseguire il commit</span><span class="sxs-lookup"><span data-stu-id="4cf88-112">Head-gaze and commit</span></span></td>
        <td><span data-ttu-id="4cf88-113">✔️ Consigliato</span><span class="sxs-lookup"><span data-stu-id="4cf88-113">✔️ Recommended</span></span></td>
        <td><span data-ttu-id="4cf88-114">✔️ Consigliato (in terza scelta - <a href="interaction-fundamentals.md">vedere le altre opzioni</a>)</span><span class="sxs-lookup"><span data-stu-id="4cf88-114">✔️ Recommended (third choice - <a href="interaction-fundamentals.md">See the other options</a>)</span></span></td>
        <td><span data-ttu-id="4cf88-115">Opzione alternativa ➕</span><span class="sxs-lookup"><span data-stu-id="4cf88-115">➕ Alternate option</span></span></td>
    </tr>
</table>

## <a name="head-gaze"></a><span data-ttu-id="4cf88-116">Head-sguardo</span><span class="sxs-lookup"><span data-stu-id="4cf88-116">Head-gaze</span></span>
<span data-ttu-id="4cf88-117">Realtà mista auricolari usano la posizione e l'orientamento della testina dell'utente per determinare il vettore di direzione head.</span><span class="sxs-lookup"><span data-stu-id="4cf88-117">Mixed reality headsets use the position and orientation of the user's head to determine their head direction vector.</span></span> <span data-ttu-id="4cf88-118">È possibile considerare questo come il laser che faccia riferimento dritto dal direttamente tra gli occhi dell'utente.</span><span class="sxs-lookup"><span data-stu-id="4cf88-118">You can think of this as a laser that points straight ahead from directly between the user's eyes.</span></span> <span data-ttu-id="4cf88-119">Si tratta di un piuttosto grossolana approssimazione di dove sta guardando l'utente.</span><span class="sxs-lookup"><span data-stu-id="4cf88-119">This is a fairly coarse approximation of where the user is looking.</span></span> <span data-ttu-id="4cf88-120">L'applicazione possa interseca il raggio con oggetti reali o virtuali e creare un cursore in tale posizione per consentire all'utente di sapere che cosa sono in uso.</span><span class="sxs-lookup"><span data-stu-id="4cf88-120">Your application can intersect this ray with virtual or real-world objects and draw a cursor at that location to let the user know what they are currently targeting.</span></span>

<span data-ttu-id="4cf88-121">Oltre a head sguardo, alcuni auricolari realtà mista, ad esempio le 2 HoloLens includono sotto controllo i sistemi che producono un vettore visiva di rilevamento.</span><span class="sxs-lookup"><span data-stu-id="4cf88-121">In addition to head gaze, some mixed reality headsets like the HoloLens 2 include eye tracking systems that produce an eye-gaze vector.</span></span> <span data-ttu-id="4cf88-122">Ciò fornisce una misura con granularità fine del dove sta guardando l'utente.</span><span class="sxs-lookup"><span data-stu-id="4cf88-122">This provides a fine-grained measurement of where the user is looking.</span></span> <span data-ttu-id="4cf88-123">È possibile compilare sguardo ed eseguire il commit le interazioni tramite sguardo sotto controllo, ma ciò comporta un set di vincoli di progettazione, che verranno trattati separatamente in molto diverso il [occhio rilevamento articolo](eye-tracking.md).</span><span class="sxs-lookup"><span data-stu-id="4cf88-123">It is possible to build gaze and commit interactions using eye gaze, but this comes with a very different set of design constraints, which will be covered separately in the [eye tracking article](eye-tracking.md).</span></span>

## <a name="commit"></a><span data-ttu-id="4cf88-124">Eseguire il commit</span><span class="sxs-lookup"><span data-stu-id="4cf88-124">Commit</span></span>
<span data-ttu-id="4cf88-125">Dopo la destinazione è un oggetto o un elemento dell'interfaccia utente, l'utente può interagire o "click" su di essa utilizzando input secondari.</span><span class="sxs-lookup"><span data-stu-id="4cf88-125">After targeting an object or UI element, the user can interact or "click" on it using a secondary input.</span></span> <span data-ttu-id="4cf88-126">Questo è noto come il passaggio di commit del modello.</span><span class="sxs-lookup"><span data-stu-id="4cf88-126">This is known as the commit step of the model.</span></span> <span data-ttu-id="4cf88-127">Sono supportati i seguenti metodi di commit:</span><span class="sxs-lookup"><span data-stu-id="4cf88-127">The following commit methods are supported:</span></span>

- <span data-ttu-id="4cf88-128">Movimento dell'indice puntato</span><span class="sxs-lookup"><span data-stu-id="4cf88-128">Air Tap gesture</span></span>
- <span data-ttu-id="4cf88-129">Pronunciare il comando vocale "Select" o uno dei comandi vocali destinazione</span><span class="sxs-lookup"><span data-stu-id="4cf88-129">Speak the voice command "Select" or one of the targeted voice commands</span></span>
- <span data-ttu-id="4cf88-130">Fare clic sul pulsante singolo un [HoloLens Clicker](hardware-accessories.md#hololens-clicker)</span><span class="sxs-lookup"><span data-stu-id="4cf88-130">Press the single button on a [HoloLens Clicker](hardware-accessories.md#hololens-clicker)</span></span>
- <span data-ttu-id="4cf88-131">Fare clic sul pulsante 'A' su un Xbox Gamepad</span><span class="sxs-lookup"><span data-stu-id="4cf88-131">Press the 'A' button on an Xbox Gamepad</span></span>
- <span data-ttu-id="4cf88-132">Fare clic sul pulsante 'A' in un Controller adattivo Xbox</span><span class="sxs-lookup"><span data-stu-id="4cf88-132">Press the 'A' button on an Xbox Adaptive Controller</span></span>

### <a name="head-gaze-and-air-tap-gesture"></a><span data-ttu-id="4cf88-133">Head-sguardo e aria gesto tocco</span><span class="sxs-lookup"><span data-stu-id="4cf88-133">Head-gaze and air tap gesture</span></span>
<span data-ttu-id="4cf88-134">Indice puntato è un gesto tocco con l'icona della mano mantenuto in verticale.</span><span class="sxs-lookup"><span data-stu-id="4cf88-134">Air tap is a tapping gesture with the hand held upright.</span></span> <span data-ttu-id="4cf88-135">Per eseguire l'indice puntato, generare il dito indice nella posizione pronto, quindi avvicinare le dita con il controllo thumb e generare il dito indice eseguire il backup per rilasciare.</span><span class="sxs-lookup"><span data-stu-id="4cf88-135">To perform an Air tap, raise your index finger to the ready position, then pinch with your thumb and raise your index finger back up to release.</span></span> <span data-ttu-id="4cf88-136">In 1 HoloLens, indice puntato è l'input secondario più comune.</span><span class="sxs-lookup"><span data-stu-id="4cf88-136">On HoloLens 1, Air tap is the most common secondary input.</span></span>

![Con un dito nella posizione pronta e quindi un movimento toccare o fare clic su](images/readyandpress.jpg)<br>

<span data-ttu-id="4cf88-138">Indice puntato è disponibile anche su HoloLens 2 e è stato aumentato dalla versione originale.</span><span class="sxs-lookup"><span data-stu-id="4cf88-138">Air tap is also available on HoloLens 2, and it has been relaxed from the original version.</span></span> <span data-ttu-id="4cf88-139">Quasi tutti i tipi di pinches sono ora supportati, fino a quando l'icona della mano è verticale e ha ancora.</span><span class="sxs-lookup"><span data-stu-id="4cf88-139">Nearly all types of pinches are now supported, as long as the hand is upright and holding still.</span></span> <span data-ttu-id="4cf88-140">Questo rende molto più semplice per gli utenti apprendere e di eseguire il movimento.</span><span class="sxs-lookup"><span data-stu-id="4cf88-140">This makes it much easier for users to learn and perform the gesture.</span></span>  <span data-ttu-id="4cf88-141">Questo nuovo indice puntato sostituisca il precedente tramite l'API stessa, in modo che le applicazioni esistenti otterranno automaticamente il nuovo comportamento dopo la ricompilazione per HoloLens 2.</span><span class="sxs-lookup"><span data-stu-id="4cf88-141">This new Air tap replaces the old one through the same API, so existing applications will get the new behavior automatically after recompiling for HoloLens 2.</span></span>

### <a name="head-gaze-and-select-voice-command"></a><span data-ttu-id="4cf88-142">Head-sguardo e "Selezionare" vocali comando</span><span class="sxs-lookup"><span data-stu-id="4cf88-142">Head-gaze and "Select" voice command</span></span>
<span data-ttu-id="4cf88-143">L'esecuzione di comandi vocali è uno dei metodi di interazione principale nella realtà mista.</span><span class="sxs-lookup"><span data-stu-id="4cf88-143">Voice commanding is one of the primary interaction methods on Mixed Reality.</span></span> <span data-ttu-id="4cf88-144">Fornisce un meccanismo molto potente "Mani libero" per controllare il sistema.</span><span class="sxs-lookup"><span data-stu-id="4cf88-144">It provides a very powerful "Hands Free" mechanism to control the system.</span></span> <span data-ttu-id="4cf88-145">Sono disponibili tipi differente di modelli di interazione vocale:</span><span class="sxs-lookup"><span data-stu-id="4cf88-145">There are diferent types of voice interaction models:</span></span>

- <span data-ttu-id="4cf88-146">Il comando generico "Select" che consente di eseguire un "fare clic su" azionamento o commit come input secondari.</span><span class="sxs-lookup"><span data-stu-id="4cf88-146">The generic command "Select" that allows to perform a "click" actuation or commit as a secondary input.</span></span>
- <span data-ttu-id="4cf88-147">Comandi dell'oggetto, ad esempio "Chiudi" o "Ingrandirlo" che consente di eseguire ed eseguire il commit a un'azione come input secondari.</span><span class="sxs-lookup"><span data-stu-id="4cf88-147">Object commands like "Close" or "Make it bigger" that allow to perform and commit to an action as a secondary input.</span></span>
- <span data-ttu-id="4cf88-148">File globali, ad esempio "Torna all'inizio" che non richiedono una destinazione.</span><span class="sxs-lookup"><span data-stu-id="4cf88-148">Global commnads like "Go to start" that don't require a target.</span></span>
- <span data-ttu-id="4cf88-149">Interfacce utente conversazione o entità, come Cortana dotati di una funzionalità del linguaggio naturale per intelligenza artificiale.</span><span class="sxs-lookup"><span data-stu-id="4cf88-149">Conversation user interfaces or entities like Cortana that have an AI Natural Language capability.</span></span>
- <span data-ttu-id="4cf88-150">File personalizzato</span><span class="sxs-lookup"><span data-stu-id="4cf88-150">Custom commnads</span></span>

<span data-ttu-id="4cf88-151">Per trovare altri dettagli e un elenco di comprenhesive di comandi disponibili e sul relativo utilizzo, consultare il [l'esecuzione di comandi vocali](voice-design.md) indicazioni.</span><span class="sxs-lookup"><span data-stu-id="4cf88-151">To find more details and a comprenhesive list of available commands and how to use, check out our [voice commanding](voice-design.md) guidance.</span></span>


### <a name="head-gaze-and-hololens-clicker"></a><span data-ttu-id="4cf88-152">Head-sguardo e HoloLens Clicker</span><span class="sxs-lookup"><span data-stu-id="4cf88-152">Head-gaze and HoloLens Clicker</span></span>
<span data-ttu-id="4cf88-153">Il HoloLens Clicker è il primo dispositivo periferico creato appositamente per HoloLens e viene fornita con la versione di sviluppo di HoloLens 1.</span><span class="sxs-lookup"><span data-stu-id="4cf88-153">The HoloLens Clicker is the first peripheral device built specifically for HoloLens and is included with the HoloLens 1 Development Edition.</span></span> <span data-ttu-id="4cf88-154">Il HoloLens Clicker consente all'utente di fare clic su con movimento manuale minimo ed eseguire il commit come input secondari.</span><span class="sxs-lookup"><span data-stu-id="4cf88-154">The HoloLens Clicker allows a user to click with minimal hand motion and commit as a secondary input.</span></span> <span data-ttu-id="4cf88-155">Il clicker HoloLens si connette a HoloLens 1 o 2 tramite Bluetooth Low Energy (BTLE).</span><span class="sxs-lookup"><span data-stu-id="4cf88-155">The HoloLens clicker connects to the HoloLens 1 or 2 using Bluetooth Low Energy (BTLE).</span></span>

![](images/hololens-clicker-500px.jpg)<br>
<span data-ttu-id="4cf88-156">HoloLens Clicker</span><span class="sxs-lookup"><span data-stu-id="4cf88-156">HoloLens Clicker</span></span>

<span data-ttu-id="4cf88-157">Sono disponibili altre informazioni e istruzioni per associare il dispositivo [qui](hardware-accessories.md#pairing-bluetooth-accessories)</span><span class="sxs-lookup"><span data-stu-id="4cf88-157">More information and instructions to pair the device can be found [here](hardware-accessories.md#pairing-bluetooth-accessories)</span></span>




### <a name="head-gaze-and-xbox-wireless-controller"></a><span data-ttu-id="4cf88-158">Head-sguardo e Controller Xbox Wireless</span><span class="sxs-lookup"><span data-stu-id="4cf88-158">Head-gaze and Xbox Wireless Controller</span></span>
<span data-ttu-id="4cf88-159">Il Controller Wireless Xbox consente l'esecuzione di un azionamento "fare clic su" come database secondario con il pulsante di input.</span><span class="sxs-lookup"><span data-stu-id="4cf88-159">The Xbox Wireless Controller allows to perform a "click" actuation as a secondary input by using the A button.</span></span> <span data-ttu-id="4cf88-160">Il dispositivo viene mappato a un set predefinito di azioni che consentono di esplorare e controllo del sistema.</span><span class="sxs-lookup"><span data-stu-id="4cf88-160">The device is mapped to a default set of actions that help navigate and controll the system.</span></span> <span data-ttu-id="4cf88-161">Se si desidera personalizzare il controller, usare l'App di Accesories Xbox per configurare il Controller Wireless Xbox.</span><span class="sxs-lookup"><span data-stu-id="4cf88-161">If you want to customize the controller, use the Xbox Accesories App to configure your Xbox Wireless Controller.</span></span>

![](images/xboxcontroller.jpg)<br>
<span data-ttu-id="4cf88-162">Controller Xbox Wireless</span><span class="sxs-lookup"><span data-stu-id="4cf88-162">Xbox Wireless Controller</span></span>

[<span data-ttu-id="4cf88-163">Associazione di un controller Xbox con il PC</span><span class="sxs-lookup"><span data-stu-id="4cf88-163">Pairing an Xbox controller with your PC</span></span>](hardware-accessories.md#pairing-bluetooth-accessories)


### <a name="head-gaze-and-xbox-adaptive-controller"></a><span data-ttu-id="4cf88-164">Controller adattivo head sguardo e Xbox</span><span class="sxs-lookup"><span data-stu-id="4cf88-164">Head-gaze and Xbox Adaptive Controller</span></span>
<span data-ttu-id="4cf88-165">Progettato principalmente per soddisfare le esigenze dei giocatori con difficoltà, il Controller di Adaptive Xbox è un hub unificato per i dispositivi che consente di rendere più accessibile realtà mista.</span><span class="sxs-lookup"><span data-stu-id="4cf88-165">Designed primarily to meet the needs of gamers with limited mobility, the Xbox Adaptive Controller is a unified hub for devices that helps make Mixed Reality more accessible.</span></span>

<span data-ttu-id="4cf88-166">Il Controller adattivo Xbox consente l'esecuzione di un azionamento "fare clic su" come un database secondario con il pulsante di input.</span><span class="sxs-lookup"><span data-stu-id="4cf88-166">The Xbox Adaptive Controller allows to perform a "click" actuation as a secondary input by using the A button.</span></span> <span data-ttu-id="4cf88-167">Il dispositivo viene mappato a un set predefinito di azioni che consentono di esplorare e controllo del sistema.</span><span class="sxs-lookup"><span data-stu-id="4cf88-167">The device is mapped to a default set of actions that help navigate and controll the system.</span></span> <span data-ttu-id="4cf88-168">Se si desidera personalizzare il controller, usare l'App di Accesories Xbox per configurare il Controller adattivo Xbox.</span><span class="sxs-lookup"><span data-stu-id="4cf88-168">If you want to customize the controller, use the Xbox Accesories App to configure your Xbox Adaptive Controller.</span></span>

![](images/xbox-adaptive-controller-devices.jpg)<br>
<span data-ttu-id="4cf88-169">Controller adattivo Xbox</span><span class="sxs-lookup"><span data-stu-id="4cf88-169">Xbox Adaptive Controller</span></span>

<span data-ttu-id="4cf88-170">Connetti i dispositivi esterni, ad esempio commutatori, pulsanti, punti di montaggio e joystick per creare un'esperienza personalizzata controller che ricade sul cliente in modo univoco.</span><span class="sxs-lookup"><span data-stu-id="4cf88-170">Connect external devices such as switches, buttons, mounts, and joysticks to create a custom controllers experience that is uniquely yours.</span></span> <span data-ttu-id="4cf88-171">Pulsante, thumbstick e trigger di input vengono controllate con tecnologie e dispositivi connessi tramite jack mm 3.5 e le porte USB.</span><span class="sxs-lookup"><span data-stu-id="4cf88-171">Button, thumbstick and trigger inputs are controlled with assistive devices connected through 3.5mm jacks and USB ports.</span></span>

![](images/xbox-adaptive-controller-ports.jpg)<br>
<span data-ttu-id="4cf88-172">Porta Controller adattivo Xbox</span><span class="sxs-lookup"><span data-stu-id="4cf88-172">Xbox Adaptive Controller ports</span></span>

[<span data-ttu-id="4cf88-173">Istruzioni per associare il dispositivo</span><span class="sxs-lookup"><span data-stu-id="4cf88-173">Instructions to pair the device</span></span>](hardware-accessories.md#pairing-bluetooth-accessories)

<span data-ttu-id="4cf88-174"><a href=https://www.xbox.com/en-US/xbox-one/accessories/controllers/xbox-adaptive-controller>Altre informazioni disponibili sul sito Xbox</a></span><span class="sxs-lookup"><span data-stu-id="4cf88-174"><a href=https://www.xbox.com/en-US/xbox-one/accessories/controllers/xbox-adaptive-controller>More info available on the Xbox site</a></span></span>


# <a name="head-gaze-design-guidelines"></a><span data-ttu-id="4cf88-175">Linee guida di progettazione head sguardo</span><span class="sxs-lookup"><span data-stu-id="4cf88-175">Head-gaze design guidelines</span></span>
> [!NOTE]
> <span data-ttu-id="4cf88-176">Informazioni aggiuntive specifiche di progettazione estasiati [presto](index.md).</span><span class="sxs-lookup"><span data-stu-id="4cf88-176">More guidance specific to gaze design [coming soon](index.md).</span></span>

## <a name="head-gaze-targeting"></a><span data-ttu-id="4cf88-177">Head-sguardo targeting</span><span class="sxs-lookup"><span data-stu-id="4cf88-177">Head-gaze targeting</span></span>
<span data-ttu-id="4cf88-178">Tutte le interazioni vengono compilate al momento la possibilità di un utente di destinazione l'elemento a cui che si desidera interagire, indipendentemente dalla modalità di input.</span><span class="sxs-lookup"><span data-stu-id="4cf88-178">All interactions are built upon the ability of a user to target the element they want to interact with, regardless of the input modality.</span></span> <span data-ttu-id="4cf88-179">Realtà mista di Windows, questa operazione viene in genere eseguita usando sguardo dell'utente.</span><span class="sxs-lookup"><span data-stu-id="4cf88-179">In Windows Mixed Reality, this is generally done using the user's gaze.</span></span>
<span data-ttu-id="4cf88-180">Per consentire agli utenti un'esperienza di corretto funzionamento, comprensione calcolata del sistema della finalità dell'utente e l'intenzione dell'utente effettivo, deve essere allineati quanto più vicina.</span><span class="sxs-lookup"><span data-stu-id="4cf88-180">To enable a user to work with an experience successfully, the system's calculated understanding of a user's intent, and the user's actual intent, must align as closely as possible.</span></span> <span data-ttu-id="4cf88-181">Al grado che il sistema interpreta le azioni dell'utente desiderato correttamente, le prestazioni e aumenta la soddisfazione migliora.</span><span class="sxs-lookup"><span data-stu-id="4cf88-181">To the degree that the system interprets the user's intended actions correctly, satisfaction increases and performance improves.</span></span>


## <a name="target-sizing-and-feedback"></a><span data-ttu-id="4cf88-182">Commenti e suggerimenti e le dimensioni di destinazione</span><span class="sxs-lookup"><span data-stu-id="4cf88-182">Target sizing and feedback</span></span>
<span data-ttu-id="4cf88-183">Il vettore sguardo è stato dimostrato ripetutamente per poter essere usato per specificare come destinazione bene, ma spesso è adatto per gross targeting (acquisizione leggermente maggiori destinazioni).</span><span class="sxs-lookup"><span data-stu-id="4cf88-183">The gaze vector has been shown repeatedly to be usable for fine targeting, but often works best for gross targeting (acquiring somewhat larger targets).</span></span> <span data-ttu-id="4cf88-184">Le dimensioni di destinazione minimo di 1 a 1.5 gradi devono consentire le azioni dell'utente ha esito positivo nella maggior parte degli scenari, anche se le destinazioni di gradi 3 spesso consentono maggiore velocità.</span><span class="sxs-lookup"><span data-stu-id="4cf88-184">Minimum target sizes of 1 to 1.5 degrees should allow successful user actions in most scenarios, though targets of 3 degrees often allow for greater speed.</span></span> <span data-ttu-id="4cf88-185">Si noti che le dimensioni che le destinazioni degli utenti in modo efficace è un'area 2D anche per gli elementi 3D, qualunque proiezione è rivolta essi devono essere l'area definibili come destinazione.</span><span class="sxs-lookup"><span data-stu-id="4cf88-185">Note that the size that the user targets is effectively a 2D area even for 3D elements--whichever projection is facing them should be the targetable area.</span></span> <span data-ttu-id="4cf88-186">Fornendo alcune salienti della segnalazione che un elemento è "active" (che l'utente è destinato a si) è molto utile: può trattarsi di trattamenti come effetti visibili "mouse", evidenzia audio o fa clic su, o cancellare l'allineamento di un cursore con un elemento.</span><span class="sxs-lookup"><span data-stu-id="4cf88-186">Providing some salient cue that an element is "active" (that the user is targeting it) is extremely helpful - this can include treatments like visible "hover" effects, audio highlights or clicks, or clear alignment of a cursor with an element.</span></span>

<span data-ttu-id="4cf88-187">![Dimensioni di destinazione ottimale a distanza di 2 metri](images/gazetargeting-size-1000px.jpg)</span><span class="sxs-lookup"><span data-stu-id="4cf88-187">![Optimal target size at 2 meter distance](images/gazetargeting-size-1000px.jpg)</span></span><br>
<span data-ttu-id="4cf88-188">*Dimensioni di destinazione ottimale a distanza di 2 metri*</span><span class="sxs-lookup"><span data-stu-id="4cf88-188">*Optimal target size at 2 meter distance*</span></span>

<span data-ttu-id="4cf88-189">![Un esempio di evidenziazione di un oggetto di destinazione sguardo](images/gazetargeting-highlighting-640px.jpg)</span><span class="sxs-lookup"><span data-stu-id="4cf88-189">![An example of highlighting a gaze targeted object](images/gazetargeting-highlighting-640px.jpg)</span></span><br>
<span data-ttu-id="4cf88-190">*Un esempio di evidenziazione di un oggetto di destinazione sguardo*</span><span class="sxs-lookup"><span data-stu-id="4cf88-190">*An example of highlighting a gaze targeted object*</span></span>

## <a name="target-placement"></a><span data-ttu-id="4cf88-191">Selezione host di destinazione</span><span class="sxs-lookup"><span data-stu-id="4cf88-191">Target placement</span></span>
<span data-ttu-id="4cf88-192">Gli utenti spesso riuscirà a trovare gli elementi dell'interfaccia utente che vengono posizionati in modo molto elevato o molto bassa nel loro campo visivo, concentrandosi la maggior parte dei loro attenzione sulle aree intorno a loro lo stato attivo principale (in genere circa livello rossi).</span><span class="sxs-lookup"><span data-stu-id="4cf88-192">Users will often fail to find UI elements that are positioned very high or very low in their field of view, focusing most of their attention on areas around their main focus (usually roughly eye level).</span></span> <span data-ttu-id="4cf88-193">Consente l'inserimento di quasi tutte le destinazioni in alcune fuori banda ragionevole intorno a livello di attenzione.</span><span class="sxs-lookup"><span data-stu-id="4cf88-193">Placing most targets in some reasonable band around eye level can help.</span></span> <span data-ttu-id="4cf88-194">Data la tendenza per gli utenti per concentrarsi su un'area visual relativamente piccola in qualsiasi momento (cono attentional della visione è all'incirca 10 gradi), raggruppare gli elementi dell'interfaccia utente per il livello che sono correlati a livello concettuale possono sfruttare i comportamenti di concatenamento dell'attenzione da elemento a un elemento con un account utente viene spostata loro sguardo all'interno di un'area.</span><span class="sxs-lookup"><span data-stu-id="4cf88-194">Given the tendency for users to focus on a relatively small visual area at any time (the attentional cone of vision is roughly 10 degrees), grouping UI elements together to the degree that they're related conceptually can leverage attention-chaining behaviors from item to item as a user moves their gaze through an area.</span></span> <span data-ttu-id="4cf88-195">Durante la progettazione dell'interfaccia utente, tenere presenti le variazioni di grandi dimensioni potenziali nel campo visivo tra HoloLens e auricolari coinvolgente e concreto.</span><span class="sxs-lookup"><span data-stu-id="4cf88-195">When designing UI, keep in mind the potential large variation in field of view between HoloLens and immersive headsets.</span></span>

<span data-ttu-id="4cf88-196">![Un esempio di elementi dell'interfaccia utente raggruppati per più semplice sguardo targeting in Esplora Galaxy](images/gazetargeting-grouping-1000px.jpg)</span><span class="sxs-lookup"><span data-stu-id="4cf88-196">![An example of grouped UI elements for easier gaze targeting in Galaxy Explorer](images/gazetargeting-grouping-1000px.jpg)</span></span><br>
<span data-ttu-id="4cf88-197">*Un esempio di elementi dell'interfaccia utente raggruppati per più semplice sguardo targeting in Esplora Galaxy*</span><span class="sxs-lookup"><span data-stu-id="4cf88-197">*An example of grouped UI elements for easier gaze targeting in Galaxy Explorer*</span></span>

## <a name="improving-targeting-behaviors"></a><span data-ttu-id="4cf88-198">Miglioramento della destinazione dei comportamenti</span><span class="sxs-lookup"><span data-stu-id="4cf88-198">Improving targeting behaviors</span></span>
<span data-ttu-id="4cf88-199">Se l'intenzione dell'utente a un elemento di destinazione può essere determinato o approssimati a stretto contatto, può essere molto utile accettare "near miss" tentativi di interazione come se esse sono destinate in modo corretto.</span><span class="sxs-lookup"><span data-stu-id="4cf88-199">If user intent to target something can be determined (or approximated closely), it can be very helpful to accept "near miss" attempts at interaction as though they were targeted correctly.</span></span> <span data-ttu-id="4cf88-200">Esistono un numero limitato di metodi corretta che può essere incorporato nelle esperienze di realtà mista:</span><span class="sxs-lookup"><span data-stu-id="4cf88-200">There are a handful of successful methods that can be incorporated in mixed reality experiences:</span></span>

### <a name="head-gaze-stabilization-gravity-wells"></a><span data-ttu-id="4cf88-201">Head-sguardo stabilizzazione ("aree di gravità")</span><span class="sxs-lookup"><span data-stu-id="4cf88-201">Head-gaze stabilization ("gravity wells")</span></span>
<span data-ttu-id="4cf88-202">Questa deve essere attiva per la maggior parte/all del tempo.</span><span class="sxs-lookup"><span data-stu-id="4cf88-202">This should be turned on most/all of the time.</span></span> <span data-ttu-id="4cf88-203">Questa tecnica consente di rimuovere l'instabilità head/collo naturale che gli utenti possono avere.</span><span class="sxs-lookup"><span data-stu-id="4cf88-203">This technique removes the natural head/neck jitters that users may have.</span></span> <span data-ttu-id="4cf88-204">Anche lo spostamento a causa dei comportamenti di ricerca/parlando.</span><span class="sxs-lookup"><span data-stu-id="4cf88-204">Also movement due to looking/speaking behaviors.</span></span>

### <a name="closest-link-algorithms"></a><span data-ttu-id="4cf88-205">Algoritmi di collegamento più vicino</span><span class="sxs-lookup"><span data-stu-id="4cf88-205">Closest link algorithms</span></span>
<span data-ttu-id="4cf88-206">Queste funzionano meglio in aree con sparse contenuti interattivi.</span><span class="sxs-lookup"><span data-stu-id="4cf88-206">These work best in areas with sparse interactive content.</span></span> <span data-ttu-id="4cf88-207">Se è presente un'elevata probabilità che è possibile determinare quali un utente ha tentato di interagire con, è possibile integrare la capacità targeting semplicemente assumendo un certo livello di intent.</span><span class="sxs-lookup"><span data-stu-id="4cf88-207">If there is a high probability that you can determine what a user was attempting to interact with, you can supplement their targeting abilities by simply assuming some level of intent.</span></span>

### <a name="backdatingpostdating-actions"></a><span data-ttu-id="4cf88-208">Azioni backdating/postdating</span><span class="sxs-lookup"><span data-stu-id="4cf88-208">Backdating/postdating actions</span></span>
<span data-ttu-id="4cf88-209">Questo meccanismo è utile per le attività che richiedono velocità.</span><span class="sxs-lookup"><span data-stu-id="4cf88-209">This mechanism is useful in tasks requiring speed.</span></span> <span data-ttu-id="4cf88-210">Quando un utente è in movimento attraverso una serie di targeting/attivazione evasive alla velocità, può essere utile per presuppone alcune finalità e consentire mancati passaggi su cui intervenire destinazioni che l'utente ha lo stato attivo leggermente prima o leggermente dopo il tocco (50 ms prima/dopo è rimasto in vigore in test preliminare).</span><span class="sxs-lookup"><span data-stu-id="4cf88-210">When a user is moving through a series of targeting/activation maneuvers at speed, it can be useful to assume some intent and allow missed steps to act upon targets which the user had in focus slightly before or slightly after the tap (50ms before/after was effective in early testing).</span></span>

### <a name="smoothing"></a><span data-ttu-id="4cf88-211">Anti-aliasing</span><span class="sxs-lookup"><span data-stu-id="4cf88-211">Smoothing</span></span>
<span data-ttu-id="4cf88-212">Questo meccanismo è utile per gli spostamenti di ricerca del percorso, riducendo l'instabilità/oscillazione leggero a causa di caratteristiche naturale movimento della testina.</span><span class="sxs-lookup"><span data-stu-id="4cf88-212">This mechanism is useful for pathing movements, reducing the slight jitter/wobble due to natural head movement characteristics.</span></span> <span data-ttu-id="4cf88-213">Quando l'anti-aliasing tramite i movimenti di ricerca del percorso, arrotondare di dimensioni/distanza di spostamenti di tipo invece che nel corso del tempo</span><span class="sxs-lookup"><span data-stu-id="4cf88-213">When smoothing over pathing motions, smooth by size/distance of movements rather than over time</span></span>

### <a name="magnetism"></a><span data-ttu-id="4cf88-214">Campi magnetici</span><span class="sxs-lookup"><span data-stu-id="4cf88-214">Magnetism</span></span>
<span data-ttu-id="4cf88-215">Questo meccanismo può essere considerato come una versione più generale degli algoritmi "Più vicino link" - Creazione di un cursore verso una destinazione o aumentare semplicemente hitboxes (se visibilmente o No) quando gli utenti si avvicinano probabilmente destinazioni, tramite una certa conoscenza del layout interattiva per intenzione dell'utente approccio migliore.</span><span class="sxs-lookup"><span data-stu-id="4cf88-215">This mechanism can be thought of as a more general version of "Closest link" algorithms - drawing a cursor toward a target, or simply increasing hitboxes (whether visibly or not) as users approach likely targets, using some knowledge of the interactive layout to better approach user intent.</span></span> <span data-ttu-id="4cf88-216">Ciò risulta particolarmente utile per le destinazioni di piccole dimensioni.</span><span class="sxs-lookup"><span data-stu-id="4cf88-216">This can be particularly powerful for small targets.</span></span>

### <a name="focus-stickiness"></a><span data-ttu-id="4cf88-217">Persistenza dello stato attivo</span><span class="sxs-lookup"><span data-stu-id="4cf88-217">Focus stickiness</span></span>
<span data-ttu-id="4cf88-218">Quando si determina quale vicino agli elementi interattivi per attivare, fornire un valore di bias all'elemento che è attualmente attivo.</span><span class="sxs-lookup"><span data-stu-id="4cf88-218">When determining which nearby interactive elements to give focus to, provide a bias to the element that is currently focused.</span></span> <span data-ttu-id="4cf88-219">Ciò consentirà di ridurre lo stato attivo imprevedibile cambio comportamenti quando mobile in un punto intermedio tra due elementi con rumore naturale.</span><span class="sxs-lookup"><span data-stu-id="4cf88-219">This will help reduce erratic focus switching behaviours when floating at a midpoint between two elements with natural noise.</span></span>


## <a name="composite-gestures"></a><span data-ttu-id="4cf88-220">Movimenti compositi</span><span class="sxs-lookup"><span data-stu-id="4cf88-220">Composite gestures</span></span>
<span data-ttu-id="4cf88-221">Le App in grado di riconoscere le scelte più di solo i singoli.</span><span class="sxs-lookup"><span data-stu-id="4cf88-221">Apps can recognize more than just individual taps.</span></span> <span data-ttu-id="4cf88-222">Dalla combinazione scelta, tenere premuto e rilasciare con lo spostamento della mano, movimenti compositi più complessi possono essere eseguiti.</span><span class="sxs-lookup"><span data-stu-id="4cf88-222">By combining tap, hold and release with the movement of the hand, more complex composite gestures can be performed.</span></span> <span data-ttu-id="4cf88-223">Questi gesti compositi o ad alto livello si basano su di basso livello inpui dati spaziali (da indice puntato e Bloom) che gli sviluppatori hanno accesso a.</span><span class="sxs-lookup"><span data-stu-id="4cf88-223">These composite or high-level gestures build on the low-level spatial input data (from Air tap and Bloom) that developers have access to.</span></span>

### <a name="air-tap"></a><span data-ttu-id="4cf88-224">Indice puntato</span><span class="sxs-lookup"><span data-stu-id="4cf88-224">Air tap</span></span>
<span data-ttu-id="4cf88-225">Il movimento dell'indice puntato (nonché i movimenti seguenti) reagisce solo a un tocco specifico.</span><span class="sxs-lookup"><span data-stu-id="4cf88-225">The Air tap gesture (as well as the other gestures below) reacts only to a specific tap.</span></span> <span data-ttu-id="4cf88-226">Per rilevare altre scelte, ad esempio Menu o. é quindi, l'app deve usare direttamente le interazioni di basso livello descritte due componenti chiave movimenti in precedenza nella sezione.</span><span class="sxs-lookup"><span data-stu-id="4cf88-226">To detect other taps, such as Menu or Grasp, your app must directly use the lower-level interactions described in two key component gestures section above.</span></span>

### <a name="tap-and-hold"></a><span data-ttu-id="4cf88-227">Toccare e tenere premuto</span><span class="sxs-lookup"><span data-stu-id="4cf88-227">Tap and hold</span></span>
<span data-ttu-id="4cf88-228">Tenere premuto è mantenere semplicemente la posizione di un dito verso il basso dell'indice puntato.</span><span class="sxs-lookup"><span data-stu-id="4cf88-228">Hold is simply maintaining the downward finger position of the air tap.</span></span> <span data-ttu-id="4cf88-229">La combinazione di aria toccare e tenere premuto consente un'ampia gamma di interazioni più complesse "fare clic e trascinare" in combinazione con lo spostamento di gestione risorse di Azure, ad esempio esegue la scelta di un oggetto anziché attivarlo o interazioni secondario "mousedown", ad esempio che mostra un menu di scelta rapida.</span><span class="sxs-lookup"><span data-stu-id="4cf88-229">The combination of air tap and hold allows for a variety of more complex "click and drag" interactions when combined with arm movement such as picking up an object instead of activating it or "mousedown" secondary interactions such as showing a context menu.</span></span>
<span data-ttu-id="4cf88-230">Prestare attenzione quando si progetta per questa azione, tuttavia, come gli utenti può essere soggetta a si rilassa loro maneggevolezza manualmente nel corso di un'operazione estesa.</span><span class="sxs-lookup"><span data-stu-id="4cf88-230">Caution should be used when designing for this gesture however, as users can be prone to relaxing their hand postures during the course of any extended gesture.</span></span>

### <a name="manipulation"></a><span data-ttu-id="4cf88-231">Manipolazione</span><span class="sxs-lookup"><span data-stu-id="4cf88-231">Manipulation</span></span>
<span data-ttu-id="4cf88-232">I movimenti di manipolazione sono utilizzabile per spostare, ridimensionare o ruotare ologramma quando si desidera che l'ologrammi reagire 1:1 per gli spostamenti manuale dell'utente.</span><span class="sxs-lookup"><span data-stu-id="4cf88-232">Manipulation gestures can be used to move, resize or rotate a hologram when you want the hologram to react 1:1 to the user's hand movements.</span></span> <span data-ttu-id="4cf88-233">Un utilizzo di tali spostamenti di tipo 1:1 consiste nel consentire all'utente di disegnare o disegnare nel mondo.</span><span class="sxs-lookup"><span data-stu-id="4cf88-233">One use for such 1:1 movements is to let the user draw or paint in the world.</span></span>
<span data-ttu-id="4cf88-234">La selezione di destinazioni iniziali per un movimento di manipolazione deve essere eseguita da sguardo o fa riferimento.</span><span class="sxs-lookup"><span data-stu-id="4cf88-234">The initial targeting for a manipulation gesture should be done by gaze or pointing.</span></span> <span data-ttu-id="4cf88-235">Una volta avviata la toccare e tenere premuto, qualsiasi modifica dell'oggetto viene quindi gestita manualmente gli spostamenti, liberando Guardatevi intorno mentre che modificano, all'utente.</span><span class="sxs-lookup"><span data-stu-id="4cf88-235">Once the tap and hold starts, any manipulation of the object is then handled by hand movements, freeing the user to look around while they manipulate.</span></span>

### <a name="navigation"></a><span data-ttu-id="4cf88-236">Navigazione</span><span class="sxs-lookup"><span data-stu-id="4cf88-236">Navigation</span></span>
<span data-ttu-id="4cf88-237">Movimenti di esplorazione operano come un joystick virtuale e possono essere utilizzati per spostarsi di widget dell'interfaccia utente, ad esempio menu radiali.</span><span class="sxs-lookup"><span data-stu-id="4cf88-237">Navigation gestures operate like a virtual joystick, and can be used to navigate UI widgets, such as radial menus.</span></span> <span data-ttu-id="4cf88-238">Toccare e tenere premuto per avviare il movimento e quindi spostare la mano all'interno di un cubo 3D normalizzato, incentrata sulla stampa iniziale.</span><span class="sxs-lookup"><span data-stu-id="4cf88-238">You tap and hold to start the gesture and then move your hand within a normalized 3D cube, centered around the initial press.</span></span> <span data-ttu-id="4cf88-239">È possibile spostare la mano lungo l'asse X, Y o Z da un valore pari a -1 a 1, dove 0 è il punto di partenza.</span><span class="sxs-lookup"><span data-stu-id="4cf88-239">You can move your hand along the X, Y or Z axis from a value of -1 to 1, with 0 being the starting point.</span></span>
<span data-ttu-id="4cf88-240">Navigazione utilizzabile per compilare in base al relativo alla velocità lo scorrimento continuo o i movimenti zoom, simili alla visualizzazione a scorrimento un'interfaccia utente 2D facendo clic sul pulsante centrale del mouse e quindi spostando il puntatore del mouse su e giù.</span><span class="sxs-lookup"><span data-stu-id="4cf88-240">Navigation can be used to build velocity-based continuous scrolling or zooming gestures, similar to scrolling a 2D UI by clicking the middle mouse button and then moving the mouse up and down.</span></span>

<span data-ttu-id="4cf88-241">Navigazione con rails si riferisce alla capacità di riconoscere gli spostamenti in determinati asse fino al raggiungimento di determinate soglia su quell'asse.</span><span class="sxs-lookup"><span data-stu-id="4cf88-241">Navigation with rails refers to the ability of recognizing movements in certain axis until certain threshold is reached on that axis.</span></span> <span data-ttu-id="4cf88-242">Ciò è utile, solo quando lo spostamento in più di un asse è abilitato in un'applicazione dallo sviluppatore, ad esempio, se un'applicazione è configurata per riconoscere i movimenti di navigazione tra asse Y X, ma anche specificata con rails asse X.</span><span class="sxs-lookup"><span data-stu-id="4cf88-242">This is only useful, when movement in more than one axis is enabled in an application by the developer, e.g. if an application is configured to recognize navigation gestures across X, Y axis but also specified X axis with rails.</span></span> <span data-ttu-id="4cf88-243">In questo caso sistema riconoscerà mano gli spostamenti tra asse X fino a quando rimangono all'interno di un immaginario Guide (Guida) dell'asse X se lo spostamento di disponibilità si verifica anche asse Y.</span><span class="sxs-lookup"><span data-stu-id="4cf88-243">In this case system will recognize hand movements across X axis as long as they remain within an imaginary rails (guide) on X axis, if hand movement also occurs Y axis.</span></span>

<span data-ttu-id="4cf88-244">All'interno delle App 2D, gli utenti possono usare i movimenti di spostamento verticale a scorrere, eseguire lo zoom avanti o trascinare all'interno dell'app.</span><span class="sxs-lookup"><span data-stu-id="4cf88-244">Within 2D apps, users can use vertical navigation gestures to scroll, zoom, or drag inside the app.</span></span> <span data-ttu-id="4cf88-245">Questo viene inserito virtuale con un dito tocca all'app per simulare i movimenti tocco dello stesso tipo.</span><span class="sxs-lookup"><span data-stu-id="4cf88-245">This injects virtual finger touches to the app to simulate touch gestures of the same type.</span></span> <span data-ttu-id="4cf88-246">Gli utenti possono selezionare le azioni avvengono attivando e disattivando tra gli strumenti della barra di sopra dell'app, selezionando il pulsante o indicante che '< scorrimento/trascinare/> dello zoom'.</span><span class="sxs-lookup"><span data-stu-id="4cf88-246">Users can select which of these actions take place by toggling between the tools on the bar above the app, either by selecting the button or saying '<Scroll/Drag/Zoom> Tool'.</span></span>

[<span data-ttu-id="4cf88-247">Altre informazioni sui movimenti compositi</span><span class="sxs-lookup"><span data-stu-id="4cf88-247">More info on composite gestures</span></span>](gestures.md#composite-gestures)

## <a name="gesture-recognizers"></a><span data-ttu-id="4cf88-248">Riconoscitori di movimento</span><span class="sxs-lookup"><span data-stu-id="4cf88-248">Gesture recognizers</span></span>

<span data-ttu-id="4cf88-249">Un vantaggio dell'utilizzo di riconoscimento del movimento è che è possibile configurare un riconoscitore di movimento solo per i movimenti che di destinazione corrente ologrammi possono accettare.</span><span class="sxs-lookup"><span data-stu-id="4cf88-249">One benefit of using gesture recognition is that you can configure a gesture recognizer just for the gestures the currently targeted hologram can accept.</span></span> <span data-ttu-id="4cf88-250">La piattaforma verrà eseguita solo la risoluzione dell'ambiguità necessarie per distinguere questi gesti supportati particolari.</span><span class="sxs-lookup"><span data-stu-id="4cf88-250">The platform will do only the disambiguation necessary to distinguish those particular supported gestures.</span></span> <span data-ttu-id="4cf88-251">In questo modo, ologramma che supporta solo l'indice puntato può accettare qualsiasi periodo di tempo tra pressione e rilascio, mentre un ologrammi che supporta sia toccare e tenere premuto possibile alzare di livello il tocco per l'attesa dopo la soglia di tempo di attesa.</span><span class="sxs-lookup"><span data-stu-id="4cf88-251">That way, a hologram that just supports air tap can accept any length of time between press and release, while a hologram that supports both tap and hold can promote the tap to a hold after the hold time threshold.</span></span>

## <a name="hand-recognition"></a><span data-ttu-id="4cf88-252">Riconoscimento di mano</span><span class="sxs-lookup"><span data-stu-id="4cf88-252">Hand recognition</span></span>
<span data-ttu-id="4cf88-253">HoloLens riconosce i movimenti della mano per rilevare la posizione di una o entrambe le mani visibili al dispositivo.</span><span class="sxs-lookup"><span data-stu-id="4cf88-253">HoloLens recognizes hand gestures by tracking the position of either or both hands that are visible to the device.</span></span> <span data-ttu-id="4cf88-254">HoloLens vede le mani quando sono in stato ready (parte posteriore l'icona della mano è rivolta con dito indice) o lo stato di premuto (parte posteriore l'icona della mano rivolta verso il basso è il dito indice).</span><span class="sxs-lookup"><span data-stu-id="4cf88-254">HoloLens sees hands when they are in either the ready state (back of the hand facing you with index finger up) or the pressed state (back of the hand facing you with the index finger down).</span></span> <span data-ttu-id="4cf88-255">Quando sono in altri può causare, di HoloLens tali file verranno ignorati.</span><span class="sxs-lookup"><span data-stu-id="4cf88-255">When hands are in other poses, the HoloLens will ignore them.</span></span>
<span data-ttu-id="4cf88-256">Per ogni indicatore rileva tale HoloLens, è possibile accedere alla posizione (senza l'orientamento) e il relativo stato premuto.</span><span class="sxs-lookup"><span data-stu-id="4cf88-256">For each hand that HoloLens detects, you can access its position (without orientation) and its pressed state.</span></span> <span data-ttu-id="4cf88-257">Quando l'icona della mano si avvicina il bordo della cornice di movimento, ha anche fornito con un vettore di direzione, è possibile mostrare all'utente in modo che sappia come spostare le mani per ottenerlo di nuovo in cui HoloLens può visualizzarlo.</span><span class="sxs-lookup"><span data-stu-id="4cf88-257">As the hand nears the edge of the gesture frame, you're also provided with a direction vector, which you can show to the user so they know how to move their hand to get it back where HoloLens can see it.</span></span>

## <a name="gesture-frame"></a><span data-ttu-id="4cf88-258">Frame di movimento</span><span class="sxs-lookup"><span data-stu-id="4cf88-258">Gesture frame</span></span>
<span data-ttu-id="4cf88-259">Per movimenti su HoloLens, l'icona della mano deve essere all'interno di un"movimento", in un intervallo che il rilevamento del movimento fotocamere possono visualizzare in modo appropriato (molto più o meno da naso vita e tra ricade).</span><span class="sxs-lookup"><span data-stu-id="4cf88-259">For gestures on HoloLens, the hand must be within a “gesture frame”, in a range that the gesture-sensing cameras can see appropriately (very roughly from nose to waist, and between the shoulders).</span></span> <span data-ttu-id="4cf88-260">Gli utenti devono essere sottoposti a training su un'area del riconoscimento per l'esito positivo dell'azione e per i propri comfort (molti utenti inizialmente presupporrà che il frame di movimento deve essere entro la visualizzazione tramite HoloLens e contenere le armi uncomfortably per interagire).</span><span class="sxs-lookup"><span data-stu-id="4cf88-260">Users need to be trained on this area of recognition both for success of action and for their own comfort (many users will initially assume that the gesture frame must be within their view through HoloLens, and hold their arms up uncomfortably in order to interact).</span></span> <span data-ttu-id="4cf88-261">Quando si usa il HoloLens Clicker, subito a usare non è necessario essere all'interno della cornice di movimento.</span><span class="sxs-lookup"><span data-stu-id="4cf88-261">When using the HoloLens Clicker, your hands do not need to be within the gesture frame.</span></span>

<span data-ttu-id="4cf88-262">Nel caso di movimenti continuati, in particolare, vi è alcuni rischi correlati agli utenti lo spostamento le mani fuori dalla cornice movimenti mentre è in movimento a metà (durante lo spostamento di un determinato oggetto holographic, ad esempio) e la perdita di base al risultato desiderato.</span><span class="sxs-lookup"><span data-stu-id="4cf88-262">In the case of continuous gestures in particular, there is some risk of users moving their hands outside of the gesture frame while in mid-gesture (while moving some holographic object, for example), and losing their intended outcome.</span></span>

<span data-ttu-id="4cf88-263">Esistono tre aspetti da considerare:</span><span class="sxs-lookup"><span data-stu-id="4cf88-263">There are three things that you should consider:</span></span>

- <span data-ttu-id="4cf88-264">Formazione dell'utente del movimento frame esistenza e limiti approssimativi (tenuto durante l'installazione di HoloLens).</span><span class="sxs-lookup"><span data-stu-id="4cf88-264">User education on the gesture frame's existence and approximate boundaries (this is taught during HoloLens setup).</span></span>

- <span data-ttu-id="4cf88-265">Informare gli utenti quando i movimenti sono prossime alla/sostanziale i limiti di intervallo movimento all'interno di un'applicazione, come accade in un movimento perso porterà a risultati indesiderati.</span><span class="sxs-lookup"><span data-stu-id="4cf88-265">Notifying users when their gestures are nearing/breaking the gesture frame boundaries within an application, to the degree that a lost gesture will lead to undesired outcomes.</span></span> <span data-ttu-id="4cf88-266">Research ha illustrato le qualità di chiave di un sistema di notifica e la shell di HoloLens fornisce un buon esempio di questo tipo di notifica (visual, sul cursore centrale, che indica la direzione nella quale limite attraversamento è in corso).</span><span class="sxs-lookup"><span data-stu-id="4cf88-266">Research has shown the key qualities of such a notification system, and the HoloLens shell provides a good example of this type of notification (visual, on the central cursor, indicating the direction in which boundary crossing is taking place).</span></span>

- <span data-ttu-id="4cf88-267">Conseguenze di compromettere il funzionamento i limiti di frame di movimento dovrebbero essere ridotta a icona.</span><span class="sxs-lookup"><span data-stu-id="4cf88-267">Consequences of breaking the gesture frame boundaries should be minimized.</span></span> <span data-ttu-id="4cf88-268">In genere, ciò significa che il risultato di un movimento deve essere arrestato in corrispondenza del limite, ma non invertito.</span><span class="sxs-lookup"><span data-stu-id="4cf88-268">In general, this means that the outcome of a gesture should be stopped at the boundary, but not reversed.</span></span> <span data-ttu-id="4cf88-269">Ad esempio, se un utente sta spostando un oggetto holographic attraverso una chat room, lo spostamento deve essere interrotta quando viene superata la cornice di movimento, ma non verranno restituita al punto di partenza.</span><span class="sxs-lookup"><span data-stu-id="4cf88-269">For example, if a user is moving some holographic object across a room, movement should stop when the gesture frame is breached, but not be returned to the starting point.</span></span> <span data-ttu-id="4cf88-270">L'utente potrebbe esperienza alcuni frustrazione, ma può comprendere più rapidamente i limiti e non è necessario riavviare le azioni desiderate complete ogni volta che.</span><span class="sxs-lookup"><span data-stu-id="4cf88-270">The user may experience some frustration then, but may more quickly understand the boundaries, and not have to restart their full intended actions each time.</span></span>


## <a name="see-also"></a><span data-ttu-id="4cf88-271">Vedere anche</span><span class="sxs-lookup"><span data-stu-id="4cf88-271">See also</span></span>
* [<span data-ttu-id="4cf88-272">Manipolazione diretta con le mani</span><span class="sxs-lookup"><span data-stu-id="4cf88-272">Direct manipulation with hands</span></span>](direct-manipulation.md)
* [<span data-ttu-id="4cf88-273">Puntamento e commit con le mani</span><span class="sxs-lookup"><span data-stu-id="4cf88-273">Point and commit with hands</span></span>](point-and-commit.md)
* [<span data-ttu-id="4cf88-274">Interazioni istintive</span><span class="sxs-lookup"><span data-stu-id="4cf88-274">Instinctual interactions</span></span>](interaction-fundamentals.md)
* [<span data-ttu-id="4cf88-275">Puntamento con la testa e attesa</span><span class="sxs-lookup"><span data-stu-id="4cf88-275">Head-gaze and dwell</span></span>](gaze-and-dwell.md)
* [<span data-ttu-id="4cf88-276">Esecuzione di comandi vocali</span><span class="sxs-lookup"><span data-stu-id="4cf88-276">Voice commanding</span></span>](voice-design.md)





