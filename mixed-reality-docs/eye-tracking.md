---
title: Sotto controllo di rilevamento
description: Sotto controllo di rilevamento
author: sostel
ms.author: sostel
ms.date: 04/05/2019
ms.topic: article
ms.localizationpriority: high
keywords: Rilevamento rossi, mista realtà, Input, sguardo sotto controllo
ms.openlocfilehash: d41b9973ede323e842d7187becb1220ba9980a5d
ms.sourcegitcommit: 5b4292ef786447549c0199003e041ca48bb454cd
ms.translationtype: MT
ms.contentlocale: it-IT
ms.lasthandoff: 05/30/2019
ms.locfileid: "66402355"
---
# <a name="eye-tracking-on-hololens-2"></a><span data-ttu-id="80217-104">Occhio rilevamento su HoloLens 2</span><span class="sxs-lookup"><span data-stu-id="80217-104">Eye tracking on HoloLens 2</span></span>
<span data-ttu-id="80217-105">HoloLens 2 consente un livello completamente nuovo di contesto e informazioni sulle risorse umane all'interno di Holographic esperienza, offrendo agli sviluppatori la possibilità straordinaria con informazioni su ciò che siano esaminando gli utenti.</span><span class="sxs-lookup"><span data-stu-id="80217-105">HoloLens 2 allows for a whole new level of context and human understanding within the Holographic experience by providing developers with the incredible ability of using information about what users are looking at.</span></span> <span data-ttu-id="80217-106">Questa pagina offre una panoramica del modo in cui gli sviluppatori possono trarre vantaggio dal rilevamento di occhio per diversi casi d'uso e gli elementi da cercare durante la progettazione di interfacce utente basate su occhio-sguardo.</span><span class="sxs-lookup"><span data-stu-id="80217-106">This page gives an overview of how developers can benefit from eye tracking for various use cases and what to look out for when designing eye-gaze-based user interfaces.</span></span> 

## <a name="use-cases"></a><span data-ttu-id="80217-107">Casi di utilizzo</span><span class="sxs-lookup"><span data-stu-id="80217-107">Use cases</span></span>
<span data-ttu-id="80217-108">Occhio rilevamento consente alle applicazioni di rilevare dove sta guardando l'utente in tempo reale.</span><span class="sxs-lookup"><span data-stu-id="80217-108">Eye tracking enables applications to track where the user is looking in real time.</span></span> <span data-ttu-id="80217-109">In questa sezione descrive alcune delle possibili casi di utilizzo e le interazioni innovative che diventano possibili con sotto controllo di rilevamento nella realtà mista.</span><span class="sxs-lookup"><span data-stu-id="80217-109">This section describes some of the potential use cases and novel interactions that become possible with eye tracking in mixed reality.</span></span>
<span data-ttu-id="80217-110">Prima di iniziare, in quanto segue si indicano che il [Toolkit di realtà mista](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) più volte poiché fornisce alcuni esempi interessanti e potenti per l'uso del rilevamento sotto controllo, ad esempio destinazione supportata occhio semplificata e veloce le selezioni e automaticamente lo scorrimento di base in cui l'utente è simile al testo.</span><span class="sxs-lookup"><span data-stu-id="80217-110">Before getting started, in the following we will mention the [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) several times as it provides several interesting and powerful examples for using eye tracking such as quick and effortless eye-supported target selections and automatically scrolling through text based on where the user looks at.</span></span> 

### <a name="user-intent"></a><span data-ttu-id="80217-111">Intenzioni dell'utente</span><span class="sxs-lookup"><span data-stu-id="80217-111">User intent</span></span>    
<span data-ttu-id="80217-112">Informazioni su dove un utente esamina forniscono una potente **contesto per gli altri input**, ad esempio voce, mani e controller.</span><span class="sxs-lookup"><span data-stu-id="80217-112">Information about where a user looks at provides a powerful **context for other inputs**, such as voice, hands and controllers.</span></span>
<span data-ttu-id="80217-113">Può essere utilizzato per diverse attività.</span><span class="sxs-lookup"><span data-stu-id="80217-113">This can be used for various tasks.</span></span>
<span data-ttu-id="80217-114">Ad esempio, la soluzione può variare da rapidamente e facilmente **targeting** tra la scena semplicemente esaminando un ologrammi e che indica che "select" (vedere anche [Head sguardo ed eseguire il commit](gaze-and-commit.md)) o pronunciando "put questo...", quindi ricerca di in cui si desidera posizionare l'ologrammi e scelgo "... There".</span><span class="sxs-lookup"><span data-stu-id="80217-114">For example, this may range from quickly and effortlessly **targeting** across the scene by simply looking at a hologram and saying "select" (also see [Head-gaze and commit](gaze-and-commit.md)) or by saying "put this...", then looking over to where you want to place the hologram and say "...there".</span></span> <span data-ttu-id="80217-115">Esempi per questo sono reperibile nel [Toolkit realtà mista - supportata sotto controllo la selezione di destinazione](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html) e [Toolkit di realtà mista - supportata sotto controllo il posizionamento di destinazione](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html).</span><span class="sxs-lookup"><span data-stu-id="80217-115">Examples for this can be found in [Mixed Reality Toolkit - Eye-supported Target Selection](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html) and [Mixed Reality Toolkit - Eye-supported Target Positioning](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html).</span></span>

<span data-ttu-id="80217-116">Un altro esempio per le intenzioni dell'utente può includere l'uso di informazioni su cosa esaminano gli utenti per migliorare la collaborazione con gli agenti virtuali integrati e vntana interattiva.</span><span class="sxs-lookup"><span data-stu-id="80217-116">An additional example for user intent may include using information about what users look at to enhance the engagement with embodied virtual agents and interactive holograms.</span></span> <span data-ttu-id="80217-117">Ad esempio, gli agenti virtuali possono adattare le opzioni disponibili e il comportamento di base attualmente visualizzato il contenuto.</span><span class="sxs-lookup"><span data-stu-id="80217-117">For example, virtual agents may adapt available options and their behavior based on currently viewed content.</span></span> 

### <a name="implicit-actions"></a><span data-ttu-id="80217-118">Azioni implicite</span><span class="sxs-lookup"><span data-stu-id="80217-118">Implicit actions</span></span>
<span data-ttu-id="80217-119">La categoria di azioni implicite è strettamente correlato al intenzione dell'utente.</span><span class="sxs-lookup"><span data-stu-id="80217-119">The category of implicit actions closely relates to user intent.</span></span>
<span data-ttu-id="80217-120">L'idea è che gli elementi dell'interfaccia utente o vntana reagiscono in modo abbastanza instinctual potrebbe non ancora percepisca si interagisce con il sistema affatto, ma piuttosto che il sistema e l'utente siano sincronizzati. Ad esempio, è un esempio estremamente ha esito positivo **scorrimento automatico basati su occhio-sguardo**.</span><span class="sxs-lookup"><span data-stu-id="80217-120">The idea is that holograms or user interface elements react in a somewhat instinctual way that may not even feel like you are interacting with the system at all, but rather that the system and the user are in sync. For example, one immensely successful example is **eye-gaze-based auto scroll**.</span></span> <span data-ttu-id="80217-121">L'idea è semplice: L'utente legge un testo e appena possibile continuare la lettura.</span><span class="sxs-lookup"><span data-stu-id="80217-121">The idea is as simple: The user reads a text and can just keep on reading.</span></span> <span data-ttu-id="80217-122">Il testo gradualmente sposta verso l'alto mantenere gli utenti nel flusso di lettura.</span><span class="sxs-lookup"><span data-stu-id="80217-122">The text gradually moves up to keep users in their reading flow.</span></span> <span data-ttu-id="80217-123">Un aspetto fondamentale è che la velocità di scorrimento si adatta per la velocità di lettura dell'utente.</span><span class="sxs-lookup"><span data-stu-id="80217-123">A key aspect is that the scrolling speed adapts to the reading speed of the user.</span></span>
<span data-ttu-id="80217-124">Un altro esempio è **supportato sotto controllo di scorrimento e zoom** per cui l'utente può agiscono come entrare verso esattamente ciò che direste viene messa a fuoco in.</span><span class="sxs-lookup"><span data-stu-id="80217-124">Another example is **eye-supported zoom and pan** for which the user can feel like diving exactly toward what he or she is focusing at.</span></span> <span data-ttu-id="80217-125">Attivare lo zoom e controllando la velocità di zoom può essere controllate tramite vocali o passare input che è importante fornire la sensazione di controllo ed evitare di sovraccaricare l'utente (si discuterà queste linee guida di progettazione in dettaglio più avanti).</span><span class="sxs-lookup"><span data-stu-id="80217-125">Triggering the zoom and controlling the zoom speed can be controlled via voice or hand input which is important about providing the feeling of control and avoid overwhelming the user (we will talk about these design guidelines in more detail below).</span></span> <span data-ttu-id="80217-126">Dopo lo zoom avanti, l'utente può quindi in modo uniforme seguire, ad esempio, il corso di una via e numero civico esplorazione nodi vicini alla propria semplicemente con loro sguardo sotto controllo.</span><span class="sxs-lookup"><span data-stu-id="80217-126">Once zoomed in, the user can then smoothly follow, for example, the course of a street to explore his or her neighborhood just simply by using their eye gaze.</span></span>
<span data-ttu-id="80217-127">Esempi di demo per questi tipi di interazioni possono essere individuati nel [Toolkit realtà mista - navigazione supportate occhio](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html) esempio.</span><span class="sxs-lookup"><span data-stu-id="80217-127">Demo examples for these types of interactions can be found in the [Mixed Reality Toolkit - Eye-supported Navigation](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html) sample.</span></span>

<span data-ttu-id="80217-128">Per casi di utilizzo di ulteriori _implicite azioni_ possono includere:</span><span class="sxs-lookup"><span data-stu-id="80217-128">Additional use cases for _implicit actions_ may include:</span></span>
- <span data-ttu-id="80217-129">**Notifiche intelligente:** Mai ottenere infastidita dal notifiche si estraggono in alto a destra in cui erano messa a fuoco?</span><span class="sxs-lookup"><span data-stu-id="80217-129">**Smart notifications:** Ever get annoyed by notifications popping up right where you were focusing?</span></span> <span data-ttu-id="80217-130">Prendendo in considerazione in cui un utente è attualmente prestando attenzione a, è possibile renderlo migliori!</span><span class="sxs-lookup"><span data-stu-id="80217-130">Taking into account where a user is currently paying attention to, you can make it better!</span></span> <span data-ttu-id="80217-131">Visualizzare le notifiche di offset da cui attualmente sta guardando l'utente per limitare gli elementi di distrazione e automaticamente non prenderli in considerazione una volta terminata la lettura.</span><span class="sxs-lookup"><span data-stu-id="80217-131">Show notifications offset from where the user is currently looking to limit distractions and automatically dismiss them once finished reading.</span></span> 
- <span data-ttu-id="80217-132">**Accurata vntana:** Ologrammi che reagiscono leggermente quando viene preso in esame.</span><span class="sxs-lookup"><span data-stu-id="80217-132">**Attentive holograms:** Holograms that subtly react when being looked at.</span></span> <span data-ttu-id="80217-133">Questo può variare da leggermente brillanti elementi dell'interfaccia utente, un lenta blooming fiore al virtuale un avvio animali domestici riesaminare si o tenta di evitare lo sguardo occhio dopo un prolungato limita ad assistere passivamente.</span><span class="sxs-lookup"><span data-stu-id="80217-133">This may range from slightly glowing UI elements, a slowly blooming flower to a virtual pet starting to look back at you or trying to avoid your eye gaze after a prolonged stare.</span></span> <span data-ttu-id="80217-134">Questo può fornire un'idea interessante di connettività e la soddisfazione degli utenti all'app.</span><span class="sxs-lookup"><span data-stu-id="80217-134">This may provide an interesting sense of connectivity and satisfaction in your app.</span></span>

### <a name="attention-tracking"></a><span data-ttu-id="80217-135">Attenzione di rilevamento</span><span class="sxs-lookup"><span data-stu-id="80217-135">Attention tracking</span></span>   
<span data-ttu-id="80217-136">Informazioni su dove gli utenti guardano sono uno strumento estremamente potente per valutare l'usabilità di progettazioni e identificare eventuali problemi nei flussi di lavoro efficienti.</span><span class="sxs-lookup"><span data-stu-id="80217-136">Information about where users look at is an immensely powerful tool to assess usability of designs and to identify problems in efficient work streams.</span></span> <span data-ttu-id="80217-137">A questo punto, occhio analitica e visualizzazione di rilevamento è già presenti una pratica comune nelle diverse aree dell'applicazione.</span><span class="sxs-lookup"><span data-stu-id="80217-137">By now,  eye tracking visualization and analytics are already a common practice in various application areas.</span></span> <span data-ttu-id="80217-138">Con 2 HoloLens, offriamo una nuova dimensione per questa conoscenza come vntana 3D può essere inserito in contesti reali e valutate insieme.</span><span class="sxs-lookup"><span data-stu-id="80217-138">With HoloLens 2, we provide a new dimension to this understanding as 3D holograms can be placed in real-world contexts and assessed alongside.</span></span> <span data-ttu-id="80217-139">Il [Toolkit di realtà mista](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) fornisce esempi di base per la registrazione e il caricamento sotto controllo i dati di rilevamento e come visualizzarle.</span><span class="sxs-lookup"><span data-stu-id="80217-139">The [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) provides basic examples for logging and loading eye tracking data and for how to visualize them.</span></span>

<span data-ttu-id="80217-140">Altre applicazioni in quest'area possono includere:</span><span class="sxs-lookup"><span data-stu-id="80217-140">Other applications in this area may include:</span></span> 
-   <span data-ttu-id="80217-141">**Visualizzazione di sguardo sotto controllo remoto:** Visualizzare ciò che i collaboratori remoti siano esaminando, ad esempio, verificare se le istruzioni vengono riconosciute correttamente e seguite.</span><span class="sxs-lookup"><span data-stu-id="80217-141">**Remote eye gaze visualization:** Visualize what remote collaborators are looking at to, for example, ensure whether instructions are correctly understood and followed.</span></span>
-   <span data-ttu-id="80217-142">**Ricerche di utente:** Attenzione rilevamento utilizzabile per esplorare il modo principiante o gli utenti esperti analizzare visivamente contenuto o il coordinamento di occhio mano per attività complesse (ad esempio, per l'analisi dei dati medici o l'utilizzo della macchina).</span><span class="sxs-lookup"><span data-stu-id="80217-142">**User research studies:** Attention tracking can be used to explore the way novice vs. experts users visually analyze content or their hand-eye-coordination for complex tasks (e.g., for analysis of medical data or while operating machinery).</span></span>
-   <span data-ttu-id="80217-143">**Le simulazioni di training e il monitoraggio delle prestazioni:** Fare pratica e ottimizzare l'esecuzione di attività che identifica i colli di bottiglia in modo più efficace nel flusso di esecuzione.</span><span class="sxs-lookup"><span data-stu-id="80217-143">**Training simulations and Performance monitoring:** Practice and optimize the execution of tasks by identifying bottlenecks more effectively in the execution flow.</span></span>
-   <span data-ttu-id="80217-144">**Progettare le valutazioni, annunci e la ricerca di mercato:** Sotto controllo di rilevamento è uno strumento comune per la ricerca di mercato per la valutazione di progettazioni del prodotto e il sito Web.</span><span class="sxs-lookup"><span data-stu-id="80217-144">**Design evaluations, advertisement and marketing research:** Eye tracking is a common tool for market research to evaluate website and product designs.</span></span>

### <a name="additional-use-cases"></a><span data-ttu-id="80217-145">Casi d'uso aggiuntive</span><span class="sxs-lookup"><span data-stu-id="80217-145">Additional use cases</span></span>
- <span data-ttu-id="80217-146">**Modalità di gioco:** Mai desiderato di sono così sofisticate come?</span><span class="sxs-lookup"><span data-stu-id="80217-146">**Gaming:** Ever wanted to have superpowers?</span></span> <span data-ttu-id="80217-147">Qui è un'opportunità!</span><span class="sxs-lookup"><span data-stu-id="80217-147">Here's your chance!</span></span> <span data-ttu-id="80217-148">Levitate vntana tempi a tali file.</span><span class="sxs-lookup"><span data-stu-id="80217-148">Levitate holograms by staring at them.</span></span> <span data-ttu-id="80217-149">Risolvere i raggi laser dagli occhi.</span><span class="sxs-lookup"><span data-stu-id="80217-149">Shoot laser beams from your eyes.</span></span> <span data-ttu-id="80217-150">Trasforma nemici in stone o Bloccale!</span><span class="sxs-lookup"><span data-stu-id="80217-150">Turn enemies into stone or freeze them!</span></span> <span data-ttu-id="80217-151">Usare le tue nuove idee x-ray per esplorare gli edifici.</span><span class="sxs-lookup"><span data-stu-id="80217-151">Use your x-ray vision to explore buildings.</span></span> <span data-ttu-id="80217-152">Il limite è la tua immaginazione.</span><span class="sxs-lookup"><span data-stu-id="80217-152">Your imagination is the limit!</span></span>  

- <span data-ttu-id="80217-153">**Avatar espressivi:** Rilevamento facilita gli avatar 3D più espressivi mediante live sotto controllo Data di rilevamento per animare gli occhi dell'avatar per indicare quali l'utente è attualmente esaminando sotto controllo.</span><span class="sxs-lookup"><span data-stu-id="80217-153">**Expressive avatars:** Eye tracking aids in more expressive 3D avatars by using live eye tracking date to animate the avatar's eyes to indicate what the user is currently looking at.</span></span> <span data-ttu-id="80217-154">Aggiunge anche ulteriori espressività aggiungendo animoticon e lampeggia.</span><span class="sxs-lookup"><span data-stu-id="80217-154">It also adds more expressiveness by adding winks and blinks.</span></span> 

- <span data-ttu-id="80217-155">**Immissione di testo:** Sotto controllo di rilevamento è utilizzabile come un'alternativa interessante per l'immissione di testo di tutti i tentativi bassa soprattutto quando vocale o mani sono facili da usare.</span><span class="sxs-lookup"><span data-stu-id="80217-155">**Text entry:** Eye tracking can be used as an interesting alternative for low-effort text entry especially when speech or hands are inconvenient to use.</span></span> 


## <a name="eye-tracking-api"></a><span data-ttu-id="80217-156">API rilevamento sotto controllo</span><span class="sxs-lookup"><span data-stu-id="80217-156">Eye tracking API</span></span>
<span data-ttu-id="80217-157">Prima di entrare nei dettagli sulle linee guida di progettazione specifiche per l'interazione visiva, si vuole scegliere brevemente le funzionalità che fornisce lo strumento di rilevamento di HoloLens 2 sotto controllo.</span><span class="sxs-lookup"><span data-stu-id="80217-157">Before going into detail about the specific design guidelines for eye-gaze interaction, we want to briefly point to the capabilities that the HoloLens 2 Eye Tracker is providing.</span></span> <span data-ttu-id="80217-158">Il [API di rilevamento occhio](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose) è accessibile tramite: `Windows.Perception.People.EyesPose`.</span><span class="sxs-lookup"><span data-stu-id="80217-158">The [Eye Tracking API](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose) is accessible through: `Windows.Perception.People.EyesPose`.</span></span> <span data-ttu-id="80217-159">Fornisce un raggio di sguardo occhio single (sguardo origine e la direzione) per gli sviluppatori.</span><span class="sxs-lookup"><span data-stu-id="80217-159">It provides a single eye gaze ray (gaze origin and direction) to developers.</span></span>
<span data-ttu-id="80217-160">Lo strumento di rilevamento occhio offra dati con sui _30 FPS_.</span><span class="sxs-lookup"><span data-stu-id="80217-160">The eye tracker provides data at about _30 FPS_.</span></span>
<span data-ttu-id="80217-161">Sguardo l'occhio stimato si trova all'interno di autorità di certificazione.</span><span class="sxs-lookup"><span data-stu-id="80217-161">The predicted eye gaze lies within ca.</span></span> <span data-ttu-id="80217-162">1.0-1,5 gradi in angolo visual tutto l'effettivo stato destinazione.</span><span class="sxs-lookup"><span data-stu-id="80217-162">1.0 - 1.5 degrees in visual angle around the actual looked at target.</span></span> <span data-ttu-id="80217-163">Sono previste le imprecisioni leggere, è consigliabile pianificare per alcuni dei margini intorno a questo valore limite inferiore.</span><span class="sxs-lookup"><span data-stu-id="80217-163">As slight imprecisions are expected, you should plan for some margin around this lower bound value.</span></span> <span data-ttu-id="80217-164">È questo aspetto verrà esaminato più seguito.</span><span class="sxs-lookup"><span data-stu-id="80217-164">We will discuss this more below.</span></span> <span data-ttu-id="80217-165">Per occhio per lavorare in modo accurato di rilevamento, ogni utente deve passare attraverso un occhio calibrazione utente di rilevamento.</span><span class="sxs-lookup"><span data-stu-id="80217-165">For eye tracking to work accurately, each user is required to go through an eye tracking user calibration.</span></span> 

<span data-ttu-id="80217-166">![Dimensioni di destinazione ottimale a distanza di 2 metri](images/gazetargeting-size-1000px.jpg)</span><span class="sxs-lookup"><span data-stu-id="80217-166">![Optimal target size at 2 meter distance](images/gazetargeting-size-1000px.jpg)</span></span><br>
<span data-ttu-id="80217-167">*Dimensioni di destinazione ottimale a distanza di 2 metri*</span><span class="sxs-lookup"><span data-stu-id="80217-167">*Optimal target size at 2 meter distance*</span></span>


## <a name="eye-gaze-design-guidelines"></a><span data-ttu-id="80217-168">Linee guida di progettazione sguardo sotto controllo</span><span class="sxs-lookup"><span data-stu-id="80217-168">Eye gaze design guidelines</span></span>
<span data-ttu-id="80217-169">Compilazione di un'interazione che sfrutta veloce come destinazione rossi mobile può risultare complessa.</span><span class="sxs-lookup"><span data-stu-id="80217-169">Building an interaction that takes advantage of fast moving eye targeting can be challenging.</span></span> <span data-ttu-id="80217-170">In questa sezione sono riepilogati i principali vantaggi e problematiche da prendere in considerazione quando si progetta l'app.</span><span class="sxs-lookup"><span data-stu-id="80217-170">In this section, we summarize the key advantages and challenges to take into account when designing your app.</span></span> 

### <a name="benefits-of-eye-gaze-input"></a><span data-ttu-id="80217-171">Vantaggi dell'input sguardo sotto controllo</span><span class="sxs-lookup"><span data-stu-id="80217-171">Benefits of eye gaze input</span></span>
- <span data-ttu-id="80217-172">**Che punta ad alta velocità.**</span><span class="sxs-lookup"><span data-stu-id="80217-172">**High speed pointing.**</span></span> <span data-ttu-id="80217-173">Il braccio occhio è il più rapido reacting braccio nel nostro corpo.</span><span class="sxs-lookup"><span data-stu-id="80217-173">The eye muscle is the fastest reacting muscle in our body.</span></span> 

- <span data-ttu-id="80217-174">**Lavoro richiesto basso.**</span><span class="sxs-lookup"><span data-stu-id="80217-174">**Low effort.**</span></span> <span data-ttu-id="80217-175">Attività spostamenti fisici sono necessari.</span><span class="sxs-lookup"><span data-stu-id="80217-175">Barely any physical movements are necessary.</span></span> 

- <span data-ttu-id="80217-176">**Implicitness.**</span><span class="sxs-lookup"><span data-stu-id="80217-176">**Implicitness.**</span></span> <span data-ttu-id="80217-177">Spesso descritti dagli utenti come "presente durante la lettura", informazioni sui movimenti occhi dell'utente consentono al sistema di sapere che per interagire con i piani utente di destinazione.</span><span class="sxs-lookup"><span data-stu-id="80217-177">Often described by users as "mind reading", information about a user's eye movements lets the system know which target the user plans to engage with.</span></span> 

- <span data-ttu-id="80217-178">**Canale di input alternativi.**</span><span class="sxs-lookup"><span data-stu-id="80217-178">**Alternative input channel.**</span></span> <span data-ttu-id="80217-179">Sguardo occhio possibile fornire un input supporto potente per la disponibilità e della voce input compilazione in anni di esperienza di utenti in base al loro coordinamento a forma di mano.</span><span class="sxs-lookup"><span data-stu-id="80217-179">Eye gaze can provide a powerful supporting input for hand and voice input building on years of experience from users based on their hand-eye coordination.</span></span>

- <span data-ttu-id="80217-180">**Visual attenzione.**</span><span class="sxs-lookup"><span data-stu-id="80217-180">**Visual attention.**</span></span> <span data-ttu-id="80217-181">Un altro vantaggio importante è la possibilità di dedurre che ciò che un utente è prestando attenzione a.</span><span class="sxs-lookup"><span data-stu-id="80217-181">Another important benefit is the possibility to infer what a user's is paying attention to.</span></span> <span data-ttu-id="80217-182">Ciò consente in diverse aree dell'applicazione dalla più efficacemente la valutazione di diversi progetti in modo da consentire nelle interfacce utente più intelligenti e avanzata segnali basati su social network per le comunicazioni remote.</span><span class="sxs-lookup"><span data-stu-id="80217-182">This can help in various application areas ranging from more effectively evaluating different designs to aiding in smarter User Interfaces and enhanced social cues for remote communication.</span></span>

<span data-ttu-id="80217-183">In breve, utilizzando sguardo sotto controllo, come un input potenzialmente offre un segnale contesto semplificato e veloce - risulta particolarmente utile in combinazione con altri input, ad esempio *voice* e *manuale* input confermare l'intenzione dell'utente.</span><span class="sxs-lookup"><span data-stu-id="80217-183">In a nutshell, using eye gaze as an input potentially offers a fast and effortless contextual signal - This is particularly powerful in combination with other inputs such as *voice* and *manual* input to confirm the user's intent.</span></span>


### <a name="challenges-of-eye-gaze-as-an-input"></a><span data-ttu-id="80217-184">Difficoltà d'occhio estasiati come input</span><span class="sxs-lookup"><span data-stu-id="80217-184">Challenges of eye gaze as an input</span></span>
<span data-ttu-id="80217-185">Con molta energia, è disponibile un numero elevato di responsabilità: Mentre sguardo sotto controllo può essere utilizzato per creare esperienze utente magici sente, ad esempio un nostro esperto, è anche importante sapere cosa non è valida in account per questo in modo appropriato.</span><span class="sxs-lookup"><span data-stu-id="80217-185">With lots of power, comes lots of responsibility: While eye gaze can be used to create magical user experiences feeling like a superhero, it is also important to know what it is not good at to account for this appropriately.</span></span> <span data-ttu-id="80217-186">Di seguito, verranno illustrate alcune *sfide* per prendere in considerazione e come risolverli quando si lavora con input sguardo occhio:</span><span class="sxs-lookup"><span data-stu-id="80217-186">In the following, we discuss some *challenges* to take into account and how to address them when working with eye gaze input:</span></span> 

- <span data-ttu-id="80217-187">**Lo sguardo occhio è "always on"** nel momento in cui si apre il coperchio sotto controllo, gli occhi avviare fixating operazioni nell'ambiente in uso.</span><span class="sxs-lookup"><span data-stu-id="80217-187">**Your eye gaze is "always on"** The moment you open your eye lids, your eyes start fixating things in your environment.</span></span> <span data-ttu-id="80217-188">Reazione a ogni aspetto creazione ed emissione potenzialmente accidentalmente azioni perché sono stati esaminati svolgere un compito troppo a lungo comporta un'esperienza terribile!</span><span class="sxs-lookup"><span data-stu-id="80217-188">Reacting to every look you make and potentially accidentally issuing actions because you looked at something for too long would result in a terrible experience!</span></span>
<span data-ttu-id="80217-189">È per questo motivo è consigliabile combinare sguardo sotto controllo con un *comandi vocali*, *movimento a mano*, *clic sul pulsante* o permanenza esteso per attivare la selezione di una destinazione.</span><span class="sxs-lookup"><span data-stu-id="80217-189">This is why we recommend combining eye gaze with a *voice command*, *hand gesture*, *button click* or extended dwell to trigger the selection of a target.</span></span>
<span data-ttu-id="80217-190">Questa soluzione consente inoltre di una modalità in cui l'utente può liberamente cercare senza la sensazione eccessivamente elevata di involontariamente l'attivazione di un elemento.</span><span class="sxs-lookup"><span data-stu-id="80217-190">This solution also allows for a mode in which the user can freely look around without the overwhelming feeling of involuntarily triggering something.</span></span> <span data-ttu-id="80217-191">Questo problema deve anche essere tener conto quando si progettano i commenti e suggerimenti visivi e sonori osservando semplicemente una destinazione.</span><span class="sxs-lookup"><span data-stu-id="80217-191">This issue should also be taken into account when designing visual and auditory feedback when merely looking at a target.</span></span>
<span data-ttu-id="80217-192">Non sovraccaricare l'utente con effetto immediato a comparsa o passare il mouse suoni.</span><span class="sxs-lookup"><span data-stu-id="80217-192">Do not overwhelm the user with immediate pop-out effects or hover sounds.</span></span> <span data-ttu-id="80217-193">Importante sottolineare che è fondamentale.</span><span class="sxs-lookup"><span data-stu-id="80217-193">Subtlety is key!</span></span> <span data-ttu-id="80217-194">Verranno illustrate alcune procedure consigliate per questo ulteriormente di seguito quando si parla di suggerimenti per la progettazione.</span><span class="sxs-lookup"><span data-stu-id="80217-194">We will discuss some best practices for this further below when talking about design recommendations.</span></span>

- <span data-ttu-id="80217-195">**Osservazione e controllo** si supponga che si desidera allineare in modo preciso una fotografia alla bacheca.</span><span class="sxs-lookup"><span data-stu-id="80217-195">**Observation vs. control** Imagine you want to precisely align a photograph at your wall.</span></span> <span data-ttu-id="80217-196">Si esamina i bordi e dell'ambiente circostante per vedere se allineato correttamente.</span><span class="sxs-lookup"><span data-stu-id="80217-196">You look at its borders and its surroundings to see if it aligns well.</span></span> <span data-ttu-id="80217-197">Si supponga ora di come si farebbe che quando allo stesso tempo si vuole usare lo sguardo occhio come input a spostare l'immagine.</span><span class="sxs-lookup"><span data-stu-id="80217-197">Now imagine how you would do that when at the same time you want to use your eye gaze as an input to move the picture.</span></span> <span data-ttu-id="80217-198">Difficile, vero?</span><span class="sxs-lookup"><span data-stu-id="80217-198">Difficult, isn't it?</span></span> <span data-ttu-id="80217-199">Questo descrive il ruolo double di sguardo sotto controllo quando è necessario sia per l'input e controllo.</span><span class="sxs-lookup"><span data-stu-id="80217-199">This describes the double role of eye gaze when it is required both for input and control.</span></span> 

- <span data-ttu-id="80217-200">**Uscire dalla prima di fare clic su:** Per le selezioni di destinazione rapide, la ricerca ha dimostrato che sguardo occhi di un utente può passare prima di concludere un clic manuale (ad esempio, un airtap).</span><span class="sxs-lookup"><span data-stu-id="80217-200">**Leave before click:** For quick target selections, research has shown that a user's eye gaze may move on before concluding a manual click (e.g., an airtap).</span></span> <span data-ttu-id="80217-201">Di conseguenza, particolare attenzione alla sincronizzazione occhio veloce sguardo segnale con input di controllo più lente (ad esempio, vocali, le mani, controller).</span><span class="sxs-lookup"><span data-stu-id="80217-201">Hence, special attention must be paid to synchronizing the fast eye gaze signal with slower control input (e.g., voice, hands, controller).</span></span>

- <span data-ttu-id="80217-202">**Destinazioni di piccole dimensioni:** Si conosce la sensazione quando si prova a leggere il testo che è semplicemente un po' troppo piccolo per difficili da leggere?</span><span class="sxs-lookup"><span data-stu-id="80217-202">**Small targets:** Do you know the feeling when you try to read text that is just a bit too small to comfortably read?</span></span> <span data-ttu-id="80217-203">Il sentimento straining sugli occhi che causano è sentirsi stanco e altri in quanto si tenta di adattare agli occhi di messa a fuoco migliore?</span><span class="sxs-lookup"><span data-stu-id="80217-203">This straining feeling on your eyes that cause you to feel tired and worn out because you try to readjust your eyes to focus better?</span></span>
<span data-ttu-id="80217-204">Si tratta di una visione che è possibile richiamare gli utenti quando si forza la selezione di destinazioni troppo piccole nella tua app usando come destinazione rossi.</span><span class="sxs-lookup"><span data-stu-id="80217-204">This is a feeling you may invoke in your users when forcing them to select too small targets in your app using eye targeting.</span></span>
<span data-ttu-id="80217-205">Per la progettazione, per creare un'esperienza piacevole e comoda per gli utenti, è consigliabile che le destinazioni devono essere almeno 2° in angolo visual, preferibilmente più grande.</span><span class="sxs-lookup"><span data-stu-id="80217-205">For your design, to create a pleasant and comfortable experience for your users, we recommend that targets should be at least 2° in visual angle, preferably larger.</span></span>

- <span data-ttu-id="80217-206">**Incomplete spostamenti sguardo occhio** occhi eseguono spostamenti rapido da fixation fixation.</span><span class="sxs-lookup"><span data-stu-id="80217-206">**Ragged eye gaze movements** Our eyes perform rapid movements from fixation to fixation.</span></span> <span data-ttu-id="80217-207">Se si esamina i percorsi di analisi di movimenti registrati sotto controllo, si noterà che il loro aspetto incomplete.</span><span class="sxs-lookup"><span data-stu-id="80217-207">If you look at scan paths of recorded eye movements, you can see that they look ragged.</span></span> <span data-ttu-id="80217-208">Gli occhi spostare rapidamente e in spontanei, che si sposta alla *sguardo head* oppure *mano i movimenti*.</span><span class="sxs-lookup"><span data-stu-id="80217-208">Your eyes move quickly and in spontaneous jumps in comparison to *head gaze* or *hand motions*.</span></span>  

- <span data-ttu-id="80217-209">**Affidabilità di rilevamento:** Sotto controllo l'accuratezza di rilevamento potrebbe peggiorare qualche modifica light mano a mano d'occhio regolate per le nuove condizioni.</span><span class="sxs-lookup"><span data-stu-id="80217-209">**Tracking reliability:** Eye tracking accuracy may degrade a little in changing light as your eye adjust to the new conditions.</span></span>
<span data-ttu-id="80217-210">Anche se ciò non necessariamente influenzerà la progettazione di app, come la precisione deve essere entro il limite di 2° citato in precedenza.</span><span class="sxs-lookup"><span data-stu-id="80217-210">While this should not necessarily affect your app design, as the accuracy should be within the above mentioned limitation of 2°.</span></span> <span data-ttu-id="80217-211">Significa che l'utente deve eseguire un'altra calibrazione.</span><span class="sxs-lookup"><span data-stu-id="80217-211">It may mean that the user has to run another calibration.</span></span> 


### <a name="design-recommendations"></a><span data-ttu-id="80217-212">Indicazioni sulla progettazione</span><span class="sxs-lookup"><span data-stu-id="80217-212">Design recommendations</span></span>
<span data-ttu-id="80217-213">Nell'esempio seguente, sono elencati i consigli di progettazione specifiche basate i vantaggi descritti e sfide per occhio estasiati input:</span><span class="sxs-lookup"><span data-stu-id="80217-213">In the following, we list specific design recommendations based on the described advantages and challenges for eye gaze input:</span></span>

1. <span data-ttu-id="80217-214">**Sguardo occhio! = sguardo Head:**</span><span class="sxs-lookup"><span data-stu-id="80217-214">**Eye gaze != Head gaze:**</span></span>
    - <span data-ttu-id="80217-215">**Prendere in considerazione se rapidi ma occhio incomplete spostamenti adatta l'attività di input:** Sebbene i movimenti occhio veloci e incomplete sono un ottimo per selezionare le destinazioni rapidamente tra il campo visivo, è meno applicabile per le attività che richiedono smooth traiettorie inpue (ad esempio, per il disegno o reti circuizione annotazioni).</span><span class="sxs-lookup"><span data-stu-id="80217-215">**Consider whether fast yet ragged eye movements fit your input task:** While our fast and ragged eye movements are great to quickly select targets across our Field of View, it is less applicable for tasks that require smooth input trajectories (e.g., for drawing or encircling annotations).</span></span> <span data-ttu-id="80217-216">In questo caso, manualmente o head puntando deve essere preferito.</span><span class="sxs-lookup"><span data-stu-id="80217-216">In this case, hand or head pointing should be preferred.</span></span>
  
    - <span data-ttu-id="80217-217">**Evitare di associare un elemento direttamente a sguardo occhi dell'utente (ad esempio, un dispositivo di scorrimento o cursore).**</span><span class="sxs-lookup"><span data-stu-id="80217-217">**Avoid attaching something directly to the user’s eye gaze (e.g., a slider or cursor).**</span></span>
<span data-ttu-id="80217-218">In caso di un cursore, questo può comportare l'effetto "cursore fuga" a causa di un leggero offset nel segnale sguardo previsto sotto controllo.</span><span class="sxs-lookup"><span data-stu-id="80217-218">In case of a cursor, this may result in the “fleeing cursor” effect due to slight offsets in the projected eye gaze signal.</span></span> <span data-ttu-id="80217-219">In caso di un dispositivo di scorrimento, è in conflitto con il ruolo double di controllare il dispositivo di scorrimento con gli occhi pur volendo anche verificare se l'oggetto si trova nella posizione corretta.</span><span class="sxs-lookup"><span data-stu-id="80217-219">In case of a slider, it conflicts with the double role of controlling the slider with your eyes while also wanting to check whether the object is at the correct location.</span></span> <span data-ttu-id="80217-220">In breve, gli utenti potrebbero rapidamente sentirsi sovraccaricato e distratti, soprattutto se il segnale è impreciso per tale utente.</span><span class="sxs-lookup"><span data-stu-id="80217-220">In a nutshell, users may quickly feel overwhelmed and distracted, especially if the signal is imprecise for that user.</span></span> 
  
2. <span data-ttu-id="80217-221">**Combinare sguardo occhio con altri input:** L'integrazione di occhio tracciabilità con gli altri input, ad esempio movimenti della mano, i comandi vocali o pressione di pulsanti, ha diversi vantaggi:</span><span class="sxs-lookup"><span data-stu-id="80217-221">**Combine eye gaze with other inputs:** The integration of Eye Tracking with other inputs, such as hand gestures, voice commands or button presses, serves several advantages:</span></span>
    - <span data-ttu-id="80217-222">**Consenti l'osservazione gratuitamente:** Dato che il ruolo principale di occhi consiste nell'osservare l'ambiente, è importante consentire agli utenti di cercare senza attivare qualsiasi (visual, uditivi...) commenti e suggerimenti o azioni.</span><span class="sxs-lookup"><span data-stu-id="80217-222">**Allow for free observation:** Given that the main role of our eyes is to observe our environment, it is important to allow users to look around without triggering any (visual, auditory, ...) feedback or actions.</span></span> 
    <span data-ttu-id="80217-223">La combinazione di ET con un altro controllo di input consente di transizione graduale tra le modalità di controllo di input e osservazione ET.</span><span class="sxs-lookup"><span data-stu-id="80217-223">Combining ET with another input control allows for smoothly transitioning between ET observation and input control modes.</span></span>
  
    - <span data-ttu-id="80217-224">**Provider di contesto potenti:** Utilizzare le informazioni su dove sta guardando l'utente durante un comando vocale senza o eseguire un gesto della mano consente facilmente inoltrandoli l'input per il campo di visualizzazione.</span><span class="sxs-lookup"><span data-stu-id="80217-224">**Powerful context provider:** Using information about where the user is looking at while uttering a voice command or performing a hand gesture allows for effortlessly channeling the input across the field-of-view.</span></span> <span data-ttu-id="80217-225">Ecco alcuni esempi: "Put che non esiste" in modo rapido e assicurano la massima selezionare e posizionare ologramma tra la scena osservando semplicemente una destinazione e di destinazione.</span><span class="sxs-lookup"><span data-stu-id="80217-225">Examples include: “Put that there” to quickly and fluently select and position a hologram across the scene by simply looking at a target and destination.</span></span> 

    - <span data-ttu-id="80217-226">**È necessario per la sincronizzazione multimodali input ("lasciare prima di fare clic su" problema):** La combinazione rapida occhio spostamenti più complessi input aggiuntivi (ad esempio, i comandi vocali lunghi o movimenti della mano) assuma il rischio che lo spostamento di con lo sguardo sotto controllo prima di completare il comando di input aggiuntivo.</span><span class="sxs-lookup"><span data-stu-id="80217-226">**Need for synchronizing multimodal inputs (“leave before click” issue):** Combining rapid eye movements with more complex additional inputs (e.g., long voice commands or hand gestures) bears the risk of moving on with your eye gaze before finishing the additional input command.</span></span> <span data-ttu-id="80217-227">Di conseguenza, se si creano i propri controlli di input (ad esempio, movimenti della mano personalizzato), assicurarsi di inizio di questa durata input o approssimativa per correlare cosa era fixated su un utente in precedenza.</span><span class="sxs-lookup"><span data-stu-id="80217-227">Hence, if you create your own input controls (e.g., custom hand gestures), make sure to log the onset of this input or approximate duration to correlate it with what a user had fixated on in the past.</span></span>
    
3. <span data-ttu-id="80217-228">**Commenti e suggerimenti sottile per sotto controllo input di rilevamento:** È utile fornire commenti e suggerimenti, se una destinazione viene esaminata (per indicare che il sistema funzioni come previsto), ma deve essere mantenuta meno evidente.</span><span class="sxs-lookup"><span data-stu-id="80217-228">**Subtle feedback for eye tracking input:** It is useful to provide feedback if a target is looked at (to indicate that the system is working as intended) but should be kept subtle.</span></span> <span data-ttu-id="80217-229">Ciò può includere la fusione lentamente in ingresso/uscita evidenziazioni visual o eseguire altri comportamenti di destinazione meno evidenti, ad esempio i movimenti lenta (ad esempio, leggermente aumentando la destinazione) per indicare che il sistema in modo corretto ha rilevato che l'utente sta guardando una destinazione, tuttavia, senza inutilmente interrompere il flusso di lavoro corrente dell'utente.</span><span class="sxs-lookup"><span data-stu-id="80217-229">This may include slowly blending in/out visual highlights or perform other subtle target behaviors, such as slow motions (e.g., slightly increasing the target) to indicate that the system correctly detected that the user is looking at a target, however, without unnecessarily interrupting the user’s current workflow.</span></span> 

4. <span data-ttu-id="80217-230">**Evitare l'applicazione di movimenti occhio non naturali come input:** Non forzare agli utenti di eseguire spostamenti occhio specifico (movimenti sguardo) per attivare le azioni nell'app.</span><span class="sxs-lookup"><span data-stu-id="80217-230">**Avoid enforcing unnatural eye movements as input:** Do not force users to perform specific eye movements (gaze gestures) to trigger actions in your app.</span></span>

5. <span data-ttu-id="80217-231">**Account per le imprecisioni:** Sono disponibili due tipi delle imprecisioni che sono evidenti per gli utenti: Offset e instabilità.</span><span class="sxs-lookup"><span data-stu-id="80217-231">**Account for imprecisions:** We distinguish two types of imprecisions which are noticeable to users: Offset and Jitter.</span></span> <span data-ttu-id="80217-232">Il modo più semplice per gli offset di indirizzo è fornire destinazioni sufficientemente grande per interagire con (> 2° in angolo visual – come riferimento: l'anteprima è circa 2° in angolo visual quando il ridimensionamento orizzontale di Azure Resource Manager (1)).</span><span class="sxs-lookup"><span data-stu-id="80217-232">The easiest way to address offsets is to provide sufficiently large targets to interact with (> 2° in visual angle – as reference: your thumbnail is about 2° in visual angle when you stretch out your arm (1)).</span></span> <span data-ttu-id="80217-233">Ciò comporta il materiale sussidiario seguente:</span><span class="sxs-lookup"><span data-stu-id="80217-233">This leads to the following guidance:</span></span>
    - <span data-ttu-id="80217-234">Non forzare la selezione di destinazioni di piccole dimensioni: Research ha dimostrato che se le destinazioni sono sufficientemente grandi e il sistema è progettato anche, gli utenti descrivono l'interazione come semplificata e magico scrivendo.</span><span class="sxs-lookup"><span data-stu-id="80217-234">Do not force users to select tiny targets: Research has shown that if targets are sufficiently large (and the system is designed well), users describe the interaction as effortless and magical.</span></span> <span data-ttu-id="80217-235">Se le destinazioni diventano troppo piccole, gli utenti descrivono l'esperienza come difficoltoso e frustrazione.</span><span class="sxs-lookup"><span data-stu-id="80217-235">If targets become too small, users describe the experience as fatiguing and frustrating.</span></span>
    
## <a name="eye-gaze-design-guidelines"></a><span data-ttu-id="80217-236">Linee guida di progettazione sguardo sotto controllo</span><span class="sxs-lookup"><span data-stu-id="80217-236">Eye gaze design guidelines</span></span>

<span data-ttu-id="80217-237">Con 2 HoloLens, abbiamo la straordinaria opportunità per rendere sguardo & commit più veloce e più a proprio agio usando occhio sguardo anziché sguardo head.</span><span class="sxs-lookup"><span data-stu-id="80217-237">With HoloLens 2, we have the great opportunity to make gaze & commit faster and more comfortable by using eye gaze instead of head gaze.</span></span> <span data-ttu-id="80217-238">Tuttavia, sguardo occhio si comporta in modo molto diverso da sguardo head in determinati modi e pertanto viene fornito con una serie di difficoltà univoco.</span><span class="sxs-lookup"><span data-stu-id="80217-238">However, eye gaze behaves very differently to head gaze in certain ways and hence comes with a number of unique challenges.</span></span> <span data-ttu-id="80217-239">Nell'occhio estasiati linee guida di progettazione, riepilogheremo generali vantaggi e problematiche da prendere in considerazione quando si usa registrazione sotto controllo come un supporto di input nell'app holographic.</span><span class="sxs-lookup"><span data-stu-id="80217-239">In Eye Gaze Design Guidelines, we summarize general advantages and challenges to take into account when using eye tracking as an input medium in your holographic app.</span></span> <span data-ttu-id="80217-240">In questa sezione, focalizzata sulla progettazione specifiche per sguardo occhio & commit.</span><span class="sxs-lookup"><span data-stu-id="80217-240">In this section, we focus on the specific design considerations for eye gaze & commit.</span></span> <span data-ttu-id="80217-241">Prima di tutto gli occhi spostare incredibilmente veloce e sono quindi ideali in rapidamente come destinazione attraverso la vista.</span><span class="sxs-lookup"><span data-stu-id="80217-241">First, our eyes move incredibly fast and thus are great at quickly targeting across the view.</span></span> <span data-ttu-id="80217-242">In questo modo occhio estasiati ideale per sguardo rapido & commit azioni, soprattutto se combinate con commit veloce, ad esempio una macchina-indice puntato o un pulsante.</span><span class="sxs-lookup"><span data-stu-id="80217-242">This makes eye gaze ideal for quick gaze & commit actions especially when combined with fast commits such as an air-tap or button press.</span></span>

<span data-ttu-id="80217-243">Non visualizzare un cursore: Mentre è quasi impossibile interagire senza un cursore quando si usa head estasiati, il cursore diventa rapidamente rappresentano una distrazione e indesiderate quando si usa sguardo sotto controllo.</span><span class="sxs-lookup"><span data-stu-id="80217-243">Do not show a cursor: While it is nearly impossible to interact without a cursor when using head gaze, the cursor becomes quickly distracting and annoying when using eye gaze.</span></span> <span data-ttu-id="80217-244">Anziché basarsi su un cursore per informare l'utente se occhio rilevamento funziona e ha corretto ha rilevato l'attualmente cercato nella destinazione, usare meno evidenti visual Evidenzia (ulteriori dettagli sotto).</span><span class="sxs-lookup"><span data-stu-id="80217-244">Instead of relying on a cursor to inform the user whether eye tracking is working and has correctly detected the currently looked at target, use subtle visual highlights (more details below).</span></span>

<span data-ttu-id="80217-245">Cercano di ottenere commenti e suggerimenti al passaggio del mouse combinata meno evidenti: Che cosa sembra eccezionale indicazioni visive per sguardo head può comportare esperienze terribile, piuttosto complessa usando sguardo sotto controllo.</span><span class="sxs-lookup"><span data-stu-id="80217-245">Strive for subtle blended hover feedback: What seems great visual feedback for head gaze can result in terrible, overwhelming experiences using eye gaze.</span></span> <span data-ttu-id="80217-246">Tenere presente che gli occhi sono molto veloci, darting rapidamente tra i punti del campo di visualizzazione.</span><span class="sxs-lookup"><span data-stu-id="80217-246">Remember that your eyes are enormously fast, quickly darting across points in your field-of-view.</span></span> <span data-ttu-id="80217-247">Modifiche di evidenziazione improvvisi rapida (attivato/disattivato) possono comportare flickery commenti e suggerimenti durante la ricerca.</span><span class="sxs-lookup"><span data-stu-id="80217-247">Quick sudden highlight changes (on/off) may result in flickery feedback when looking around.</span></span> <span data-ttu-id="80217-248">Pertanto, quando si forniscono commenti e suggerimenti al passaggio del mouse, è consigliabile con un'evidenziazione in modo uniforme devono essere smussati aggiuntivo (e devono essere smussati-out durante la ricerca da subito).</span><span class="sxs-lookup"><span data-stu-id="80217-248">So, when providing hover feedback, we recommend using a smoothly blended-in highlight (and blended-out when looking away).</span></span> <span data-ttu-id="80217-249">Ciò significa che inizialmente è poco notare i commenti e suggerimenti quando si esamina una destinazione.</span><span class="sxs-lookup"><span data-stu-id="80217-249">This means that at first you would barely notice the feedback when looking at a target.</span></span> <span data-ttu-id="80217-250">Nel corso di 500 e 1000 ms aumenterebbe di intensità di evidenziazione.</span><span class="sxs-lookup"><span data-stu-id="80217-250">Over the course of 500-1000 ms the highlight would increase in intensity.</span></span> <span data-ttu-id="80217-251">Mentre gli utenti meno esperti potrebbero mantenere esamina la destinazione per assicurarsi che il sistema ha determinato correttamente che la destinazione con lo stato attivo, può rapidamente estasiati & commit viene eseguito senza attendere il feedback è la massima intensità da utenti esperti.</span><span class="sxs-lookup"><span data-stu-id="80217-251">While novice users could keep looking at the target to ensure that the system has correctly determined the focused target, expert users could quickly gaze & commit without waiting until the feedback is at its full intensity.</span></span> <span data-ttu-id="80217-252">Inoltre, è anche consigliabile usare una sfumatura orizzontale quando dissolvenza in uscita i commenti e suggerimenti al passaggio del mouse.</span><span class="sxs-lookup"><span data-stu-id="80217-252">In addition, we also recommend using a blend-out when fading out the hover feedback.</span></span> <span data-ttu-id="80217-253">Research ha dimostrato che modifiche di movimento e contrasto rapide sono molto evidenti nella tua vision periferiche (questa operazione, l'area del campo visivo in cui non è indispensabile).</span><span class="sxs-lookup"><span data-stu-id="80217-253">Research has shown that quick motion and contrast changes are very noticeable in your peripheral vision (so, the area of your visual field where you are not looking).</span></span> <span data-ttu-id="80217-254">La dissolvenza privo di lentezza del blend aggiuntivo.</span><span class="sxs-lookup"><span data-stu-id="80217-254">The fade-out doesn't have to be as slow as the blend-in.</span></span> <span data-ttu-id="80217-255">Questo è fondamentale solo quando è disponibile a contrasto elevato o modifiche ai colori per l'evidenziazione.</span><span class="sxs-lookup"><span data-stu-id="80217-255">This is only critical when you have high contrast or color changes for your highlight.</span></span> <span data-ttu-id="80217-256">Se i commenti e suggerimenti al passaggio del mouse è stato alquanto impercettibile per iniziare, probabilmente non si verificherà una differenza.</span><span class="sxs-lookup"><span data-stu-id="80217-256">If the hover feedback was pretty subtle to begin with, you probably won't notice a difference.</span></span>

<span data-ttu-id="80217-257">Osservando la sincronizzazione segnali sguardo ed eseguire il commit: La sincronizzazione di input segnali possono essere meno difficile per semplice sguardo & commit, pertanto, non preoccuparti!</span><span class="sxs-lookup"><span data-stu-id="80217-257">Look out for synchronizing gaze and commit signals: The synchronization of input signals may be less of a challenge for simple gaze & commit, so, don't worry!</span></span> <span data-ttu-id="80217-258">È un elemento da cercare nel caso in cui si desidera usare azioni commit più complicate, ma che può comportare movimenti della mano complesse o i comandi vocali lunghi.</span><span class="sxs-lookup"><span data-stu-id="80217-258">It is something to look out for in case you want to use more complicated commit actions though that may involve long voice commands or complicated hand gestures.</span></span> <span data-ttu-id="80217-259">Si supponga Esaminiamo target e utter un comando vocali lunghi.</span><span class="sxs-lookup"><span data-stu-id="80217-259">Imagine you look at target and utter a long voice command.</span></span> <span data-ttu-id="80217-260">Presa in considerazione l'ora in cui è necessario parlare e l'ora in cui il sistema è necessaria per determinare cosa hai detto, lo sguardo occhio in genere tempo passa all'alcuni nuova destinazione nella scena.</span><span class="sxs-lookup"><span data-stu-id="80217-260">Taken into account the time that you needed to speak and the time that the system needed to detect what you said, your eye gaze has usually long moved on to some new target in the scene.</span></span> <span data-ttu-id="80217-261">Di conseguenza, rendere gli utenti consapevoli che possono dover mantenere esaminando una destinazione fino a quando non è stato riconosciuto il comando o gestire l'input in un modo per determinare che genera del comando e ciò che l'utente era stata esaminando epoca.</span><span class="sxs-lookup"><span data-stu-id="80217-261">Hence, either make your users aware that they may need to keep looking at a target until the command has been recognized or handle the input in a way to determine the onset of the command and what the user had been looking at back then.</span></span>

## <a name="see-also"></a><span data-ttu-id="80217-262">Vedere anche</span><span class="sxs-lookup"><span data-stu-id="80217-262">See also</span></span>
* [<span data-ttu-id="80217-263">Puntamento con la testa e commit</span><span class="sxs-lookup"><span data-stu-id="80217-263">Head-gaze and commit</span></span>](gaze-and-commit.md)
* [<span data-ttu-id="80217-264">Movimenti</span><span class="sxs-lookup"><span data-stu-id="80217-264">Gestures</span></span>](gestures.md)
* [<span data-ttu-id="80217-265">Esecuzione di comandi vocali</span><span class="sxs-lookup"><span data-stu-id="80217-265">Voice commanding</span></span>](voice-design.md)
* [<span data-ttu-id="80217-266">Controller del movimento</span><span class="sxs-lookup"><span data-stu-id="80217-266">Motion controllers</span></span>](motion-controllers.md)
* [<span data-ttu-id="80217-267">Comodità</span><span class="sxs-lookup"><span data-stu-id="80217-267">Comfort</span></span>](comfort.md)
