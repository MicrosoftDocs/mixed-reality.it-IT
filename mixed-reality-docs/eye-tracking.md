---
title: Tracciamento oculare
description: Tracciamento oculare
author: sostel
ms.author: sostel
ms.date: 04/05/2019
ms.topic: article
ms.localizationpriority: high
keywords: tracciamento oculare, realtà mista, input, sguardo fisso
ms.openlocfilehash: 7298a34a946f86aaf789cfe44ad971169fc8ece3
ms.sourcegitcommit: f20beea6a539d04e1d1fc98116f7601137eebebe
ms.translationtype: HT
ms.contentlocale: it-IT
ms.lasthandoff: 06/05/2019
ms.locfileid: "66453696"
---
# <a name="eye-tracking-on-hololens-2"></a><span data-ttu-id="b550f-104">Tracciamento oculare in HoloLens 2</span><span class="sxs-lookup"><span data-stu-id="b550f-104">Eye tracking on HoloLens 2</span></span>
<span data-ttu-id="b550f-105">HoloLens 2 consente di raggiungere un livello totalmente nuovo di comprensione contestuale e umana all'interno dell'esperienza olografica, offrendo agli sviluppatori l'incredibile possibilità di usare le informazioni relative a cosa gli utenti stanno guardando.</span><span class="sxs-lookup"><span data-stu-id="b550f-105">HoloLens 2 allows for a whole new level of context and human understanding within the holographic experience by providing developers with the incredible ability of using information about what users are looking at.</span></span> <span data-ttu-id="b550f-106">Questa pagina presenta una panoramica delle modalità con cui gli sviluppatori possono trarre vantaggio dal tracciamento oculare per vari casi di utilizzo e degli aspetti di cui preoccuparsi quando vengono progettate interfacce utente basate sullo sguardo fisso.</span><span class="sxs-lookup"><span data-stu-id="b550f-106">This page gives an overview of how developers can benefit from eye tracking for various use cases and what to look out for when designing eye-gaze-based user interfaces.</span></span> 

## <a name="use-cases"></a><span data-ttu-id="b550f-107">Casi di utilizzo</span><span class="sxs-lookup"><span data-stu-id="b550f-107">Use cases</span></span>
<span data-ttu-id="b550f-108">Il tracciamento oculare consente alle applicazioni di tenere traccia di dove guarda l'utente in tempo reale.</span><span class="sxs-lookup"><span data-stu-id="b550f-108">Eye tracking enables applications to track where the user is looking in real time.</span></span> <span data-ttu-id="b550f-109">Questa sezione illustra alcuni dei potenziali casi di utilizzo e le nuove interazioni che diventano possibili con il tracciamento oculare nella realtà mista.</span><span class="sxs-lookup"><span data-stu-id="b550f-109">This section describes some of the potential use cases and novel interactions that become possible with eye tracking in mixed reality.</span></span>
<span data-ttu-id="b550f-110">Prima di iniziare, è importante notare che di seguito verrà menzionato diverse volte [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) perché offre diversi esempi interessanti ed efficaci di utilizzo del tracciamento oculare, ad esempio la selezione semplice e rapida della destinazione mediante lo sguardo fisso e lo scorrimento automatico del testo in base a dove guarda l'utente.</span><span class="sxs-lookup"><span data-stu-id="b550f-110">Before getting started, in the following we will mention the [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) several times as it provides several interesting and powerful examples for using eye tracking such as quick and effortless eye-supported target selections and automatically scrolling through text based on where the user looks at.</span></span> 

### <a name="user-intent"></a><span data-ttu-id="b550f-111">Intenzione dell'utente</span><span class="sxs-lookup"><span data-stu-id="b550f-111">User intent</span></span>    
<span data-ttu-id="b550f-112">Le informazioni relative a dove guarda un utente forniscono un utile **contesto per altri input**, ad esempio la voce, le mani e i controller.</span><span class="sxs-lookup"><span data-stu-id="b550f-112">Information about where a user looks at provides a powerful **context for other inputs**, such as voice, hands and controllers.</span></span>
<span data-ttu-id="b550f-113">Tali informazioni possono essere usate per diverse attività.</span><span class="sxs-lookup"><span data-stu-id="b550f-113">This can be used for various tasks.</span></span>
<span data-ttu-id="b550f-114">Ad esempio, è possibile **selezionare la destinazione** in modo facile e rapido all'interno della scena semplicemente guardando un ologramma e dicendo "seleziona" (vedi anche [Puntamento con la testa e commit](gaze-and-commit.md)) oppure dire "metti questo...", guardarsi intorno fino al punto in cui si vuole posizionare l'ologramma e dire "...là".</span><span class="sxs-lookup"><span data-stu-id="b550f-114">For example, this may range from quickly and effortlessly **targeting** across the scene by simply looking at a hologram and saying "select" (also see [Head-gaze and commit](gaze-and-commit.md)) or by saying "put this...", then looking over to where you want to place the hologram and say "...there".</span></span> <span data-ttu-id="b550f-115">Per alcuni esempi, vedi [Mixed Reality Toolkit - Selezione della destinazione con lo sguardo](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html) e [Mixed Reality Toolkit - Posizionamento della destinazione con lo sguardo](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html).</span><span class="sxs-lookup"><span data-stu-id="b550f-115">Examples for this can be found in [Mixed Reality Toolkit - Eye-supported Target Selection](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html) and [Mixed Reality Toolkit - Eye-supported Target Positioning](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html).</span></span>

<span data-ttu-id="b550f-116">Un altro esempio di intenzione dell'utente può essere rappresentato dall'uso delle informazioni relative a cosa guarda per aumentare il coinvolgimento con ologrammi interattivi e agenti virtuali incorporati.</span><span class="sxs-lookup"><span data-stu-id="b550f-116">An additional example for user intent may include using information about what users look at to enhance the engagement with embodied virtual agents and interactive holograms.</span></span> <span data-ttu-id="b550f-117">Ad esempio, gli agenti virtuali possono adattare le opzioni disponibili e il relativo comportamento in base al contenuto visto in quel momento.</span><span class="sxs-lookup"><span data-stu-id="b550f-117">For example, virtual agents may adapt available options and their behavior based on currently viewed content.</span></span> 

### <a name="implicit-actions"></a><span data-ttu-id="b550f-118">Azioni implicite</span><span class="sxs-lookup"><span data-stu-id="b550f-118">Implicit actions</span></span>
<span data-ttu-id="b550f-119">La categoria delle azioni implicite è strettamente correlata all'intenzione dell'utente.</span><span class="sxs-lookup"><span data-stu-id="b550f-119">The category of implicit actions closely relates to user intent.</span></span>
<span data-ttu-id="b550f-120">L'idea è che gli ologrammi o gli elementi dell'interfaccia utente reagiscano quasi in modo istintivo come se l'utente non stesse interagendo con il sistema, ma come se il sistema e l'utente fossero sincronizzati. Un esempio molto significativo di questo concetto è lo **scorrimento automatico mediante sguardo fisso**.</span><span class="sxs-lookup"><span data-stu-id="b550f-120">The idea is that holograms or user interface elements react in a somewhat instinctual way that may not even feel like you are interacting with the system at all, but rather that the system and the user are in sync. For example, one immensely successful example is **eye-gaze-based auto scroll**.</span></span> <span data-ttu-id="b550f-121">L'idea è molto semplice: l'utente legge un testo e può tranquillamente continuare a leggere.</span><span class="sxs-lookup"><span data-stu-id="b550f-121">The idea is as simple: The user reads a text and can just keep on reading.</span></span> <span data-ttu-id="b550f-122">Il testo scorre gradualmente verso l'alto in modo che l'utente possa proseguire nel flusso di lettura.</span><span class="sxs-lookup"><span data-stu-id="b550f-122">The text gradually moves up to keep users in their reading flow.</span></span> <span data-ttu-id="b550f-123">Un aspetto fondamentale è rappresentato dal fatto che la velocità di scorrimento si adatta alla velocità di lettura dell'utente.</span><span class="sxs-lookup"><span data-stu-id="b550f-123">A key aspect is that the scrolling speed adapts to the reading speed of the user.</span></span>
<span data-ttu-id="b550f-124">Un altro esempio è costituito da **zoom e panoramica con gli occhi**, grazie ai quali l'utente ha la sensazione di immergersi esattamente nel contenuto su cui si è concentrato.</span><span class="sxs-lookup"><span data-stu-id="b550f-124">Another example is **eye-supported zoom and pan** for which the user can feel like diving exactly toward what he or she is focusing at.</span></span> <span data-ttu-id="b550f-125">L'attivazione dello zoom e il controllo della velocità di zoom possono essere controllati mediante input vocale o della mano. Questo è importante per dare all'utente la sensazione di avere il controllo senza essere sopraffatto (queste linee guida per la progettazione verranno trattate in dettaglio più avanti).</span><span class="sxs-lookup"><span data-stu-id="b550f-125">Triggering the zoom and controlling the zoom speed can be controlled via voice or hand input which is important about providing the feeling of control and avoid overwhelming the user (we will talk about these design guidelines in more detail below).</span></span> <span data-ttu-id="b550f-126">Dopo aver fatto zoom avanti, l'utente può ad esempio seguire fluidamente come si snoda una strada per esplorare il proprio quartiere usando semplicemente lo sguardo.</span><span class="sxs-lookup"><span data-stu-id="b550f-126">Once zoomed in, the user can then smoothly follow, for example, the course of a street to explore his or her neighborhood just simply by using their eye gaze.</span></span>
<span data-ttu-id="b550f-127">Alcune demo di esempio per questi tipi di interazioni sono disponibili in [Mixed Reality Toolkit - Navigazione con gli occhi](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html).</span><span class="sxs-lookup"><span data-stu-id="b550f-127">Demo examples for these types of interactions can be found in the [Mixed Reality Toolkit - Eye-supported Navigation](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html) sample.</span></span>

<span data-ttu-id="b550f-128">Seguono altri casi di utilizzo per le _azioni implicite_:</span><span class="sxs-lookup"><span data-stu-id="b550f-128">Additional use cases for _implicit actions_ may include:</span></span>
- <span data-ttu-id="b550f-129">**Notifiche intelligenti:** non vieni mai disturbato dalle notifiche che vengono visualizzate proprio nel punto su cui ti sei soffermato?</span><span class="sxs-lookup"><span data-stu-id="b550f-129">**Smart notifications:** Ever get annoyed by notifications popping up right where you were focusing?</span></span> <span data-ttu-id="b550f-130">Tenendo conto dell'elemento a cui l'utente sta prestando attenzione in un determinato momento, puoi evitare questo problema.</span><span class="sxs-lookup"><span data-stu-id="b550f-130">Taking into account where a user is currently paying attention to, you can make it better!</span></span> <span data-ttu-id="b550f-131">Mostra le notifiche lontano dal punto che l'utente sta guardando per limitare le distrazioni e falle scomparire automaticamente al termine della lettura.</span><span class="sxs-lookup"><span data-stu-id="b550f-131">Show notifications offset from where the user is currently looking to limit distractions and automatically dismiss them once finished reading.</span></span> 
- <span data-ttu-id="b550f-132">**Ologrammi reattivi:** crea ologrammi in grado di reagire non appena vengono guardati.</span><span class="sxs-lookup"><span data-stu-id="b550f-132">**Attentive holograms:** Holograms that subtly react when being looked at.</span></span> <span data-ttu-id="b550f-133">Può trattarsi di elementi dell'interfaccia utente che brillano leggermente, di un fiore che sboccia lentamente e persino di un cucciolo virtuale che inizia a guardarti o che tenta di evitare il tuo sguardo dopo essere stato fissato a lungo.</span><span class="sxs-lookup"><span data-stu-id="b550f-133">This may range from slightly glowing UI elements, a slowly blooming flower to a virtual pet starting to look back at you or trying to avoid your eye gaze after a prolonged stare.</span></span> <span data-ttu-id="b550f-134">Questo può conferire all'app un interessante senso di relazione con l'utente e far provare soddisfazione all'utente stesso.</span><span class="sxs-lookup"><span data-stu-id="b550f-134">This may provide an interesting sense of connectivity and satisfaction in your app.</span></span>

### <a name="attention-tracking"></a><span data-ttu-id="b550f-135">Tracciamento dell'attenzione</span><span class="sxs-lookup"><span data-stu-id="b550f-135">Attention tracking</span></span>   
<span data-ttu-id="b550f-136">Le informazioni relative a dove guardano gli utenti sono un potente strumento per valutare l'utilizzabilità delle progettazioni e per identificare i problemi in flussi di lavoro efficienti.</span><span class="sxs-lookup"><span data-stu-id="b550f-136">Information about where users look at is an immensely powerful tool to assess usability of designs and to identify problems in efficient work streams.</span></span> <span data-ttu-id="b550f-137">La visualizzazione e l'analisi del tracciamento oculare ormai sono una pratica comune in diversi settori di applicazione.</span><span class="sxs-lookup"><span data-stu-id="b550f-137">By now,  eye tracking visualization and analytics are already a common practice in various application areas.</span></span> <span data-ttu-id="b550f-138">Con HoloLens 2 viene aggiunta una nuova dimensione a tali informazioni, in quanto gli ologrammi 3D possono essere posizionati in contesti del mondo reale e valutati contemporaneamente.</span><span class="sxs-lookup"><span data-stu-id="b550f-138">With HoloLens 2, we provide a new dimension to this understanding as 3D holograms can be placed in real-world contexts and assessed alongside.</span></span> <span data-ttu-id="b550f-139">[Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) offre esempi di base per la registrazione e il caricamento dei dati di tracciamento oculare e di come visualizzarli.</span><span class="sxs-lookup"><span data-stu-id="b550f-139">The [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) provides basic examples for logging and loading eye tracking data and for how to visualize them.</span></span>

<span data-ttu-id="b550f-140">Di seguito sono riportate altre applicazioni in questo settore:</span><span class="sxs-lookup"><span data-stu-id="b550f-140">Other applications in this area may include:</span></span> 
-   <span data-ttu-id="b550f-141">**Visualizzazione in remoto mediante sguardo fisso:** è possibile visualizzare cosa stanno guardando i collaboratori remoti, ad esempio per assicurarsi che le istruzioni siano state comprese e seguite correttamente.</span><span class="sxs-lookup"><span data-stu-id="b550f-141">**Remote eye gaze visualization:** Visualize what remote collaborators are looking at to, for example, ensure whether instructions are correctly understood and followed.</span></span>
-   <span data-ttu-id="b550f-142">**Studi di ricerca sugli utenti:** è possibile usare il tracciamento dell'attenzione per verificare il modo in cui gli utenti nuovi e quelli esperti analizzano visivamente il contenuto oppure la loro coordinazione tra mano e occhio per le attività complesse, ad esempio per l'analisi di dati medici o durante l'utilizzo di macchinari.</span><span class="sxs-lookup"><span data-stu-id="b550f-142">**User research studies:** Attention tracking can be used to explore the way novice vs. experts users visually analyze content or their hand-eye-coordination for complex tasks (e.g., for analysis of medical data or while operating machinery).</span></span>
-   <span data-ttu-id="b550f-143">**Simulazioni di formazione e monitoraggio delle prestazioni:** è possibile fare pratica e ottimizzare l'esecuzione delle attività identificando i colli di bottiglia in modo più efficace nel flusso di esecuzione.</span><span class="sxs-lookup"><span data-stu-id="b550f-143">**Training simulations and Performance monitoring:** Practice and optimize the execution of tasks by identifying bottlenecks more effectively in the execution flow.</span></span>
-   <span data-ttu-id="b550f-144">**Valutazioni delle progettazioni e ricerche pubblicitarie e di marketing:** il tracciamento oculare è uno strumento comune per le ricerche di mercato allo scopo di valutare la progettazione dei siti Web e dei prodotti.</span><span class="sxs-lookup"><span data-stu-id="b550f-144">**Design evaluations, advertisement and marketing research:** Eye tracking is a common tool for market research to evaluate website and product designs.</span></span>

### <a name="additional-use-cases"></a><span data-ttu-id="b550f-145">Altri casi di utilizzo</span><span class="sxs-lookup"><span data-stu-id="b550f-145">Additional use cases</span></span>
- <span data-ttu-id="b550f-146">**Giochi:** hai mai sognato di avere dei superpoteri?</span><span class="sxs-lookup"><span data-stu-id="b550f-146">**Gaming:** Ever wanted to have superpowers?</span></span> <span data-ttu-id="b550f-147">Ora hai questa opportunità.</span><span class="sxs-lookup"><span data-stu-id="b550f-147">Here's your chance!</span></span> <span data-ttu-id="b550f-148">Puoi far levitare gli ologrammi guardandoli,</span><span class="sxs-lookup"><span data-stu-id="b550f-148">Levitate holograms by staring at them.</span></span> <span data-ttu-id="b550f-149">lanciare raggi laser dagli occhi,</span><span class="sxs-lookup"><span data-stu-id="b550f-149">Shoot laser beams from your eyes.</span></span> <span data-ttu-id="b550f-150">trasformare i nemici in blocchi di pietra o di ghiaccio</span><span class="sxs-lookup"><span data-stu-id="b550f-150">Turn enemies into stone or freeze them!</span></span> <span data-ttu-id="b550f-151">oppure usare la tua vista a raggi x per esplorare l'interno degli edifici.</span><span class="sxs-lookup"><span data-stu-id="b550f-151">Use your x-ray vision to explore buildings.</span></span> <span data-ttu-id="b550f-152">Insomma, con la tua immaginazione potrai superare ogni ostacolo.</span><span class="sxs-lookup"><span data-stu-id="b550f-152">Your imagination is the limit!</span></span>  

- <span data-ttu-id="b550f-153">**Avatar espressivi:** il tracciamento oculare è utile per rendere più espressivi gli avatar 3D. È infatti possibile usare i dati relativi al tracciamento dell'occhio umano per animare gli occhi dell'avatar e indicare quello che l'utente sta guardando in un determinato momento.</span><span class="sxs-lookup"><span data-stu-id="b550f-153">**Expressive avatars:** Eye tracking aids in more expressive 3D avatars by using live eye tracking date to animate the avatar's eyes to indicate what the user is currently looking at.</span></span> <span data-ttu-id="b550f-154">Consente inoltre di aggiungere maggiore espressività mediante strizzate d'occhio e ammiccamenti.</span><span class="sxs-lookup"><span data-stu-id="b550f-154">It also adds more expressiveness by adding winks and blinks.</span></span> 

- <span data-ttu-id="b550f-155">**Immissione di testo:** il tracciamento oculare può essere usato come alternativa interessante per immettere testo senza sforzo, soprattutto quando non è comodo servirsi della voce o delle mani.</span><span class="sxs-lookup"><span data-stu-id="b550f-155">**Text entry:** Eye tracking can be used as an interesting alternative for low-effort text entry especially when speech or hands are inconvenient to use.</span></span> 


## <a name="eye-tracking-api"></a><span data-ttu-id="b550f-156">API di tracciamento oculare</span><span class="sxs-lookup"><span data-stu-id="b550f-156">Eye tracking API</span></span>
<span data-ttu-id="b550f-157">Prima di illustrare in dettaglio le linee guida di progettazione specifiche per l'interazione mediante sguardo fisso, vengono descritte brevemente le funzionalità offerte dal tracciatore oculare HoloLens 2.</span><span class="sxs-lookup"><span data-stu-id="b550f-157">Before going into detail about the specific design guidelines for eye-gaze interaction, we want to briefly point to the capabilities that the HoloLens 2 Eye Tracker is providing.</span></span> <span data-ttu-id="b550f-158">L'[API di tracciamento oculare](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose) è accessibile tramite `Windows.Perception.People.EyesPose`</span><span class="sxs-lookup"><span data-stu-id="b550f-158">The [Eye Tracking API](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose) is accessible through: `Windows.Perception.People.EyesPose`.</span></span> <span data-ttu-id="b550f-159">e fornisce agli sviluppatori un singolo raggio dello sguardo fisso (origine e direzione dello sguardo fisso).</span><span class="sxs-lookup"><span data-stu-id="b550f-159">It provides a single eye gaze ray (gaze origin and direction) to developers.</span></span>
<span data-ttu-id="b550f-160">Il tracciatore oculare fornisce dati a circa _30 fotogrammi al secondo_.</span><span class="sxs-lookup"><span data-stu-id="b550f-160">The eye tracker provides data at about _30 FPS_.</span></span>
<span data-ttu-id="b550f-161">Lo sguardo fisso previsto è all'incirca entro</span><span class="sxs-lookup"><span data-stu-id="b550f-161">The predicted eye gaze lies within ca.</span></span> <span data-ttu-id="b550f-162">un angolo visivo di 1 - 1,5 gradi attorno alla destinazione effettivamente guardata.</span><span class="sxs-lookup"><span data-stu-id="b550f-162">1.0 - 1.5 degrees in visual angle around the actual looked at target.</span></span> <span data-ttu-id="b550f-163">Poiché sono prevedibili lievi imprecisioni, effettua la pianificazione in modo da lasciare un po' di margine per questo valore limite minimo.</span><span class="sxs-lookup"><span data-stu-id="b550f-163">As slight imprecisions are expected, you should plan for some margin around this lower bound value.</span></span> <span data-ttu-id="b550f-164">Più avanti verranno forniti altri dettagli in merito.</span><span class="sxs-lookup"><span data-stu-id="b550f-164">We will discuss this more below.</span></span> <span data-ttu-id="b550f-165">Per un accurato funzionamento del tracciamento oculare, ogni utente deve essere sottoposto a un'apposita calibrazione.</span><span class="sxs-lookup"><span data-stu-id="b550f-165">For eye tracking to work accurately, each user is required to go through an eye tracking user calibration.</span></span> 

<span data-ttu-id="b550f-166">![Dimensioni ottimali della destinazione a una distanza di 2 metri](images/gazetargeting-size-1000px.jpg)</span><span class="sxs-lookup"><span data-stu-id="b550f-166">![Optimal target size at 2 meter distance](images/gazetargeting-size-1000px.jpg)</span></span><br>
<span data-ttu-id="b550f-167">*Dimensioni ottimali della destinazione a una distanza di 2 metri*</span><span class="sxs-lookup"><span data-stu-id="b550f-167">*Optimal target size at 2 meter distance*</span></span>


## <a name="eye-gaze-design-guidelines"></a><span data-ttu-id="b550f-168">Linee guida di progettazione per l'uso dello sguardo fisso</span><span class="sxs-lookup"><span data-stu-id="b550f-168">Eye gaze design guidelines</span></span>
<span data-ttu-id="b550f-169">Può essere difficile creare un'interazione che tragga vantaggio dalla possibilità di selezionare rapidamente la destinazione mediante lo sguardo fisso.</span><span class="sxs-lookup"><span data-stu-id="b550f-169">Building an interaction that takes advantage of fast moving eye targeting can be challenging.</span></span> <span data-ttu-id="b550f-170">In questa sezione vengono riepilogati i principali vantaggi e problematiche da considerare durante la progettazione dell'app.</span><span class="sxs-lookup"><span data-stu-id="b550f-170">In this section, we summarize the key advantages and challenges to take into account when designing your app.</span></span> 

### <a name="benefits-of-eye-gaze-input"></a><span data-ttu-id="b550f-171">Vantaggi dell'input mediante sguardo fisso</span><span class="sxs-lookup"><span data-stu-id="b550f-171">Benefits of eye gaze input</span></span>
- <span data-ttu-id="b550f-172">**Puntamento ad alta velocità.**</span><span class="sxs-lookup"><span data-stu-id="b550f-172">**High speed pointing.**</span></span> <span data-ttu-id="b550f-173">Il muscolo dell'occhio è il muscolo del nostro corpo che reagisce con maggiore rapidità.</span><span class="sxs-lookup"><span data-stu-id="b550f-173">The eye muscle is the fastest reacting muscle in our body.</span></span> 

- <span data-ttu-id="b550f-174">**Sforzo limitato.**</span><span class="sxs-lookup"><span data-stu-id="b550f-174">**Low effort.**</span></span> <span data-ttu-id="b550f-175">Non sono quasi necessari movimenti fisici.</span><span class="sxs-lookup"><span data-stu-id="b550f-175">Barely any physical movements are necessary.</span></span> 

- <span data-ttu-id="b550f-176">**Natura implicita.**</span><span class="sxs-lookup"><span data-stu-id="b550f-176">**Implicitness.**</span></span> <span data-ttu-id="b550f-177">Le informazioni relative ai movimenti degli occhi di un utente consentono al sistema di sapere con quale destinazione l'utente intende interagire. Ecco perché gli utenti spesso descrivono questa situazione come "lettura del pensiero".</span><span class="sxs-lookup"><span data-stu-id="b550f-177">Often described by users as "mind reading", information about a user's eye movements lets the system know which target the user plans to engage with.</span></span> 

- <span data-ttu-id="b550f-178">**Canale di input alternativo.**</span><span class="sxs-lookup"><span data-stu-id="b550f-178">**Alternative input channel.**</span></span> <span data-ttu-id="b550f-179">Lo sguardo fisso può essere un potente input a integrazione dell'input con la mano e la voce che si basa sugli anni di esperienza degli utenti in termini di coordinazione tra la mano e l'occhio.</span><span class="sxs-lookup"><span data-stu-id="b550f-179">Eye gaze can provide a powerful supporting input for hand and voice input building on years of experience from users based on their hand-eye coordination.</span></span>

- <span data-ttu-id="b550f-180">**Attenzione visiva.**</span><span class="sxs-lookup"><span data-stu-id="b550f-180">**Visual attention.**</span></span> <span data-ttu-id="b550f-181">Un altro vantaggio importante è la possibilità di dedurre su cosa l'utente stia concentrando l'attenzione.</span><span class="sxs-lookup"><span data-stu-id="b550f-181">Another important benefit is the possibility to infer what a user's is paying attention to.</span></span> <span data-ttu-id="b550f-182">Ciò può essere utile in vari settori di applicazione, ad esempio per valutare con maggior efficacia progettazioni diverse, creare interfacce utente più intelligenti e cogliere i segnali sociali per migliorare la comunicazione remota.</span><span class="sxs-lookup"><span data-stu-id="b550f-182">This can help in various application areas ranging from more effectively evaluating different designs to aiding in smarter User Interfaces and enhanced social cues for remote communication.</span></span>

<span data-ttu-id="b550f-183">In breve, l'uso dello sguardo fisso come input potenzialmente offre un segnale contestuale facile e veloce, soprattutto in combinazione con altri input come quello *vocale* e *manuale* a conferma dell'intenzione dell'utente.</span><span class="sxs-lookup"><span data-stu-id="b550f-183">In a nutshell, using eye gaze as an input potentially offers a fast and effortless contextual signal - This is particularly powerful in combination with other inputs such as *voice* and *manual* input to confirm the user's intent.</span></span>


### <a name="challenges-of-eye-gaze-as-an-input"></a><span data-ttu-id="b550f-184">Problematiche correlate all'uso dello sguardo fisso come input</span><span class="sxs-lookup"><span data-stu-id="b550f-184">Challenges of eye gaze as an input</span></span>
<span data-ttu-id="b550f-185">Insieme a tante potenti funzionalità, arrivano anche tante responsabilità: se è possibile usare lo sguardo fisso per creare esperienze magiche che fanno sentire l'utente come un supereroe, è altrettanto importante sapere per quali finalità non è adatto in modo da tenerne conto adeguatamente.</span><span class="sxs-lookup"><span data-stu-id="b550f-185">With lots of power, comes lots of responsibility: While eye gaze can be used to create magical user experiences feeling like a superhero, it is also important to know what it is not good at to account for this appropriately.</span></span> <span data-ttu-id="b550f-186">Di seguito verranno illustrate alcune *problematiche* da considerare e come affrontarle quando si usa lo sguardo fisso come input:</span><span class="sxs-lookup"><span data-stu-id="b550f-186">In the following, we discuss some *challenges* to take into account and how to address them when working with eye gaze input:</span></span> 

- <span data-ttu-id="b550f-187">**Lo sguardo è "sempre attivo":** nel momento in cui sollevi le palpebre, gli occhi iniziano a fissare gli elementi presenti nell'ambiente.</span><span class="sxs-lookup"><span data-stu-id="b550f-187">**Your eye gaze is "always on"** The moment you open your eye lids, your eyes start fixating things in your environment.</span></span> <span data-ttu-id="b550f-188">Il fatto di reagire a ogni sguardo e di poter avviare azioni accidentalmente solo perché hai guardato un oggetto troppo a lungo può dare luogo a un'esperienza terribile.</span><span class="sxs-lookup"><span data-stu-id="b550f-188">Reacting to every look you make and potentially accidentally issuing actions because you looked at something for too long would result in a terrible experience!</span></span>
<span data-ttu-id="b550f-189">Ecco perché è consigliabile combinare lo sguardo fisso con un *comando vocale*, un *movimento della mano*, un *clic su un pulsante* o un'attesa estesa per attivare la selezione di una destinazione.</span><span class="sxs-lookup"><span data-stu-id="b550f-189">This is why we recommend combining eye gaze with a *voice command*, *hand gesture*, *button click* or extended dwell to trigger the selection of a target.</span></span>
<span data-ttu-id="b550f-190">Questa soluzione consente anche di implementare una modalità in cui l'utente può guardarsi liberamente attorno senza avere l'opprimente sensazione di poter attivare involontariamente funzioni non desiderate.</span><span class="sxs-lookup"><span data-stu-id="b550f-190">This solution also allows for a mode in which the user can freely look around without the overwhelming feeling of involuntarily triggering something.</span></span> <span data-ttu-id="b550f-191">È opportuno tenere conto di tale problematica anche per progettare feedback visivi e audio qualora si guardi semplicemente una destinazione.</span><span class="sxs-lookup"><span data-stu-id="b550f-191">This issue should also be taken into account when designing visual and auditory feedback when merely looking at a target.</span></span>
<span data-ttu-id="b550f-192">Non bombardare l'utente con effetti immediati e improvvisi o suoni al passaggio del puntatore.</span><span class="sxs-lookup"><span data-stu-id="b550f-192">Do not overwhelm the user with immediate pop-out effects or hover sounds.</span></span> <span data-ttu-id="b550f-193">La moderazione è la chiave vincente.</span><span class="sxs-lookup"><span data-stu-id="b550f-193">Subtlety is key!</span></span> <span data-ttu-id="b550f-194">Nella sezione relativa ai suggerimenti per la progettazione verranno illustrate alcune procedure consigliate su questo argomento.</span><span class="sxs-lookup"><span data-stu-id="b550f-194">We will discuss some best practices for this further below when talking about design recommendations.</span></span>

- <span data-ttu-id="b550f-195">**Osservazione e controllo:** immagina di voler allineare con precisione una fotografia sul muro.</span><span class="sxs-lookup"><span data-stu-id="b550f-195">**Observation vs. control** Imagine you want to precisely align a photograph at your wall.</span></span> <span data-ttu-id="b550f-196">Guardi pertanto i bordi e l'area circostante per verificare che l'immagine sia allineata correttamente.</span><span class="sxs-lookup"><span data-stu-id="b550f-196">You look at its borders and its surroundings to see if it aligns well.</span></span> <span data-ttu-id="b550f-197">Ora immagina come potresti eseguire la stessa operazione e contemporaneamente usare lo sguardo fisso come input per spostare la foto.</span><span class="sxs-lookup"><span data-stu-id="b550f-197">Now imagine how you would do that when at the same time you want to use your eye gaze as an input to move the picture.</span></span> <span data-ttu-id="b550f-198">L'esecuzione diventa veramente difficoltosa.</span><span class="sxs-lookup"><span data-stu-id="b550f-198">Difficult, isn't it?</span></span> <span data-ttu-id="b550f-199">Questo fa comprendere la doppia funzione dello sguardo fisso quando è necessario sia per l'input sia per il controllo.</span><span class="sxs-lookup"><span data-stu-id="b550f-199">This describes the double role of eye gaze when it is required both for input and control.</span></span> 

- <span data-ttu-id="b550f-200">**Uscita prima del clic:** per selezioni rapide della destinazione, le ricerche svolte hanno dimostrato che lo sguardo di un utente può concentrarsi su altri elementi prima che un clic manuale (ad esempio, una simulazione del tocco) venga concluso.</span><span class="sxs-lookup"><span data-stu-id="b550f-200">**Leave before click:** For quick target selections, research has shown that a user's eye gaze may move on before concluding a manual click (e.g., an airtap).</span></span> <span data-ttu-id="b550f-201">È pertanto necessario prestare particolare attenzione alla sincronizzazione del rapido segnale dello sguardo fisso con un input di controllo più lento come ad esempio la voce, le mani o un controller.</span><span class="sxs-lookup"><span data-stu-id="b550f-201">Hence, special attention must be paid to synchronizing the fast eye gaze signal with slower control input (e.g., voice, hands, controller).</span></span>

- <span data-ttu-id="b550f-202">**Destinazioni di piccole dimensioni:** ti è mai capitato di leggere un testo con un carattere troppo piccolo per essere letto comodamente?</span><span class="sxs-lookup"><span data-stu-id="b550f-202">**Small targets:** Do you know the feeling when you try to read text that is just a bit too small to comfortably read?</span></span> <span data-ttu-id="b550f-203">Hai mai provato quella spiacevole sensazione agli occhi che ti fa sentire esausto perché devi mettere continuamente a fuoco per vedere meglio?</span><span class="sxs-lookup"><span data-stu-id="b550f-203">This straining feeling on your eyes that cause you to feel tired and worn out because you try to readjust your eyes to focus better?</span></span>
<span data-ttu-id="b550f-204">Puoi provocare la stessa sensazione negli utenti se li forzi a selezionare con lo sguardo destinazioni troppo piccole nell'app.</span><span class="sxs-lookup"><span data-stu-id="b550f-204">This is a feeling you may invoke in your users when forcing them to select too small targets in your app using eye targeting.</span></span>
<span data-ttu-id="b550f-205">Durante la progettazione, per creare un'esperienza piacevole e confortevole per gli utenti, è consigliabile definire destinazioni con un angolo visivo di almeno 2 gradi.</span><span class="sxs-lookup"><span data-stu-id="b550f-205">For your design, to create a pleasant and comfortable experience for your users, we recommend that targets should be at least 2° in visual angle, preferably larger.</span></span>

- <span data-ttu-id="b550f-206">**Movimenti degli occhi non uniformi:** i nostri occhi eseguono rapidi movimenti quando passano da un oggetto all'altro per fissarlo.</span><span class="sxs-lookup"><span data-stu-id="b550f-206">**Ragged eye gaze movements** Our eyes perform rapid movements from fixation to fixation.</span></span> <span data-ttu-id="b550f-207">Se guardi i percorsi di analisi dei movimenti oculari registrati, noterai che risultano irregolari.</span><span class="sxs-lookup"><span data-stu-id="b550f-207">If you look at scan paths of recorded eye movements, you can see that they look ragged.</span></span> <span data-ttu-id="b550f-208">Gli occhi si muovono velocemente e con salti spontanei rispetto al *puntamento con la testa* o ai *movimenti delle mani*.</span><span class="sxs-lookup"><span data-stu-id="b550f-208">Your eyes move quickly and in spontaneous jumps in comparison to *head gaze* or *hand motions*.</span></span>  

- <span data-ttu-id="b550f-209">**Affidabilità del tracciamento:** il tracciamento oculare può diventare leggermente meno affidabile con il mutare della luce, in quanto gli occhi devono adattarsi alle nuove condizioni di illuminazione.</span><span class="sxs-lookup"><span data-stu-id="b550f-209">**Tracking reliability:** Eye tracking accuracy may degrade a little in changing light as your eye adjust to the new conditions.</span></span>
<span data-ttu-id="b550f-210">Questa situazione non incide necessariamente sulla progettazione dell'app in quanto l'accuratezza deve essere entro il limite sopra indicato di 2 gradi,</span><span class="sxs-lookup"><span data-stu-id="b550f-210">While this should not necessarily affect your app design, as the accuracy should be within the above mentioned limitation of 2°.</span></span> <span data-ttu-id="b550f-211">ma può comportare l'esecuzione di un'altra calibrazione per l'utente.</span><span class="sxs-lookup"><span data-stu-id="b550f-211">It may mean that the user has to run another calibration.</span></span> 


### <a name="design-recommendations"></a><span data-ttu-id="b550f-212">Suggerimenti per la progettazione</span><span class="sxs-lookup"><span data-stu-id="b550f-212">Design recommendations</span></span>
<span data-ttu-id="b550f-213">Di seguito sono riportati alcuni suggerimenti specifici per la progettazione in base ai vantaggi e alle problematiche illustrati per l'uso dello sguardo fisso come input:</span><span class="sxs-lookup"><span data-stu-id="b550f-213">In the following, we list specific design recommendations based on the described advantages and challenges for eye gaze input:</span></span>

1. <span data-ttu-id="b550f-214">**Sguardo fisso o puntamento con la testa:**</span><span class="sxs-lookup"><span data-stu-id="b550f-214">**Eye gaze != Head gaze:**</span></span>
    - <span data-ttu-id="b550f-215">**Considerare se i movimenti dell'occhio, rapidi ma non uniformi, sono adatti per l'attività di input da svolgere:** se i movimenti rapidi e irregolari dei nostri occhi sono utilissimi per selezionare velocemente le destinazioni nel campo visivo, sono meno applicabili per le attività che richiedono traiettorie di input uniformi, ad esempio per disegnare o cerchiare le annotazioni.</span><span class="sxs-lookup"><span data-stu-id="b550f-215">**Consider whether fast yet ragged eye movements fit your input task:** While our fast and ragged eye movements are great to quickly select targets across our Field of View, it is less applicable for tasks that require smooth input trajectories (e.g., for drawing or encircling annotations).</span></span> <span data-ttu-id="b550f-216">In questo caso, è preferibile usare il puntamento con la mano o con la testa.</span><span class="sxs-lookup"><span data-stu-id="b550f-216">In this case, hand or head pointing should be preferred.</span></span>
  
    - <span data-ttu-id="b550f-217">**Evitare di associare direttamente un elemento, quale un dispositivo di scorrimento o un cursore, allo sguardo dell'utente.**</span><span class="sxs-lookup"><span data-stu-id="b550f-217">**Avoid attaching something directly to the user’s eye gaze (e.g., a slider or cursor).**</span></span>
<span data-ttu-id="b550f-218">Nel caso di un cursore, si può verificare il cosiddetto effetto del "cursore che scappa" a causa di lievi offset nel segnale dello sguardo proiettato.</span><span class="sxs-lookup"><span data-stu-id="b550f-218">In case of a cursor, this may result in the “fleeing cursor” effect due to slight offsets in the projected eye gaze signal.</span></span> <span data-ttu-id="b550f-219">Nel caso di un dispositivo di scorrimento, si genera un conflitto dato dalla doppia necessità di controllare il dispositivo con gli occhi e allo stesso tempo di verificare se l'oggetto si trova nella posizione corretta.</span><span class="sxs-lookup"><span data-stu-id="b550f-219">In case of a slider, it conflicts with the double role of controlling the slider with your eyes while also wanting to check whether the object is at the correct location.</span></span> <span data-ttu-id="b550f-220">In pratica, gli utenti possono sentirsi rapidamente sopraffatti ed essere distratti, soprattutto se il segnale è impreciso.</span><span class="sxs-lookup"><span data-stu-id="b550f-220">In a nutshell, users may quickly feel overwhelmed and distracted, especially if the signal is imprecise for that user.</span></span> 
  
2. <span data-ttu-id="b550f-221">**Combinare lo sguardo fisso con altri input:** l'integrazione del tracciamento oculare con altri input, quali i movimenti delle mani, i comandi vocali o le pressioni dei pulsanti, offre diversi vantaggi:</span><span class="sxs-lookup"><span data-stu-id="b550f-221">**Combine eye gaze with other inputs:** The integration of Eye Tracking with other inputs, such as hand gestures, voice commands or button presses, serves several advantages:</span></span>
    - <span data-ttu-id="b550f-222">**Possibilità di consentire la libera osservazione:** poiché la funzione principale dei nostri occhi è quella di osservare l'ambiente, è importante consentire agli utenti di guardarsi intorno senza attivare alcun feedback (visivo o audio) o azione.</span><span class="sxs-lookup"><span data-stu-id="b550f-222">**Allow for free observation:** Given that the main role of our eyes is to observe our environment, it is important to allow users to look around without triggering any (visual, auditory, ...) feedback or actions.</span></span> 
    <span data-ttu-id="b550f-223">Combinando il tracciamento oculare con un altro controllo di input, è possibile effettuare una transizione uniforme tra l'osservazione con tracciamento oculare e le modalità dei controlli di input.</span><span class="sxs-lookup"><span data-stu-id="b550f-223">Combining ET with another input control allows for smoothly transitioning between ET observation and input control modes.</span></span>
  
    - <span data-ttu-id="b550f-224">**Potente provider di contesto:** usando le informazioni relative a dove l'utente sta guardando mentre pronuncia un comando vocale o esegue un movimento con la mano, è possibile incanalare agevolmente l'input nel campo visivo.</span><span class="sxs-lookup"><span data-stu-id="b550f-224">**Powerful context provider:** Using information about where the user is looking at while uttering a voice command or performing a hand gesture allows for effortlessly channeling the input across the field-of-view.</span></span> <span data-ttu-id="b550f-225">Ecco alcuni esempi: "Metti questo là" per selezionare e posizionare in modo rapido e fluido un ologramma all'interno della scena semplicemente guardando una destinazione e il punto in cui si vuole collocarlo.</span><span class="sxs-lookup"><span data-stu-id="b550f-225">Examples include: “Put that there” to quickly and fluently select and position a hologram across the scene by simply looking at a target and destination.</span></span> 

    - <span data-ttu-id="b550f-226">**Necessità di sincronizzare input multimodali (problematica della sezione "Uscita prima del clic"):** combinando i rapidi movimenti oculari con altri input più complessi (come ad esempio movimenti delle mani o comandi vocali lunghi), si corre il rischio di spostare lo sguardo prima di completare il comando di input aggiuntivo.</span><span class="sxs-lookup"><span data-stu-id="b550f-226">**Need for synchronizing multimodal inputs (“leave before click” issue):** Combining rapid eye movements with more complex additional inputs (e.g., long voice commands or hand gestures) bears the risk of moving on with your eye gaze before finishing the additional input command.</span></span> <span data-ttu-id="b550f-227">Pertanto, se crei personalmente i controlli di input (ad esempio, movimenti della mano personalizzati), fai in modo di registrare l'inizio di tale input o la durata approssimativa in modo da poterlo mettere in correlazione con cosa aveva fissato in precedenza l'utente.</span><span class="sxs-lookup"><span data-stu-id="b550f-227">Hence, if you create your own input controls (e.g., custom hand gestures), make sure to log the onset of this input or approximate duration to correlate it with what a user had fixated on in the past.</span></span>
    
3. <span data-ttu-id="b550f-228">**Fornire feedback non invasivo per l'input mediante tracciamento oculare:** è utile fornire un feedback se l'utente guarda una destinazione (per indicare che il sistema funziona come previsto), ma tale feedback non deve essere troppo evidente.</span><span class="sxs-lookup"><span data-stu-id="b550f-228">**Subtle feedback for eye tracking input:** It is useful to provide feedback if a target is looked at (to indicate that the system is working as intended) but should be kept subtle.</span></span> <span data-ttu-id="b550f-229">Ad esempio, è possibile creare evidenziazioni visive che si fondono all'inizio o alla fine oppure ricorrere ad altri comportamenti poco invasivi per le destinazioni, tra cui movimenti rallentati (ad esempio, che ingrandiscono leggermente la destinazione) per indicare che il sistema ha rilevato correttamente che l'utente sta guardando una destinazione, senza tuttavia interrompere inutilmente il flusso di lavoro corrente dell'utente stesso.</span><span class="sxs-lookup"><span data-stu-id="b550f-229">This may include slowly blending in/out visual highlights or perform other subtle target behaviors, such as slow motions (e.g., slightly increasing the target) to indicate that the system correctly detected that the user is looking at a target, however, without unnecessarily interrupting the user’s current workflow.</span></span> 

4. <span data-ttu-id="b550f-230">**Evitare di applicare movimenti degli occhi innaturali come input:** non forzare gli utenti a eseguire movimenti degli occhi (o dello sguardo) particolari per attivare azioni all'interno dell'app.</span><span class="sxs-lookup"><span data-stu-id="b550f-230">**Avoid enforcing unnatural eye movements as input:** Do not force users to perform specific eye movements (gaze gestures) to trigger actions in your app.</span></span>

5. <span data-ttu-id="b550f-231">**Tenere conto delle imprecisioni:** agli utenti risultano evidenti due tipi di imprecisioni, ovvero offset e instabilità.</span><span class="sxs-lookup"><span data-stu-id="b550f-231">**Account for imprecisions:** We distinguish two types of imprecisions which are noticeable to users: Offset and Jitter.</span></span> <span data-ttu-id="b550f-232">Il modo più semplice per ovviare agli offset consiste nel fornire destinazioni abbastanza grandi da consentire l'interazione con esse (> 2 gradi di angolo visivo; come riferimento considera che il pollice ha un angolo visivo di circa 2 gradi se distendi il braccio (1)).</span><span class="sxs-lookup"><span data-stu-id="b550f-232">The easiest way to address offsets is to provide sufficiently large targets to interact with (> 2° in visual angle – as reference: your thumbnail is about 2° in visual angle when you stretch out your arm (1)).</span></span> <span data-ttu-id="b550f-233">Segui pertanto le indicazioni seguenti:</span><span class="sxs-lookup"><span data-stu-id="b550f-233">This leads to the following guidance:</span></span>
    - <span data-ttu-id="b550f-234">Non forzare gli utenti a selezionare destinazioni di piccole dimensioni. Le ricerche svolte hanno dimostrato che, se le destinazioni sono sufficientemente grandi (e il sistema è progettato in modo adeguato), gli utenti descrivono l'interazione come facile e magica.</span><span class="sxs-lookup"><span data-stu-id="b550f-234">Do not force users to select tiny targets: Research has shown that if targets are sufficiently large (and the system is designed well), users describe the interaction as effortless and magical.</span></span> <span data-ttu-id="b550f-235">Se le destinazioni diventano troppo piccole, gli utenti descrivono l'esperienza come stancante e frustrante.</span><span class="sxs-lookup"><span data-stu-id="b550f-235">If targets become too small, users describe the experience as fatiguing and frustrating.</span></span>
   

## <a name="see-also"></a><span data-ttu-id="b550f-236">Vedi anche</span><span class="sxs-lookup"><span data-stu-id="b550f-236">See also</span></span>
* [<span data-ttu-id="b550f-237">Puntamento con la testa e commit</span><span class="sxs-lookup"><span data-stu-id="b550f-237">Head-gaze and commit</span></span>](gaze-and-commit.md)
* [<span data-ttu-id="b550f-238">Puntamento con la testa e sguardo fisso in DirectX</span><span class="sxs-lookup"><span data-stu-id="b550f-238">Head and eye gaze in DirectX</span></span>](gaze-in-directx.md)
* [<span data-ttu-id="b550f-239">Sguardo fisso in Unity (Mixed Reality Toolkit)</span><span class="sxs-lookup"><span data-stu-id="b550f-239">Eye gaze in Unity (Mixed Reality Toolkit)</span></span>](https://aka.ms/mrtk-eyes)
* [<span data-ttu-id="b550f-240">Movimenti della mano</span><span class="sxs-lookup"><span data-stu-id="b550f-240">Hand gestures</span></span>](gestures.md)
* [<span data-ttu-id="b550f-241">Input vocale</span><span class="sxs-lookup"><span data-stu-id="b550f-241">Voice input</span></span>](voice-design.md)
* [<span data-ttu-id="b550f-242">Controller del movimento</span><span class="sxs-lookup"><span data-stu-id="b550f-242">Motion controllers</span></span>](motion-controllers.md)
* [<span data-ttu-id="b550f-243">Comodità</span><span class="sxs-lookup"><span data-stu-id="b550f-243">Comfort</span></span>](comfort.md)
