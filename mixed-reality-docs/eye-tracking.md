---
title: Tracciamento oculare
description: HoloLens 2 consente un nuovo livello di contesto e comprensione umana all'interno dell'esperienza olografica, offrendo agli sviluppatori la possibilità di usare le informazioni relative a ciò che l'utente sta esaminando.
author: sostel
ms.author: sostel
ms.date: 10/29/2019
ms.topic: article
keywords: Rilevamento degli occhi, realtà mista, input, sguardi oculari, calibrazione
ms.openlocfilehash: 88c1827d3656ceb851e8f778daa2303b88dd17c8
ms.sourcegitcommit: b6b76275fad90df6d9645dd2bc074b7b2168c7c8
ms.translationtype: MT
ms.contentlocale: it-IT
ms.lasthandoff: 11/11/2019
ms.locfileid: "73913217"
---
# <a name="eye-tracking-on-hololens-2"></a><span data-ttu-id="0c1c0-104">Tracciamento oculare in HoloLens 2</span><span class="sxs-lookup"><span data-stu-id="0c1c0-104">Eye tracking on HoloLens 2</span></span>

![Demo sul rilevamento degli occhi in MRTK](images/mrtk_et_scenemenu.jpg)

<span data-ttu-id="0c1c0-106">HoloLens 2 consente un nuovo livello di contesto e comprensione umana all'interno dell'esperienza olografica, offrendo agli sviluppatori la possibilità di usare le informazioni relative a ciò che l'utente sta esaminando.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-106">HoloLens 2 allows for a new level of context and human understanding within the holographic experience by providing developers with the ability to use information about what the user is looking at.</span></span> <span data-ttu-id="0c1c0-107">Questa pagina indica agli sviluppatori come possono trarre vantaggio dal monitoraggio degli sguardi per diversi casi d'uso, nonché da cosa cercare quando si progettano interazioni utente basate su sguardi visivi.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-107">This page tells developers how they can benefit from eye tracking for various use cases as well as what to look for when designing eye-gaze-based user interactions.</span></span> 

<span data-ttu-id="0c1c0-108">L'API di rilevamento degli occhi è stata progettata tenendo presente la privacy degli utenti, evitando di passare informazioni identificabili, in particolare qualsiasi biometria.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-108">Eye tracking API has been designed with user’s privacy in mind, avoiding passing any identifiable information, particularly any biometrics.</span></span> <span data-ttu-id="0c1c0-109">Per le applicazioni che supportano il rilevamento degli occhi, l'utente deve concedere l'autorizzazione dell'app per usare le informazioni di rilevamento degli occhi.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-109">For eye-tracking capable applications, the user needs to grant app permission to use eye tracking information.</span></span> 


### <a name="device-support"></a><span data-ttu-id="0c1c0-110">Supporto di dispositivi</span><span class="sxs-lookup"><span data-stu-id="0c1c0-110">Device support</span></span>
<table>
<colgroup>
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
</colgroup>
<tr>
     <td><span data-ttu-id="0c1c0-111"><strong>Funzionalità</strong></span><span class="sxs-lookup"><span data-stu-id="0c1c0-111"><strong>Feature</strong></span></span></td>
     <td><span data-ttu-id="0c1c0-112"><a href="hololens-hardware-details.md"><strong>HoloLens (prima generazione)</strong></a></span><span class="sxs-lookup"><span data-stu-id="0c1c0-112"><a href="hololens-hardware-details.md"><strong>HoloLens (1st gen)</strong></a></span></span></td>
     <td><span data-ttu-id="0c1c0-113"><a href="https://docs.microsoft.com/hololens/hololens2-hardware"><strong>HoloLens 2</strong></span><span class="sxs-lookup"><span data-stu-id="0c1c0-113"><a href="https://docs.microsoft.com/hololens/hololens2-hardware"><strong>HoloLens 2</strong></span></span></td>
     <td><span data-ttu-id="0c1c0-114"><a href="immersive-headset-hardware-details.md"><strong>Visori VR immersive</strong></a></span><span class="sxs-lookup"><span data-stu-id="0c1c0-114"><a href="immersive-headset-hardware-details.md"><strong>Immersive headsets</strong></a></span></span></td>
</tr>
<tr>
     <td><span data-ttu-id="0c1c0-115">Sguardo attento</span><span class="sxs-lookup"><span data-stu-id="0c1c0-115">Eye-gaze</span></span></td>
     <td>❌</td>
     <td><span data-ttu-id="0c1c0-116">✔️</span><span class="sxs-lookup"><span data-stu-id="0c1c0-116">✔️</span></span></td>
     <td>❌</td>
</tr>
</table>

<br>

## <a name="calibration"></a><span data-ttu-id="0c1c0-117">Calibrazione</span><span class="sxs-lookup"><span data-stu-id="0c1c0-117">Calibration</span></span> 
<span data-ttu-id="0c1c0-118">Per il corretto funzionamento degli occhi, è necessario che ogni utente esamini la [calibrazione degli utenti](calibration.md) per cui l'utente deve esaminare un set di destinazioni olografiche.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-118">For eye tracking to work accurately, each user is required to go through an [eye tracking user calibration](calibration.md) for which the user has to look at a set of holographic targets.</span></span> <span data-ttu-id="0c1c0-119">In questo modo, il dispositivo può modificare il sistema per un'esperienza di visualizzazione più comoda e di qualità superiore per l'utente e garantire il rilevamento accurato degli occhi allo stesso tempo.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-119">This allows the device to adjust the system for a more comfortable and higher quality viewing experience for the user and to ensure accurate eye tracking at the same time.</span></span> 

<span data-ttu-id="0c1c0-120">Il rilevamento degli occhi dovrebbe funzionare per la maggior parte degli utenti, ma in rari casi un utente potrebbe non essere in grado di calibrare correttamente.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-120">Eye tracking should work for most users, but there are rare cases in which a user might not be able to calibrate successfully.</span></span> <span data-ttu-id="0c1c0-121">La calibrazione potrebbe non riuscire per vari motivi, tra cui:</span><span class="sxs-lookup"><span data-stu-id="0c1c0-121">Calibration might fail for various reasons, including but not limited to:</span></span> 
* <span data-ttu-id="0c1c0-122">L'utente ha rifiutato in precedenza il processo di calibrazione</span><span class="sxs-lookup"><span data-stu-id="0c1c0-122">The user previously opted out of the calibration process</span></span>
* <span data-ttu-id="0c1c0-123">L'utente è stato distratto e non ha seguito gli obiettivi di calibrazione</span><span class="sxs-lookup"><span data-stu-id="0c1c0-123">The user got distracted and didn't follow the calibration targets</span></span>
* <span data-ttu-id="0c1c0-124">L'utente dispone di determinati tipi di obiettivi e occhiali di contatto che il sistema non supporta ancora</span><span class="sxs-lookup"><span data-stu-id="0c1c0-124">The user has certain types of contact lenses and glasses which the system doesn't yet support</span></span> 
* <span data-ttu-id="0c1c0-125">L'utente ha una certa fisiologia degli occhi, condizioni oculari o interventi chirurgici che il sistema non supporta ancora</span><span class="sxs-lookup"><span data-stu-id="0c1c0-125">The user has certain eye physiology, eye conditions or had eye surgery which the system doesn't yet support</span></span>  
* <span data-ttu-id="0c1c0-126">Fattori esterni che inibiscono la verifica affidabile degli occhi, ad esempio le sbavature sulla visiera HoloLens o sugli occhiali, il sole intenso diretto e le occlusioni a causa dei capelli davanti agli occhi</span><span class="sxs-lookup"><span data-stu-id="0c1c0-126">External factors inhibiting reliable eye tracking such as smudges on the HoloLens visor or eyeglasses, intense direct sunlight and occlusions due to hair in front of the eyes</span></span>

<span data-ttu-id="0c1c0-127">Gli sviluppatori devono assicurarsi di fornire un supporto adeguato per gli utenti per i quali i dati di rilevamento degli occhi potrebbero non essere disponibili (che non sono in grado di eseguire correttamente la calibrazione).</span><span class="sxs-lookup"><span data-stu-id="0c1c0-127">Developers should make sure to provide adequate support for users for whom eye tracking data may not be available (who are not able to calibrate successfully).</span></span> <span data-ttu-id="0c1c0-128">Sono disponibili raccomandazioni per le soluzioni di fallback nella sezione nella parte inferiore di questa pagina.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-128">We have provided recommendations for fallback solutions in the section at the bottom of this page.</span></span> 

<span data-ttu-id="0c1c0-129">Per altre informazioni sulla calibrazione e su come garantire un'esperienza uniforme, vedere la pagina relativa alla [calibrazione degli utenti per la verifica degli occhi](calibration.md) .</span><span class="sxs-lookup"><span data-stu-id="0c1c0-129">To learn more about the calibration and about how to ensure a smooth experience, please check our [eye tracking user calibration](calibration.md) page.</span></span>

<br>

## <a name="available-eye-tracking-data"></a><span data-ttu-id="0c1c0-130">Dati di rilevamento degli occhi disponibili</span><span class="sxs-lookup"><span data-stu-id="0c1c0-130">Available eye tracking data</span></span>
<span data-ttu-id="0c1c0-131">Prima di approfondire i casi d'uso specifici per l'input con sguardo a occhio, è opportuno evidenziare brevemente le funzionalità fornite dall'API HoloLens 2 [Eye Tracking](https://docs.microsoft.com/uwp/api/windows.perception.people.eyespose) .</span><span class="sxs-lookup"><span data-stu-id="0c1c0-131">Before going into detail about specific use cases for eye-gaze input, we want to briefly point out the capabilities that the HoloLens 2 [Eye Tracking API](https://docs.microsoft.com/uwp/api/windows.perception.people.eyespose) provides.</span></span> <span data-ttu-id="0c1c0-132">Gli sviluppatori possono accedere a un singolo raggio d'occhio (origine e direzione dello sguardo) a circa _30 fps (30 Hz)_ .</span><span class="sxs-lookup"><span data-stu-id="0c1c0-132">Developers get access to a single eye-gaze ray (gaze origin and direction) at approximately _30 FPS (30 Hz)_.</span></span>
<span data-ttu-id="0c1c0-133">Per informazioni più dettagliate su come accedere ai dati di rilevamento degli occhi, fare riferimento alle guide per gli sviluppatori sull'uso [degli sguardi in DirectX](gaze-in-directx.md) e sugli [sguardi in Unity](https://aka.ms/mrtk-eyes).</span><span class="sxs-lookup"><span data-stu-id="0c1c0-133">For more detailed information about how to access eye tracking data, please refer to our developer guides on using [eye-gaze in DirectX](gaze-in-directx.md) and [eye-gaze in Unity](https://aka.ms/mrtk-eyes).</span></span>

<span data-ttu-id="0c1c0-134">Lo sguardo stimato è approssimativamente entro 1,5 gradi nell'angolo visivo intorno alla destinazione effettiva (vedere la figura seguente).</span><span class="sxs-lookup"><span data-stu-id="0c1c0-134">The predicted eye-gaze is approximately within 1.5 degrees in visual angle around the actual target (see the illustration below).</span></span> <span data-ttu-id="0c1c0-135">Poiché si prevede una lieve imprecisione, gli sviluppatori devono pianificare un margine attorno a questo valore associato inferiore (ad esempio, 2.0-3.0 gradi possono comportare un'esperienza molto più comoda).</span><span class="sxs-lookup"><span data-stu-id="0c1c0-135">As slight imprecisions are expected, developers should plan for some margin around this lower bound value (e.g., 2.0-3.0 degrees may result in a much more comfortable experience).</span></span> <span data-ttu-id="0c1c0-136">Di seguito viene illustrato come gestire la selezione di destinazioni di piccole dimensioni in modo più dettagliato.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-136">We will discuss how to address the selection of small targets in more detail below.</span></span> <span data-ttu-id="0c1c0-137">Per un accurato funzionamento del tracciamento oculare, ogni utente deve essere sottoposto a un'apposita calibrazione.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-137">For eye tracking to work accurately, each user is required to go through an eye tracking user calibration.</span></span> 

<span data-ttu-id="0c1c0-138">![Dimensioni ottimali della destinazione a una distanza di 2 metri](images/gazetargeting-size-1000px.jpg)</span><span class="sxs-lookup"><span data-stu-id="0c1c0-138">![Optimal target size at 2 meter distance](images/gazetargeting-size-1000px.jpg)</span></span><br>
<span data-ttu-id="0c1c0-139">*Dimensioni di destinazione ottimali a distanza di 2 metri*</span><span class="sxs-lookup"><span data-stu-id="0c1c0-139">*Optimal target size at a 2-meter distance*</span></span>

<br>

## <a name="use-cases"></a><span data-ttu-id="0c1c0-140">Casi di utilizzo</span><span class="sxs-lookup"><span data-stu-id="0c1c0-140">Use cases</span></span>
<span data-ttu-id="0c1c0-141">Il tracciamento oculare consente alle applicazioni di tenere traccia di dove guarda l'utente in tempo reale.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-141">Eye tracking enables applications to track where the user is looking in real time.</span></span> <span data-ttu-id="0c1c0-142">I casi d'uso seguenti descrivono alcune interazioni possibili con la verifica degli occhi su HoloLens 2 in realtà mista.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-142">The following use cases describe some interactions that are possible with eye tracking on HoloLens 2 in mixed reality.</span></span>
<span data-ttu-id="0c1c0-143">Si noti che questi casi d'uso non fanno ancora parte dell'esperienza della shell olografica (ad esempio, l'interfaccia visualizzata quando si avvia HoloLens 2).</span><span class="sxs-lookup"><span data-stu-id="0c1c0-143">Please note that these use cases are not yet part of the Holographic Shell experience (i.e., the interface that you see when you start up your HoloLens 2).</span></span>
<span data-ttu-id="0c1c0-144">È possibile provare alcuni di essi nel Toolkit per [realtà mista](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) , che fornisce alcuni esempi interessanti e avanzati per l'uso degli occhi, ad esempio selezioni mirate, rapide e senza problemi, nonché lo scorrimento automatico in base al testo informazioni sull'aspetto dell'utente.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-144">You can try some of them out in the [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) which provides several interesting and powerful examples for using eye tracking, such as quick and effortless eye-supported target selections as well as automatically scrolling through text based on what the user looks at.</span></span> 

### <a name="user-intent"></a><span data-ttu-id="0c1c0-145">Intenzione dell'utente</span><span class="sxs-lookup"><span data-stu-id="0c1c0-145">User intent</span></span>    
<span data-ttu-id="0c1c0-146">Le informazioni su dove e cosa esamina un utente forniscono un **contesto potente per altri input**, ad esempio Voice, Hands e Controllers.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-146">Information about where and what a user looks at provides a powerful **context for other inputs**, such as voice, hands and controllers.</span></span>
<span data-ttu-id="0c1c0-147">Tali informazioni possono essere usate per diverse attività.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-147">This can be used for various tasks.</span></span>
<span data-ttu-id="0c1c0-148">Questo, ad esempio, può variare da un punto di vista rapido e semplice a quello della scena semplicemente esaminando un ologramma e pronunciando *"Select"* (vedere anche lo [sguardo e il commit](gaze-and-commit.md)) o dicendo *"put this..."* , quindi esaminando il percorso in cui l'utente desidera inserire l'ologramma e pronunciare *"... "* .</span><span class="sxs-lookup"><span data-stu-id="0c1c0-148">For example, this can range from quickly and effortlessly **targeting** across the scene by simply looking at a hologram and saying *"select"* (also see [gaze and commit](gaze-and-commit.md)) or by saying *"put this..."*, then looking over to where the user wants to place the hologram and say *"...there"*.</span></span> <span data-ttu-id="0c1c0-149">Per alcuni esempi, vedi [Mixed Reality Toolkit - Selezione della destinazione con lo sguardo](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html) e [Mixed Reality Toolkit - Posizionamento della destinazione con lo sguardo](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html).</span><span class="sxs-lookup"><span data-stu-id="0c1c0-149">Examples for this can be found in [Mixed Reality Toolkit - Eye-supported Target Selection](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html) and [Mixed Reality Toolkit - Eye-supported Target Positioning](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html).</span></span>

<span data-ttu-id="0c1c0-150">Inoltre, un esempio per finalità utente potrebbe includere l'uso di informazioni sugli elementi esaminati dagli utenti per migliorare l'engagement con agenti virtuali incorporati e ologrammi interattivi.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-150">Additionally, an example for user intent might include using information about what users look at to enhance engagement with embodied virtual agents and interactive holograms.</span></span> <span data-ttu-id="0c1c0-151">Ad esempio, gli agenti virtuali potrebbero adattare le opzioni disponibili e il relativo comportamento in base al contenuto attualmente visualizzato.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-151">For instance, virtual agents might adapt available options and their behavior based on currently viewed content.</span></span> 

### <a name="implicit-actions"></a><span data-ttu-id="0c1c0-152">Azioni implicite</span><span class="sxs-lookup"><span data-stu-id="0c1c0-152">Implicit actions</span></span>
<span data-ttu-id="0c1c0-153">La categoria delle azioni implicite è strettamente correlata all'intenzione dell'utente.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-153">The category of implicit actions closely relates to user intent.</span></span>
<span data-ttu-id="0c1c0-154">L'idea è che gli ologrammi o gli elementi dell'interfaccia utente reagiscono in maniera istintiva, che potrebbe non sembrare che l'utente stia interagendo con il sistema, ma piuttosto che il sistema e l'utente siano sincronizzati. Un esempio è lo **scorrimento automatico basato sull'occhio** , in cui l'utente può leggere un testo lungo che inizia automaticamente a scorrere dopo che l'utente si trova nella parte inferiore della casella di testo per impedire all'utente di leggere il flusso senza sollevare il dito.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-154">The idea is that holograms or user interface elements react in an instinctual way that may not even feel like the user is interacting with the system at all, but rather that the system and the user are in sync. One example is **eye-gaze-based auto scroll** where the user can read a long text which automatically starts scrolling once the user gets to the bottom of the textbox to keep the user in the flow of reading without lifting a finger.</span></span>  
<span data-ttu-id="0c1c0-155">Un aspetto fondamentale è che la velocità di scorrimento si adatta alla velocità di lettura dell'utente.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-155">A key aspect of this is that the scrolling speed adapts to the reading speed of the user.</span></span>
<span data-ttu-id="0c1c0-156">Un altro esempio è **lo zoom e la panoramica supportati dagli occhi,** in cui l'utente può avere la tendenza a concentrarsi esattamente su quello che si sta concentrando.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-156">Another example is **eye-supported zoom and pan** where the user can feel like diving exactly toward what he or she is focused on.</span></span> <span data-ttu-id="0c1c0-157">L'attivazione dello zoom e il controllo della velocità di zoom possono essere controllati da input voce o mano, che è importante per fornire all'utente la sensazione di controllo, evitando così la sovraccarica.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-157">Triggering zoom and controlling zoom speed can be controlled by voice or hand input, which is important for providing the user with the feeling of control while avoiding being overwhelmed.</span></span> <span data-ttu-id="0c1c0-158">Di seguito vengono descritte in dettaglio le considerazioni di progettazione.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-158">We will talk about these design considerations in more detail below.</span></span> <span data-ttu-id="0c1c0-159">Una volta eseguito lo zoom avanti, l'utente può seguire in modo semplice, ad esempio, il corso di una strada per esplorare il suo quartiere utilizzando semplicemente il proprio sguardo.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-159">Once zoomed in, the user can  smoothly follow, for example, the course of a street to explore his or her neighborhood by simply using their eye-gaze.</span></span>
<span data-ttu-id="0c1c0-160">Alcune demo di esempio per questi tipi di interazioni sono disponibili in [Mixed Reality Toolkit - Navigazione con gli occhi](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html).</span><span class="sxs-lookup"><span data-stu-id="0c1c0-160">Demo examples for these types of interactions can be found in the [Mixed Reality Toolkit - Eye-supported Navigation](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html) sample.</span></span>

<span data-ttu-id="0c1c0-161">Seguono altri casi di utilizzo per le _azioni implicite_:</span><span class="sxs-lookup"><span data-stu-id="0c1c0-161">Additional use cases for _implicit actions_ may include:</span></span>
- <span data-ttu-id="0c1c0-162">**Notifiche intelligenti:** Ci si annoia a ricevere le notifiche che si trovano nel punto in cui si sta cercando?</span><span class="sxs-lookup"><span data-stu-id="0c1c0-162">**Smart notifications:** Ever get annoyed by notifications popping up right where you are looking?</span></span> <span data-ttu-id="0c1c0-163">Prendendo in considerazione le informazioni a cui un utente presta attenzione, è possibile migliorare questa esperienza compensando le notifiche da cui l'utente sta attualmente guardando.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-163">Taking into account what a user is paying attention to, you can make this experience better by offsetting notifications from where the user is currently gazing.</span></span> <span data-ttu-id="0c1c0-164">Questo limita le distrazioni e le chiude automaticamente dopo che l'utente ha terminato la lettura.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-164">This limits distractions and automatically dismisses them once the user is finished reading.</span></span> 
- <span data-ttu-id="0c1c0-165">**Ologrammi attenti:** Olografici che reagiscono in maniera impercettibile quando si osservano.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-165">**Attentive holograms:** Holograms that subtly react when being gazed upon.</span></span> <span data-ttu-id="0c1c0-166">Questo può variare da elementi dell'interfaccia utente leggermente luminosi, un fiore lentamente fiorito a un cane virtuale che inizia a esaminare l'utente e scuotendo la coda.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-166">This can range from slightly glowing UI elements, a slowly blooming flower to a virtual dog starting to look back at the user and wagging its tail.</span></span> <span data-ttu-id="0c1c0-167">Questa interazione potrebbe offrire un'interessante sensazione di connettività e soddisfazione nell'applicazione.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-167">This interaction might provide an interesting sense of connectivity and satisfaction in your application.</span></span>

### <a name="attention-tracking"></a><span data-ttu-id="0c1c0-168">Tracciamento dell'attenzione</span><span class="sxs-lookup"><span data-stu-id="0c1c0-168">Attention tracking</span></span>   
<span data-ttu-id="0c1c0-169">Le informazioni su dove o quali utenti osservano possono essere uno strumento estremamente potente, che consente di valutare l'usabilità delle progettazioni e identificare i problemi nei flussi di lavoro per renderli più efficienti.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-169">Information about where or what users look at can be an immensely powerful tool – it can help assess usability of designs and identify problems in workflows to make them more efficient.</span></span>
<span data-ttu-id="0c1c0-170">La visualizzazione e l'analisi dei tracciati degli occhi sono una pratica comune in varie aree di applicazione.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-170">Eye tracking visualization and analytics are a common practice in various application areas.</span></span> <span data-ttu-id="0c1c0-171">Con HoloLens 2, viene fornita una nuova dimensione a questa comprensione perché gli ologrammi 3D possono essere inseriti in contesti reali e valutati di conseguenza.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-171">With HoloLens 2, we provide a new dimension to this understanding as 3D holograms can be placed in real-world contexts and assessed accordingly.</span></span> <span data-ttu-id="0c1c0-172">Il [Toolkit di realtà mista](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) fornisce esempi di base per la registrazione e il caricamento dei dati di rilevamento degli occhi e come visualizzarli.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-172">The [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) provides basic examples for logging and loading eye tracking data and how to visualize them.</span></span>
<span data-ttu-id="0c1c0-173">Microsoft è dedicata a facilitare l'innovazione garantendo al tempo stesso agli utenti un'esperienza informativa e trasparente con il modo in cui vengono usate le informazioni di rilevamento degli occhi.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-173">Microsoft is dedicated to facilitating innovation while ensuring that users are provided an informed and transparent experience with how their eye tracking information is used.</span></span>  <span data-ttu-id="0c1c0-174">Microsoft collaborerà con gli sviluppatori e i team UX per fornire indicazioni per le terze parti in grado di garantire che le esperienze siano incentrate sull'utente.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-174">We will work with our developers and UX teams to provide guidance for third parties that ensures experiences are centered around the user.</span></span>  


<span data-ttu-id="0c1c0-175">Di seguito sono riportate altre applicazioni in questo settore:</span><span class="sxs-lookup"><span data-stu-id="0c1c0-175">Other applications in this area may include:</span></span> 
-   <span data-ttu-id="0c1c0-176">**Visualizzazione sguardo remoto:** Visualizzazioni remote degli sguardi: è possibile visualizzare quali collaboratori remoti stanno cercando di fornire feedback immediato e facilitare l'elaborazione di informazioni più accurate.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-176">**Remote eye-gaze visualization:** Remote eye-gaze visualizations: Visualize what remote collaborators are looking at to be able to provide immediate feedback and facilitate more accurate information processing.</span></span>
-   <span data-ttu-id="0c1c0-177">**Studi di ricerca per gli utenti:** Il monitoraggio dell'attenzione può aiutare i ricercatori a ottenere maggiori informazioni sul modo in cui gli utenti percepiscono e si impegnano nell'ambiente naturale, senza interferire, per progettare interazioni tra computer umani più istintive.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-177">**User research studies:** Attention tracking can help researchers get more insights into how users perceive and engage with natural environment,  without interfering, to design more instinctual human-computer-interactions.</span></span> <span data-ttu-id="0c1c0-178">Il rilevamento degli occhi può fornire informazioni non direttamente articolate dai partecipanti allo studio, che altrimenti potrebbero essere facilmente perse dal ricercatore.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-178">Eye tracking can provide information that is not directly articulated by participants in the study, that otherwise might be easily missed by the researcher.</span></span> 
-   <span data-ttu-id="0c1c0-179">**Training e monitoraggio delle prestazioni:** Pratica e ottimizza l'esecuzione delle attività identificando i colli di bottiglia in modo più efficace nel flusso di esecuzione.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-179">**Training and performance monitoring:** Practice and optimize the execution of tasks by identifying bottlenecks more effectively in the execution flow.</span></span> <span data-ttu-id="0c1c0-180">Il monitoraggio degli occhi può fornire informazioni naturali, in tempo reale e obiettive per contribuire al miglioramento della formazione, della produttività e della sicurezza nell'area di lavoro.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-180">Eye tracking can provide natural, real-time and objective information to help improve training, productivity, and safety in the workplace.</span></span> 
-   <span data-ttu-id="0c1c0-181">**Valutazioni di progettazione, marketing e ricerca di utenti:** Il rilevamento degli occhi consente alle aziende commerciali di eseguire studi di marketing e consumer in ambienti reali o di analizzare ciò che acquisisce l'attenzione dell'utente per migliorare la progettazione del prodotto o dello spazio.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-181">**Design evaluations, marketing and consumer research:** Eye tracking enables commercial companies to perform marketing and consumer studies in real-world environments or analyze what captures user’s attention to improve product or space design.</span></span> 

### <a name="additional-use-cases"></a><span data-ttu-id="0c1c0-182">Altri casi di utilizzo</span><span class="sxs-lookup"><span data-stu-id="0c1c0-182">Additional use cases</span></span>
- <span data-ttu-id="0c1c0-183">**Giochi:** Hai mai voluto avere superpotenza?</span><span class="sxs-lookup"><span data-stu-id="0c1c0-183">**Gaming:** Ever wanted to have superpowers?</span></span> <span data-ttu-id="0c1c0-184">Ora hai questa opportunità.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-184">Here's your chance!</span></span> <span data-ttu-id="0c1c0-185">È possibile levitare gli ologrammi guardandoli.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-185">You can levitate holograms by staring at them.</span></span> <span data-ttu-id="0c1c0-186">Spara i raggi laser dagli occhi: Provalo in [RoboRaid per HoloLens 2](https://www.microsoft.com/p/roboraid/9nblggh5fv3j).</span><span class="sxs-lookup"><span data-stu-id="0c1c0-186">Shoot laser beams from your eyes - try it out in [RoboRaid for HoloLens 2](https://www.microsoft.com/p/roboraid/9nblggh5fv3j).</span></span>
<span data-ttu-id="0c1c0-187">Trasformare i nemici in pietra o bloccarli.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-187">Turn enemies into stone or freeze them.</span></span> <span data-ttu-id="0c1c0-188">oppure usare la tua vista a raggi x per esplorare l'interno degli edifici.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-188">Use your x-ray vision to explore buildings.</span></span> <span data-ttu-id="0c1c0-189">Insomma, con la tua immaginazione potrai superare ogni ostacolo.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-189">Your imagination is the limit!</span></span>
<span data-ttu-id="0c1c0-190">Prestare attenzione a non sovraccaricare l'utente. per saperne di più, consultare le [linee guida per la progettazione degli input basati su sguardi](eye-gaze-interaction.md).</span><span class="sxs-lookup"><span data-stu-id="0c1c0-190">Beware of not overwhelming the user though - to find out more, check out our [eye-gaze-based input design guidelines](eye-gaze-interaction.md).</span></span>

- <span data-ttu-id="0c1c0-191">**Avatar espressivi:** Il rilevamento degli occhi negli Avatar 3D più espressivi usa i dati di tracking degli occhi dinamici per animare gli occhi dell'avatar che indicano l'aspetto dell'utente.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-191">**Expressive avatars:** Eye tracking aids in more expressive 3D avatars by using live eye tracking data to animate the avatar's eyes that indicate what the user is looking at.</span></span> 

- <span data-ttu-id="0c1c0-192">**Voce di testo:** Il rilevamento degli occhi può essere usato come alternativa per la voce di testo a basso sforzo, soprattutto quando il discorso o le mani non sono convenienti da usare.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-192">**Text entry:** Eye tracking can be used as an alternative for low-effort text entry, especially when speech or hands are inconvenient to use.</span></span> 

<br>

## <a name="using-eye-gaze-for-interaction"></a><span data-ttu-id="0c1c0-193">Uso di Eye-sguardi per l'interazione</span><span class="sxs-lookup"><span data-stu-id="0c1c0-193">Using eye-gaze for interaction</span></span>
<span data-ttu-id="0c1c0-194">La creazione di un'interazione che sfrutta la scelta rapida per gli occhi in rapida evoluzione può risultare complessa.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-194">Building an interaction that takes advantage of fast-moving eye targeting can be challenging.</span></span>
<span data-ttu-id="0c1c0-195">Da un lato, gli occhi si muovono così velocemente che è necessario prestare attenzione a come usare l'input occhio, perché in caso contrario gli utenti potrebbero riscontrare un'esperienza travolgente o distrazione.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-195">On the one hand, the eyes move so fast that you need to be careful on how to use eye-gaze input, because otherwise users may find the experience overwhelming or distracting.</span></span> <span data-ttu-id="0c1c0-196">D'altra parte, è anche possibile creare esperienze realmente magiche che stimolano gli utenti.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-196">On the other hand, you can also create truly magical experiences that will excite your users!</span></span> <span data-ttu-id="0c1c0-197">Per aiutarti, Guarda la panoramica dei vantaggi principali, delle sfida e dei consigli di progettazione per gli occhi mirati [all'interazione](eye-gaze-interaction.md).</span><span class="sxs-lookup"><span data-stu-id="0c1c0-197">To help you, check out our overview of key advantages, challenges and design recommendations for [eye-gaze for interaction](eye-gaze-interaction.md).</span></span> 
 
## <a name="fallback-solutions-when-eye-tracking-is-not-available"></a><span data-ttu-id="0c1c0-198">Soluzioni di fallback quando la verifica degli occhi non è disponibile</span><span class="sxs-lookup"><span data-stu-id="0c1c0-198">Fallback solutions when eye tracking is not available</span></span>

<span data-ttu-id="0c1c0-199">In rari casi, i dati di rilevamento degli occhi potrebbero non essere disponibili.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-199">In rare cases eye tracking data might not be available.</span></span>
<span data-ttu-id="0c1c0-200">Questo problema può essere dovuto a diversi motivi per i quali più comuni sono elencati di seguito:</span><span class="sxs-lookup"><span data-stu-id="0c1c0-200">This can be due to different reasons from which the most common are listed below:</span></span>
* <span data-ttu-id="0c1c0-201">Il sistema non è riuscito a [calibrare l'utente](calibration.md).</span><span class="sxs-lookup"><span data-stu-id="0c1c0-201">The system failed to [calibrate the user](calibration.md).</span></span>
* <span data-ttu-id="0c1c0-202">La [calibrazione](calibration.md)è stata ignorata dall'utente.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-202">The user skipped the [calibration](calibration.md).</span></span>   
* <span data-ttu-id="0c1c0-203">L'utente è calibrato, ma ha deciso di non concedere all'app l'autorizzazione per l'uso dei dati di rilevamento degli occhi.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-203">The user is calibrated, but decided to not give permission to your app to use their eye tracking data.</span></span>    
* <span data-ttu-id="0c1c0-204">L'utente ha occhiali univoci o una condizione oculare che il sistema non supporta ancora.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-204">The user has unique eyeglasses or some eye condition that the system does not yet support.</span></span>    
* <span data-ttu-id="0c1c0-205">Fattori esterni che inibiscono il monitoraggio degli occhi affidabili, ad esempio le sbavature sulla visiera HoloLens o sugli occhiali, il sole intenso diretto e le occlusioni a causa dei capelli davanti agli occhi.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-205">External factors inhibiting reliable eye tracking such as smudges on the HoloLens visor or eyeglasses, intense direct sunlight and occlusions due to hair in front of the eyes.</span></span>   

<span data-ttu-id="0c1c0-206">Di conseguenza, gli sviluppatori devono assicurarsi che sia disponibile un supporto di fallback appropriato per questi utenti.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-206">Hence, developers should ensure that there is appropriate fallback support for these users.</span></span> <span data-ttu-id="0c1c0-207">Nella pagina relativa al [rilevamento degli occhi nella pagina DirectX](gaze-in-directx.md#fallback-when-eye-tracking-is-not-available) vengono illustrate le API necessarie per rilevare se i dati di rilevamento degli occhi sono disponibili.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-207">On the [Eye Tracking in DirectX](gaze-in-directx.md#fallback-when-eye-tracking-is-not-available) page, we explain the APIs required to detect whether eye tracking data is available.</span></span> 

<span data-ttu-id="0c1c0-208">Anche se alcuni utenti hanno deciso consapevolmente di revocare l'accesso ai dati di rilevamento degli occhi e sono OK con il compromesso di un'esperienza utente inferiore alla privacy di non fornire l'accesso ai dati di rilevamento degli occhi, in alcuni casi potrebbe non essere intenzionale.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-208">While some users may have consciously decided to revoke access to their eye tracking data and are ok with the trade-off of an inferior user experience to the privacy of not providing access to their eye tracking data, in some cases this may be unintentional.</span></span>  
<span data-ttu-id="0c1c0-209">Di conseguenza, se l'app usa la funzionalità di rilevamento degli occhi e si tratta di una parte importante dell'esperienza, è consigliabile comunicarla chiaramente all'utente.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-209">Hence, if your app uses eye tracking, and this is an important part of the experience, we recommend clearly communicating this to the user.</span></span>     
<span data-ttu-id="0c1c0-210">Si consiglia di informare l'utente sul motivo per cui la verifica degli occhi è cruciale per l'applicazione (forse anche elencando alcune funzionalità avanzate) per sperimentare il potenziale completo dell'applicazione può aiutare gli utenti a comprendere meglio ciò che stanno rinunciando.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-210">Kindly informing the user why eye tracking is critical for your application (maybe even listing some enhanced features) to experience the full potential of your application can help the user to better understand what they are giving up.</span></span>    
<span data-ttu-id="0c1c0-211">Consentire all'utente di identificare il motivo per cui la verifica degli occhi potrebbe non funzionare (in base ai controlli precedenti) e offre alcuni suggerimenti per risolvere rapidamente i potenziali problemi.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-211">Help the user to identify why eye tracking may not be working (based on the above checks) and offer some suggestions to quickly troubleshoot potential issues.</span></span>  
<span data-ttu-id="0c1c0-212">Se, ad esempio, è possibile rilevare che il sistema supporta la verifica degli occhi, l'utente viene calibrato e persino ha dato le autorizzazioni necessarie, ma non vengono ricevuti dati di rilevamento degli occhi, questo può puntare ad altri problemi, ad esempio le sbavature o gli occhi che vengono bloccati.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-212">For example, if you can detect that the system supports eye tracking, the user is calibrated and even has given their permission, yet no eye tracking data is received, then this may point to some other issues such as smudges or the eyes being occluded.</span></span>    
<span data-ttu-id="0c1c0-213">Si noti tuttavia che ci sono casi rari di utenti per i quali la verifica degli occhi potrebbe non funzionare semplicemente.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-213">Please note though that there are rare cases of users for whom eye tracking may simply not work.</span></span>    
<span data-ttu-id="0c1c0-214">Quindi, è opportuno rispettarlo consentendo di ignorare o addirittura disabilitare i promemoria per abilitare il rilevamento degli occhi nell'app.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-214">Hence, please be respectful of that by allowing to dismiss or even disable reminders for enabling eye tracking in your app.</span></span>

### <a name="fallback-for-apps-using-eye-gaze-as-a-primary-input-pointer"></a><span data-ttu-id="0c1c0-215">Fallback per le app che usano Eye-sguardi come puntatore di input primario</span><span class="sxs-lookup"><span data-stu-id="0c1c0-215">Fallback for apps using eye-gaze as a primary input pointer</span></span>
<span data-ttu-id="0c1c0-216">Se l'app usa Eye-sguardi come input del puntatore per selezionare rapidamente gli ologrammi nella scena, ma i dati di rilevamento degli occhi non sono disponibili, è consigliabile eseguire il fallback a Head-sguardi e iniziare a visualizzare il cursore Head-sguardi.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-216">If your app uses eye-gaze as a pointer input to quickly select holograms across the scene, yet eye tracking data is unavailable, we recommend falling back to head-gaze and start showing the head-gaze cursor.</span></span> <span data-ttu-id="0c1c0-217">È consigliabile usare un timeout (ad esempio, da 500 a 1500 ms) per determinare se passare o meno.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-217">We recommend using a timeout (e.g., 500–1500 ms) to determine whether to switch or not.</span></span> <span data-ttu-id="0c1c0-218">In questo modo si impedisce la comparsa di un cursore ogni volta che il sistema può perdere brevemente il rilevamento a causa di movimenti rapidi degli occhi o occhiolini.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-218">This is to prevent popping up a cursor every time the system may briefly lose tracking due to fast eye motions or winks and blinks.</span></span> <span data-ttu-id="0c1c0-219">Per gli sviluppatori di Unity, il fallback automatico a Head-sguardi è già gestito nel Toolkit per la realtà mista.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-219">If you are a Unity developer, the automatic fallback to head-gaze is already handled in the Mixed Reality Toolkit.</span></span> <span data-ttu-id="0c1c0-220">Se si è uno sviluppatore di DirectX, è necessario gestire manualmente questo switch.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-220">If you are a DirectX developer, you need to handle this switch yourself.</span></span>

### <a name="fallback-for-other-eye-tracking-specific-applications"></a><span data-ttu-id="0c1c0-221">Fallback per altre applicazioni specifiche per il rilevamento degli occhi</span><span class="sxs-lookup"><span data-stu-id="0c1c0-221">Fallback for other eye-tracking-specific applications</span></span>
<span data-ttu-id="0c1c0-222">L'app può usare gli sguardi in modo univoco in modo specifico per gli occhi, ad esempio per animare gli occhi di un avatar o per attirare l'attenzione su Heatmaps, che si basano su informazioni precise sull'attenzione visiva.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-222">Your app may use eye-gaze in a unique way that is tailored specifically to the eyes - for example, for animating an avatar’s eyes or for eye-based attention heatmaps relying on precise information about visual attention.</span></span> <span data-ttu-id="0c1c0-223">In questo caso, non esiste alcun fallback chiaro.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-223">In this case, there is no clear fallback.</span></span> <span data-ttu-id="0c1c0-224">Se il rilevamento degli occhi non è disponibile, è possibile che sia sufficiente disabilitare queste funzionalità.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-224">If eye tracking is not available, these capabilities may simply need to be disabled.</span></span>
<span data-ttu-id="0c1c0-225">Anche in questo caso, si consiglia di comunicare chiaramente questo problema all'utente che potrebbe non essere a conoscenza del funzionamento della funzionalità.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-225">Again, we recommend to clearly communicate this to the user who may be unaware that the capability is not working.</span></span>

<br>

<span data-ttu-id="0c1c0-226">In questa pagina è stata auspicata una panoramica approfondita per iniziare a comprendere il ruolo del rilevamento degli occhi e l'input degli sguardi per HoloLens 2.</span><span class="sxs-lookup"><span data-stu-id="0c1c0-226">This page has hopefully provided you with a good overview to get you started understanding the role of eye tracking and eye-gaze input for HoloLens 2.</span></span> <span data-ttu-id="0c1c0-227">Per iniziare lo sviluppo, consultare le informazioni sul ruolo di [sguardo attento per interagire con gli ologrammi](eye-gaze-interaction.md), osservare lo sguardo [in Unity](https://aka.ms/mrtk-eyes) e guardare gli [occhi in DirectX](gaze-in-directx.md).</span><span class="sxs-lookup"><span data-stu-id="0c1c0-227">To get started developing, check out our information on the role of [eye-gaze for interacting with holograms](eye-gaze-interaction.md), [eye-gaze in Unity](https://aka.ms/mrtk-eyes) and [eye-gaze in DirectX](gaze-in-directx.md).</span></span>


## <a name="see-also"></a><span data-ttu-id="0c1c0-228">Vedi anche</span><span class="sxs-lookup"><span data-stu-id="0c1c0-228">See also</span></span>
* [<span data-ttu-id="0c1c0-229">Calibrazione</span><span class="sxs-lookup"><span data-stu-id="0c1c0-229">Calibration</span></span>](calibration.md)
* [<span data-ttu-id="0c1c0-230">Comodità</span><span class="sxs-lookup"><span data-stu-id="0c1c0-230">Comfort</span></span>](comfort.md)
* [<span data-ttu-id="0c1c0-231">Interazione basata su sguardo fisso</span><span class="sxs-lookup"><span data-stu-id="0c1c0-231">Eye-gaze-based interaction</span></span>](eye-gaze-interaction.md)
* [<span data-ttu-id="0c1c0-232">Eye-sguardi in DirectX</span><span class="sxs-lookup"><span data-stu-id="0c1c0-232">Eye-gaze in DirectX</span></span>](gaze-in-directx.md)
* [<span data-ttu-id="0c1c0-233">Eye-sguardi in Unity (Toolkit realtà mista)</span><span class="sxs-lookup"><span data-stu-id="0c1c0-233">Eye-gaze in Unity (Mixed Reality Toolkit)</span></span>](https://aka.ms/mrtk-eyes)
* [<span data-ttu-id="0c1c0-234">Sguardo e commit</span><span class="sxs-lookup"><span data-stu-id="0c1c0-234">Gaze and commit</span></span>](gaze-and-commit.md)
* [<span data-ttu-id="0c1c0-235">Input vocale</span><span class="sxs-lookup"><span data-stu-id="0c1c0-235">Voice input</span></span>](voice-design.md)


