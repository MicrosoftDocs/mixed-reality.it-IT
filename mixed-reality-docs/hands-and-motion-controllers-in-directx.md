---
title: Le mani e i controller di movimento in DirectX
description: Guida per sviluppatori per l'uso di rilevamento disponibili e i controller di movimento in native nelle App DirectX.
author: caseymeekhof
ms.author: cmeekhof
ms.date: 04/30/2019
ms.topic: article
keywords: le mani, i controller di movimento, directx, input, vntana
ms.openlocfilehash: 08666c8c26cd4851c0c003a96a9e96d7a90228ac
ms.sourcegitcommit: 45676da11ebe33a2aa3dccec0e8ad7d714420853
ms.translationtype: MT
ms.contentlocale: it-IT
ms.lasthandoff: 05/15/2019
ms.locfileid: "65629644"
---
# <a name="hands-and-motion-controllers-in-directx"></a><span data-ttu-id="251c6-104">Le mani e i controller di movimento in DirectX</span><span class="sxs-lookup"><span data-stu-id="251c6-104">Hands and motion controllers in DirectX</span></span>

<span data-ttu-id="251c6-105">Nella realtà mista di Windows, sia a essere passate e [controller di movimento](motion-controllers.md) input viene gestito tramite l'input spaziale API, disponibili nel [Windows.UI.Input.Spatial](https://docs.microsoft.com/uwp/api/windows.ui.input.spatial) dello spazio dei nomi.</span><span class="sxs-lookup"><span data-stu-id="251c6-105">In Windows Mixed Reality, both hand and [motion controller](motion-controllers.md) input is handled through the spatial input APIs, found in the [Windows.UI.Input.Spatial](https://docs.microsoft.com/uwp/api/windows.ui.input.spatial) namespace.</span></span> <span data-ttu-id="251c6-106">In questo modo è possibile gestire facilmente le azioni comuni, ad esempio **seleziona** preme allo stesso modo attraverso le mani sia i controller di movimento.</span><span class="sxs-lookup"><span data-stu-id="251c6-106">This enables you to easily handle common actions like **Select** presses the same way across both hands and motion controllers.</span></span>

## <a name="getting-started"></a><span data-ttu-id="251c6-107">Attività iniziali</span><span class="sxs-lookup"><span data-stu-id="251c6-107">Getting started</span></span>

<span data-ttu-id="251c6-108">Per accedere a spaziale di input in realtà mista di Windows, iniziare con l'interfaccia SpatialInteractionManager.</span><span class="sxs-lookup"><span data-stu-id="251c6-108">To access spatial input in Windows Mixed Reality, start with the SpatialInteractionManager interface.</span></span>  <span data-ttu-id="251c6-109">È possibile accedere all'interfaccia chiamando [SpatialInteractionManager::GetForCurrentView](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.getforcurrentview), in genere a volte durante l'avvio dell'app.</span><span class="sxs-lookup"><span data-stu-id="251c6-109">You can access this interface by calling  [SpatialInteractionManager::GetForCurrentView](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.getforcurrentview), typically sometime during app startup.</span></span>

```cpp
using namespace winrt::Windows::UI::Input::Spatial;

SpatialInteractionManager interactionManager = SpatialInteractionManager::GetForCurrentView();
```

<span data-ttu-id="251c6-110">Processo del SpatialInteractionManager consiste nel fornire l'accesso a [SpatialInteractionSources](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsource), che rappresenta un'origine di input.</span><span class="sxs-lookup"><span data-stu-id="251c6-110">The SpatialInteractionManager's job is to provide access to [SpatialInteractionSources](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsource), which represent a source of input.</span></span>  <span data-ttu-id="251c6-111">Sono disponibili tre tipi di SpatialInteractionSources nel sistema.</span><span class="sxs-lookup"><span data-stu-id="251c6-111">There are three kinds of SpatialInteractionSources available in the system.</span></span>
* <span data-ttu-id="251c6-112">**Mano** rappresenta mano rilevato dell'utente.</span><span class="sxs-lookup"><span data-stu-id="251c6-112">**Hand** represents a user's detected hand.</span></span> <span data-ttu-id="251c6-113">Origini disponibili offrono diverse funzionalità in base al dispositivo, compreso tra i movimenti di base su HoloLens mano completamente articolati e di rilevamento in 2 HoloLens.</span><span class="sxs-lookup"><span data-stu-id="251c6-113">Hand sources offer different features based on the device, ranging from basic gestures on HoloLens to fully articulated hand tracking on HoloLens 2.</span></span> 
* <span data-ttu-id="251c6-114">**Controller** rappresenta un controller di movimento associati.</span><span class="sxs-lookup"><span data-stu-id="251c6-114">**Controller** represents a paired motion controller.</span></span> <span data-ttu-id="251c6-115">I controller di movimento possono offrire un'ampia gamma di funzionalità.</span><span class="sxs-lookup"><span data-stu-id="251c6-115">Motion controllers can offer a variety of capabilities.</span></span>  <span data-ttu-id="251c6-116">Ad esempio:  Selezionare i trigger, pulsanti di Menu, pulsanti. é quindi, touchpad multipli e levette.</span><span class="sxs-lookup"><span data-stu-id="251c6-116">For example: Select triggers, Menu buttons, Grasp buttons, touchpads and thumbsticks.</span></span>
* <span data-ttu-id="251c6-117">**Voce** rappresenta la voce dell'utente a proposito di sistema ha rilevato le parole chiave.</span><span class="sxs-lookup"><span data-stu-id="251c6-117">**Voice** represents the user's voice speaking system-detected keywords.</span></span> <span data-ttu-id="251c6-118">Questa origine verrà, ad esempio, inserire una pressione Seleziona e rilasciare ogni volta che l'utente afferma "Select".</span><span class="sxs-lookup"><span data-stu-id="251c6-118">For example, this source will inject a Select press and release whenever the user says "Select".</span></span>

<span data-ttu-id="251c6-119">Per frame dei dati per un'origine è rappresentata dal [SpatialInteractionSourceState](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate) interfaccia.</span><span class="sxs-lookup"><span data-stu-id="251c6-119">Per-frame data for a source is represented by the  [SpatialInteractionSourceState](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate) interface.</span></span> <span data-ttu-id="251c6-120">Esistono due modi diversi per accedere a questi dati, a seconda che si voglia usare un modello basato sugli eventi o basati su polling nell'applicazione.</span><span class="sxs-lookup"><span data-stu-id="251c6-120">There are two different ways to access this data, depending on whether you want to use an event-driven or polling-based model in your application.</span></span>

### <a name="event-driven-input"></a><span data-ttu-id="251c6-121">Input basato su eventi</span><span class="sxs-lookup"><span data-stu-id="251c6-121">Event-driven input</span></span>
<span data-ttu-id="251c6-122">Il SpatialInteractionManager fornisce una serie di eventi che può essere in ascolto l'app.</span><span class="sxs-lookup"><span data-stu-id="251c6-122">The SpatialInteractionManager provides a number of events that your app can listen for.</span></span>  <span data-ttu-id="251c6-123">Alcuni esempi includono [SourcePressed](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcepressed), [SourceReleased](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcereleased) e [SourceUpdated](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourceupdated).</span><span class="sxs-lookup"><span data-stu-id="251c6-123">A few examples include   [SourcePressed](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcepressed), [SourceReleased](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcereleased) and [SourceUpdated](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourceupdated).</span></span>

<span data-ttu-id="251c6-124">Ad esempio, il codice seguente associa un gestore eventi chiamato MyApp::OnSourcePressed all'evento SourcePressed.</span><span class="sxs-lookup"><span data-stu-id="251c6-124">For example, the following code hooks up an event handler called MyApp::OnSourcePressed to the SourcePressed event.</span></span>  <span data-ttu-id="251c6-125">In questo modo l'app rilevare le pressioni in qualsiasi tipo di origine di interazione.</span><span class="sxs-lookup"><span data-stu-id="251c6-125">This allows your app to detect presses on any type of interaction source.</span></span>

```cpp
using namespace winrt::Windows::UI::Input::Spatial;

auto interactionManager = SpatialInteractionManager::GetForCurrentView();
interactionManager.SourcePressed({ this, &MyApp::OnSourcePressed });

```

<span data-ttu-id="251c6-126">Questo evento premuto viene inviato all'App in modo asincrono, insieme al SpatialInteractionSourceState corrispondente al momento che si è verificata la pressione.</span><span class="sxs-lookup"><span data-stu-id="251c6-126">This pressed event is sent to your app asynchronously, along with the corresponding SpatialInteractionSourceState at the time the press happened.</span></span> <span data-ttu-id="251c6-127">L'app o il motore di gioco potrebbe essere necessario eseguire alcune operazioni di elaborazione sin da subito oppure è possibile accodare i dati dell'evento nelle routine di elaborazione dell'input.</span><span class="sxs-lookup"><span data-stu-id="251c6-127">Your app or game engine may want to perform some processing right away or you may want to queue up the event data in your input processing routine.</span></span> <span data-ttu-id="251c6-128">Di seguito è una funzione del gestore eventi per l'evento SourcePressed, che illustra come controllare se è stato premuto il pulsante di selezione.</span><span class="sxs-lookup"><span data-stu-id="251c6-128">Here is an event handler function for the SourcePressed event, which shows how to check whether the select button was pressed.</span></span>

```cpp
using namespace winrt::Windows::UI::Input::Spatial;

void MyApp::OnSourcePressed(SpatialInteractionManager const& sender, SpatialInteractionSourceEventArgs const& args)
{
    if (args.PressKind() == SpatialInteractionPressKind::Select)
    {
        // Select button was pressed, update app state
    }
}
```

<span data-ttu-id="251c6-129">Il codice precedente verifica solo per la stampa 'Select', che corrisponde all'azione principale nel dispositivo.</span><span class="sxs-lookup"><span data-stu-id="251c6-129">The above code only checks for the 'Select' press, which corresponds to the primary action on the device.</span></span> <span data-ttu-id="251c6-130">Ad esempio eseguire un'AirTap su HoloLens o il pull del trigger in un controller di movimento.</span><span class="sxs-lookup"><span data-stu-id="251c6-130">Examples include doing an AirTap on HoloLens or pulling the trigger on a motion controller.</span></span>  <span data-ttu-id="251c6-131">'Select' pressioni rappresentano l'intenzione dell'utente per attivare l'ologrammi che di destinazione.</span><span class="sxs-lookup"><span data-stu-id="251c6-131">'Select' presses represent the user's intention to activate the hologram they are targeting.</span></span>  <span data-ttu-id="251c6-132">Verrà generato l'evento SourcePressed per un numero di diversi pulsanti e i movimenti ed è possibile esaminare le altre proprietà in SpatialInteractionSource per eseguire il test per i casi.</span><span class="sxs-lookup"><span data-stu-id="251c6-132">The SourcePressed event will fire for a number of different buttons and gestures, and you can inspect other properties on the SpatialInteractionSource to test for those cases.</span></span>

### <a name="polling-based-input"></a><span data-ttu-id="251c6-133">Input basati su polling</span><span class="sxs-lookup"><span data-stu-id="251c6-133">Polling-based input</span></span>
<span data-ttu-id="251c6-134">È anche possibile usare SpatialInteractionManager per eseguire il polling ogni fotogramma per lo stato corrente dell'input.</span><span class="sxs-lookup"><span data-stu-id="251c6-134">You can also use SpatialInteractionManager to poll for the current state of input every frame.</span></span>  <span data-ttu-id="251c6-135">A tale scopo, è sufficiente chiamare [GetDetectedSourcesAtTimestamp](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.getdetectedsourcesattimestamp) ogni fotogramma.</span><span class="sxs-lookup"><span data-stu-id="251c6-135">To do this, simply call [GetDetectedSourcesAtTimestamp](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.getdetectedsourcesattimestamp) every frame.</span></span>  <span data-ttu-id="251c6-136">Questa funzione restituisce una matrice contenente uno [SpatialInteractionSourceState](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate) per ogni attivo [SpatialInteractionSource](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsource).</span><span class="sxs-lookup"><span data-stu-id="251c6-136">This function returns an array containing one [SpatialInteractionSourceState](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate) for every active [SpatialInteractionSource](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsource).</span></span> <span data-ttu-id="251c6-137">Ciò significa, uno per ogni controller attivo del movimento, uno per ogni indicatore rilevate e uno per i dialoghi se un comando 'select' è stato recentemente pronunciato.</span><span class="sxs-lookup"><span data-stu-id="251c6-137">This means one for each active motion controller, one for each tracked hand, and one for speech if a 'select' command was recently uttered.</span></span> <span data-ttu-id="251c6-138">È quindi possibile esaminare le proprietà in ogni SpatialInteractionSourceState all'input dell'unità all'interno dell'applicazione.</span><span class="sxs-lookup"><span data-stu-id="251c6-138">You can then inspect the properties on each SpatialInteractionSourceState to drive input into your application.</span></span> 

<span data-ttu-id="251c6-139">Ecco un esempio di come verificare l'azione 'select' utilizzando il metodo di polling.</span><span class="sxs-lookup"><span data-stu-id="251c6-139">Here is an example of how to check for the 'select' action using the polling method.</span></span> <span data-ttu-id="251c6-140">Si noti che il *prediction* variabile rappresenta un [HolographicFramePrediction](https://docs.microsoft.com/en-us/uwp/api/Windows.Graphics.Holographic.HolographicFramePrediction) oggetto, che può essere ottenuto dal [HolographicFrame](https://docs.microsoft.com/en-us/uwp/api/windows.graphics.holographic.holographicframe).</span><span class="sxs-lookup"><span data-stu-id="251c6-140">Note that the *prediction* variable represents a [HolographicFramePrediction](https://docs.microsoft.com/en-us/uwp/api/Windows.Graphics.Holographic.HolographicFramePrediction) object, which can be obtained from the [HolographicFrame](https://docs.microsoft.com/en-us/uwp/api/windows.graphics.holographic.holographicframe).</span></span>

```cpp
using namespace winrt::Windows::UI::Input::Spatial;

auto interactionManager = SpatialInteractionManager::GetForCurrentView();
auto sourceStates = m_spatialInteractionManager.GetDetectedSourcesAtTimestamp(prediction.Timestamp());

for (auto& sourceState : sourceStates)
{
    if (sourceState.IsSelectPressed())
    {
        // Select button is down, update app state
    }
}
```

<span data-ttu-id="251c6-141">Ogni SpatialInteractionSource ha un ID, che è possibile usare per identificare le origini nuova e correlare le origini esistenti da un fotogramma per fotogramma.</span><span class="sxs-lookup"><span data-stu-id="251c6-141">Each SpatialInteractionSource has an ID, which you can use to identify new sources and correlate existing sources from frame to frame.</span></span>  <span data-ttu-id="251c6-142">Mani vengono assegnate un ID di nuovo ogni volta che possono lasciare e immettere il campo di visualizzazione, ma gli ID controller restano statici per la durata della sessione.</span><span class="sxs-lookup"><span data-stu-id="251c6-142">Hands are assigned a new ID every time they leave and enter the FOV, but controller IDs remain static for the duration of the session.</span></span>  <span data-ttu-id="251c6-143">È possibile usare, ad esempio gli eventi in SpatialInteractionManager [SourceDetected](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcedetected) e [SourceLost](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcelost), per rispondere al mani immettono o lasciare il dispositivo di visualizzazione o quando i controller di movimento sono attivati/disattivato o sono abbinate/non abbinato.</span><span class="sxs-lookup"><span data-stu-id="251c6-143">You can use the events on SpatialInteractionManager such as [SourceDetected](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcedetected) and [SourceLost](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcelost), to react when hands enter or leave the device's view, or when motion controllers are turned on/off or are paired/unpaired.</span></span>

### <a name="predicted-vs-historical-poses"></a><span data-ttu-id="251c6-144">Prevedere e può causare cronologici</span><span class="sxs-lookup"><span data-stu-id="251c6-144">Predicted vs. historical poses</span></span>
<span data-ttu-id="251c6-145">Si noti che GetDetectedSourcesAtTimestamp ha un parametro di timestamp.</span><span class="sxs-lookup"><span data-stu-id="251c6-145">Note that GetDetectedSourcesAtTimestamp has a timestamp parameter.</span></span> <span data-ttu-id="251c6-146">In questo modo è possibile richiedere lo stato e presentare i dati sia stimato o cronologici e ciò consente correlare spaziali interazioni con altre origini di input.</span><span class="sxs-lookup"><span data-stu-id="251c6-146">This enables you to request state and pose data that is either predicted or historical, letting you correlate spatial interactions with other sources of input.</span></span> <span data-ttu-id="251c6-147">Ad esempio, durante il rendering di posizione dell'icona della mano nel frame corrente, è possibile passare il timestamp stimato fornito dal [HolographicFrame](https://docs.microsoft.com/en-us/uwp/api/windows.graphics.holographic.holographicframe).</span><span class="sxs-lookup"><span data-stu-id="251c6-147">For example, when rendering the hand's position in the current frame, you can pass in the predicted timestamp provided by the [HolographicFrame](https://docs.microsoft.com/en-us/uwp/api/windows.graphics.holographic.holographicframe).</span></span> <span data-ttu-id="251c6-148">Ciò consente al sistema di forward-prevedere la posizione di mano ai fini corretto allineamento con l'output di frame sottoposto a rendering, riducendo al minimo la latenza percepita.</span><span class="sxs-lookup"><span data-stu-id="251c6-148">This enables the system to forward-predict the hand position to closely align with the rendered frame output, minimizing perceived latency.</span></span>

<span data-ttu-id="251c6-149">Tuttavia, questo tipo una posa stimata non produce un raggio di puntamento ideale per lo sviluppo con un'origine di interazione per.</span><span class="sxs-lookup"><span data-stu-id="251c6-149">However, such a predicted pose does not produce an ideal pointing ray for targeting with an interaction source.</span></span> <span data-ttu-id="251c6-150">Ad esempio, quando viene premuto un pulsante di controller di movimento, può richiedere fino a 20 ms per l'evento di bubbling tramite Bluetooth al sistema operativo.</span><span class="sxs-lookup"><span data-stu-id="251c6-150">For example, when a motion controller button is pressed, it can take up to 20ms for that event to bubble up through Bluetooth to the operating system.</span></span> <span data-ttu-id="251c6-151">Allo stesso modo, dopo che un utente ha eseguito un'azione manuale, determinato intervallo di tempo può trascorrere prima che il sistema rileva il movimento e l'app, quindi esegue il polling per tale.</span><span class="sxs-lookup"><span data-stu-id="251c6-151">Similarly, after a user performs a hand gesture, some amount of time may pass before the system detects the gesture and your app then polls for it.</span></span> <span data-ttu-id="251c6-152">Una volta l'app esegue il polling di una modifica dello stato, può causare l'intestazione e il trasferimento di consente di destinazione che in passato è effettivamente successo l'interazione.</span><span class="sxs-lookup"><span data-stu-id="251c6-152">By the time your app polls for a state change, the head and hand poses used to target that interaction actually happened in the past.</span></span> <span data-ttu-id="251c6-153">Se la destinazione è passando il timestamp di HolographicFrame corrente a GetDetectedSourcesAtTimestamp, la posa verrà invece inoltrare eseguita la stima per il raggio di destinazione al momento che verrà visualizzato il frame, che può essere più di 20 ms in futuro.</span><span class="sxs-lookup"><span data-stu-id="251c6-153">If you target by passing your current HolographicFrame's timestamp to GetDetectedSourcesAtTimestamp, the pose will instead be forward predicted to the targeting ray at the time the frame will be displayed, which could be more than 20ms in the future.</span></span> <span data-ttu-id="251c6-154">Source sia vantaggioso per il futuro posa *rendering* l'origine di interazione, ma si sommano il problema in fase di *destinate a* interazione, come la destinazione è l'utente si è verificato in passato.</span><span class="sxs-lookup"><span data-stu-id="251c6-154">This future pose is good for *rendering* the interaction source, but compounds our time problem for *targeting* the interaction, as the user's targeting occurred in the past.</span></span>

<span data-ttu-id="251c6-155">Per fortuna, il [SourcePressed](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcepressed), [SourceReleased](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcereleased) e [SourceUpdated](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourceupdated) eventi forniscono la cronologia [stato](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourceeventargs.state) associato ogni evento di input.</span><span class="sxs-lookup"><span data-stu-id="251c6-155">Fortunately, the [SourcePressed](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcepressed), [SourceReleased](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcereleased) and [SourceUpdated](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourceupdated) events provide the historical [State](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourceeventargs.state) associated with each input event.</span></span>  <span data-ttu-id="251c6-156">Ciò include direttamente i cronologici head e mano pose disponibili tramite [TryGetPointerPose](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.trygetpointerpose), insieme a un cronologici [Timestamp](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.timestamp) che è possibile passare ad altre API per la correlazione con questo evento.</span><span class="sxs-lookup"><span data-stu-id="251c6-156">This directly includes the historical head and hand poses available through [TryGetPointerPose](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.trygetpointerpose), along with a historical [Timestamp](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.timestamp) that you can pass to other APIs to correlate with this event.</span></span>

<span data-ttu-id="251c6-157">Ciò porta per le procedure consigliate seguenti durante il rendering e selezione di destinazioni con controller e le mani ogni frame:</span><span class="sxs-lookup"><span data-stu-id="251c6-157">That leads to the following best practices when rendering and targeting with hands and controllers each frame:</span></span>
* <span data-ttu-id="251c6-158">Per la **per il rendering manuale/controller** ogni fotogramma, l'app deve **polling** per il **stimato forward** comportare di ogni origine di interazione in fase di photon del frame corrente.</span><span class="sxs-lookup"><span data-stu-id="251c6-158">For **hand/controller rendering** each frame, your app should **poll** for the **forward-predicted** pose of each interaction source at the current frame’s photon time.</span></span>  <span data-ttu-id="251c6-159">È possibile eseguire il polling per tutte le origini di interazione chiamando [GetDetectedSourcesAtTimestamp](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.getdetectedsourcesattimestamp) ogni fotogramma, passando il timestamp stimato fornito da [HolographicFrame::CurrentPrediction](https://docs.microsoft.com/en-us/uwp/api/windows.graphics.holographic.holographicframe.currentprediction).</span><span class="sxs-lookup"><span data-stu-id="251c6-159">You can poll for all interaction sources by calling [GetDetectedSourcesAtTimestamp](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.getdetectedsourcesattimestamp) each frame, passing in the predicted timestamp provided by [HolographicFrame::CurrentPrediction](https://docs.microsoft.com/en-us/uwp/api/windows.graphics.holographic.holographicframe.currentprediction).</span></span>
* <span data-ttu-id="251c6-160">Per **destinate a mano/controller** durante una pressione o una versione, l'app deve gestire premuto o rilasciato **eventi**, raycasting base il **cronologici** posa head o manualmente per tale evento.</span><span class="sxs-lookup"><span data-stu-id="251c6-160">For **hand/controller targeting** upon a press or release, your app should handle pressed/released **events**, raycasting based on the **historical** head or hand pose for that event.</span></span> <span data-ttu-id="251c6-161">Si ottiene questo ray targeting gestendo il [SourcePressed](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcepressed) o [SourceReleased](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcereleased) evento, recupero il [stato](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourceeventargs.state) proprietà dagli argomenti dell'evento e chiamando quindi il [ TryGetPointerPose](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.trygetpointerpose) (metodo).</span><span class="sxs-lookup"><span data-stu-id="251c6-161">You get this targeting ray by handling the [SourcePressed](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcepressed) or [SourceReleased](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcereleased) event, getting the [State](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourceeventargs.state) property from the event arguments, and then calling its [TryGetPointerPose](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.trygetpointerpose) method.</span></span>

## <a name="cross-device-input-properties"></a><span data-ttu-id="251c6-162">Proprietà di input di più dispositivi</span><span class="sxs-lookup"><span data-stu-id="251c6-162">Cross-device input properties</span></span>
<span data-ttu-id="251c6-163">L'API SpatialInteractionSource supporta i controller e il trasferimento di sistemi con un'ampia gamma di funzionalità di rilevamento.</span><span class="sxs-lookup"><span data-stu-id="251c6-163">The SpatialInteractionSource API supports controllers and hand tracking systems with a wide range of capabilities.</span></span> <span data-ttu-id="251c6-164">Un numero di queste funzionalità è comune tra i tipi di dispositivo.</span><span class="sxs-lookup"><span data-stu-id="251c6-164">A number of these capabilities are common between device types.</span></span> <span data-ttu-id="251c6-165">Ad esempio, mano rilevamento movimento controller ed entrambi forniscono un'azione 'select' e alla posizione 3D.</span><span class="sxs-lookup"><span data-stu-id="251c6-165">For example, hand tracking and motion controllers both provide a 'select' action and a 3D position.</span></span> <span data-ttu-id="251c6-166">Laddove possibile, l'API esegue il mapping di queste funzionalità comuni per le stesse proprietà nel SpatialInteractionSource.</span><span class="sxs-lookup"><span data-stu-id="251c6-166">Wherever possible, the API maps these common capabilities to the same properties on the SpatialInteractionSource.</span></span>  <span data-ttu-id="251c6-167">Ciò consente alle applicazioni di supportare più facilmente un'ampia gamma di tipi di input.</span><span class="sxs-lookup"><span data-stu-id="251c6-167">This enables applications to more easily support a wide range of input types.</span></span> <span data-ttu-id="251c6-168">Nella tabella seguente vengono descritte le proprietà supportate e le modalità di confronto tra i tipi di input.</span><span class="sxs-lookup"><span data-stu-id="251c6-168">The following table describes the properties that are supported, and how they compare across input types.</span></span>

| <span data-ttu-id="251c6-169">Proprietà</span><span class="sxs-lookup"><span data-stu-id="251c6-169">Property</span></span> | <span data-ttu-id="251c6-170">Descrizione</span><span class="sxs-lookup"><span data-stu-id="251c6-170">Description</span></span> | <span data-ttu-id="251c6-171">Movimenti di HoloLens</span><span class="sxs-lookup"><span data-stu-id="251c6-171">HoloLens Gestures</span></span> | <span data-ttu-id="251c6-172">Controller di movimento</span><span class="sxs-lookup"><span data-stu-id="251c6-172">Motion Controllers</span></span> | <span data-ttu-id="251c6-173">Articolati e mani</span><span class="sxs-lookup"><span data-stu-id="251c6-173">Articulated Hands</span></span>|
|--- |--- |--- |--- |--- |
| [<span data-ttu-id="251c6-174">SpatialInteractionSource::**Handedness**</span><span class="sxs-lookup"><span data-stu-id="251c6-174">SpatialInteractionSource::**Handedness**</span></span>](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsource.handedness) | <span data-ttu-id="251c6-175">A sinistra o destra / controller.</span><span class="sxs-lookup"><span data-stu-id="251c6-175">Right or left hand / controller.</span></span> | <span data-ttu-id="251c6-176">Non supportato</span><span class="sxs-lookup"><span data-stu-id="251c6-176">Not Supported</span></span> | <span data-ttu-id="251c6-177">Supportato</span><span class="sxs-lookup"><span data-stu-id="251c6-177">Supported</span></span> | <span data-ttu-id="251c6-178">Supportato</span><span class="sxs-lookup"><span data-stu-id="251c6-178">Supported</span></span> |
| [<span data-ttu-id="251c6-179">SpatialInteractionSourceState::**IsSelectPressed**</span><span class="sxs-lookup"><span data-stu-id="251c6-179">SpatialInteractionSourceState::**IsSelectPressed**</span></span>](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.isselectpressed) | <span data-ttu-id="251c6-180">Stato corrente del pulsante principale.</span><span class="sxs-lookup"><span data-stu-id="251c6-180">Current state of the primary button.</span></span> | <span data-ttu-id="251c6-181">Indice puntato</span><span class="sxs-lookup"><span data-stu-id="251c6-181">Air Tap</span></span> | <span data-ttu-id="251c6-182">Trigger</span><span class="sxs-lookup"><span data-stu-id="251c6-182">Trigger</span></span> | <span data-ttu-id="251c6-183">Tipo "relaxed" aria toccare (zoom indietro verticale)</span><span class="sxs-lookup"><span data-stu-id="251c6-183">Relaxed Air Tap (upright pinch)</span></span> |
| [<span data-ttu-id="251c6-184">SpatialInteractionSourceState::**IsGrasped**</span><span class="sxs-lookup"><span data-stu-id="251c6-184">SpatialInteractionSourceState::**IsGrasped**</span></span>](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.isgrasped) | <span data-ttu-id="251c6-185">Stato corrente del pulsante con quadratini di ridimensionamento.</span><span class="sxs-lookup"><span data-stu-id="251c6-185">Current state of the grab button.</span></span> | <span data-ttu-id="251c6-186">Non supportato</span><span class="sxs-lookup"><span data-stu-id="251c6-186">Not Supported</span></span> | <span data-ttu-id="251c6-187">Pulsante di quadratini di ridimensionamento</span><span class="sxs-lookup"><span data-stu-id="251c6-187">Grab button</span></span> | <span data-ttu-id="251c6-188">Zoom indietro o chiuso manualmente</span><span class="sxs-lookup"><span data-stu-id="251c6-188">Pinch or Closed Hand</span></span> |
| [<span data-ttu-id="251c6-189">SpatialInteractionSourceState::**IsMenuPressed**</span><span class="sxs-lookup"><span data-stu-id="251c6-189">SpatialInteractionSourceState::**IsMenuPressed**</span></span>](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.ismenupressed) | <span data-ttu-id="251c6-190">Stato corrente del pulsante di menu.</span><span class="sxs-lookup"><span data-stu-id="251c6-190">Current state of the menu button.</span></span>    | <span data-ttu-id="251c6-191">Non supportato</span><span class="sxs-lookup"><span data-stu-id="251c6-191">Not Supported</span></span> | <span data-ttu-id="251c6-192">Pulsante di menu</span><span class="sxs-lookup"><span data-stu-id="251c6-192">Menu Button</span></span> | <span data-ttu-id="251c6-193">Non supportato</span><span class="sxs-lookup"><span data-stu-id="251c6-193">Not Supported</span></span> |
| [<span data-ttu-id="251c6-194">SpatialInteractionSourceLocation::**Position**</span><span class="sxs-lookup"><span data-stu-id="251c6-194">SpatialInteractionSourceLocation::**Position**</span></span>](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcelocation.position) | <span data-ttu-id="251c6-195">Percorso XYZ della posizione del triangolo di ridimensionamento o manualmente nel controller.</span><span class="sxs-lookup"><span data-stu-id="251c6-195">XYZ location of the hand or grip position on the controller.</span></span> | <span data-ttu-id="251c6-196">Percorso Palm</span><span class="sxs-lookup"><span data-stu-id="251c6-196">Palm location</span></span> | <span data-ttu-id="251c6-197">Triangolo di ridimensionamento posa posizione</span><span class="sxs-lookup"><span data-stu-id="251c6-197">Grip pose position</span></span> | <span data-ttu-id="251c6-198">Percorso Palm</span><span class="sxs-lookup"><span data-stu-id="251c6-198">Palm location</span></span> |
| [<span data-ttu-id="251c6-199">SpatialInteractionSourceLocation::**Orientation**</span><span class="sxs-lookup"><span data-stu-id="251c6-199">SpatialInteractionSourceLocation::**Orientation**</span></span>](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcelocation.orientation) | <span data-ttu-id="251c6-200">Quaternione che rappresenta l'orientamento della mano o triangolo rappresentare nel controller.</span><span class="sxs-lookup"><span data-stu-id="251c6-200">Quaternion representing the orientation of the hand or grip pose on the controller.</span></span> | <span data-ttu-id="251c6-201">Non supportato</span><span class="sxs-lookup"><span data-stu-id="251c6-201">Not Supported</span></span> | <span data-ttu-id="251c6-202">Orientamento posa triangolo di ridimensionamento</span><span class="sxs-lookup"><span data-stu-id="251c6-202">Grip pose orientation</span></span> | <span data-ttu-id="251c6-203">Orientamento Palm</span><span class="sxs-lookup"><span data-stu-id="251c6-203">Palm orientation</span></span> |
| [<span data-ttu-id="251c6-204">SpatialPointerInteractionSourcePose::**Position**</span><span class="sxs-lookup"><span data-stu-id="251c6-204">SpatialPointerInteractionSourcePose::**Position**</span></span>](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialpointerinteractionsourcepose.position#Windows_UI_Input_Spatial_SpatialPointerInteractionSourcePose_Position) | <span data-ttu-id="251c6-205">Origine del raggio puntamento.</span><span class="sxs-lookup"><span data-stu-id="251c6-205">Origin of the pointing ray.</span></span> | <span data-ttu-id="251c6-206">Non supportato</span><span class="sxs-lookup"><span data-stu-id="251c6-206">Not Supported</span></span> | <span data-ttu-id="251c6-207">Supportato</span><span class="sxs-lookup"><span data-stu-id="251c6-207">Supported</span></span> | <span data-ttu-id="251c6-208">Supportato</span><span class="sxs-lookup"><span data-stu-id="251c6-208">Supported</span></span> |
| [<span data-ttu-id="251c6-209">SpatialPointerInteractionSourcePose::**ForwardDirection**</span><span class="sxs-lookup"><span data-stu-id="251c6-209">SpatialPointerInteractionSourcePose::**ForwardDirection**</span></span>](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialpointerinteractionsourcepose.forwarddirection#Windows_UI_Input_Spatial_SpatialPointerInteractionSourcePose_ForwardDirection) | <span data-ttu-id="251c6-210">Direzione del raggio puntamento.</span><span class="sxs-lookup"><span data-stu-id="251c6-210">Direction of the pointing ray.</span></span> | <span data-ttu-id="251c6-211">Non supportato</span><span class="sxs-lookup"><span data-stu-id="251c6-211">Not Supported</span></span> | <span data-ttu-id="251c6-212">Supportato</span><span class="sxs-lookup"><span data-stu-id="251c6-212">Supported</span></span> | <span data-ttu-id="251c6-213">Supportato</span><span class="sxs-lookup"><span data-stu-id="251c6-213">Supported</span></span> |

<span data-ttu-id="251c6-214">Alcune di queste proprietà non sono disponibili in tutti i dispositivi e l'API fornisce un mezzo per effettuare questa verifica.</span><span class="sxs-lookup"><span data-stu-id="251c6-214">Some of the above properties are not available on all devices, and the API provides a means to test for this.</span></span> <span data-ttu-id="251c6-215">Ad esempio, è possibile esaminare i [SpatialInteractionSource::IsGraspSupported](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsource.isgraspsupported) proprietà per determinare se un'azione. é quindi disponibile per l'origine.</span><span class="sxs-lookup"><span data-stu-id="251c6-215">For example, you can inspect the [SpatialInteractionSource::IsGraspSupported](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsource.isgraspsupported) property to determine whether the source provides a grasp action.</span></span>

### <a name="grip-pose-vs-pointing-pose"></a><span data-ttu-id="251c6-216">Triangolo di ridimensionamento posa confronto posa puntamento</span><span class="sxs-lookup"><span data-stu-id="251c6-216">Grip pose vs. pointing pose</span></span>

<span data-ttu-id="251c6-217">Realtà mista di Windows supporta controller di movimento in un'ampia gamma di fattori di forma.</span><span class="sxs-lookup"><span data-stu-id="251c6-217">Windows Mixed Reality supports motion controllers in a variety of form factors.</span></span>  <span data-ttu-id="251c6-218">Supporta inoltre la mano articolati e sistemi di rilevamento.</span><span class="sxs-lookup"><span data-stu-id="251c6-218">It also supports articulated hand tracking systems.</span></span>  <span data-ttu-id="251c6-219">Tutti questi sistemi dispongono di diverse relazioni tra la posizione di disponibilità e la direzione di "inoltro" naturale che le app devono usare per gli oggetti che puntano o rendreing a disposizione dell'utente.</span><span class="sxs-lookup"><span data-stu-id="251c6-219">All of these systems have different relationships between the hand position and the natural "forward" direction that apps should use for pointing or rendreing objects in the user's hand.</span></span>  <span data-ttu-id="251c6-220">Per supportare tutto ciò, esistono due tipi di può causare 3D fornite per entrambi i controller di rilevamento e movimenti della mano.</span><span class="sxs-lookup"><span data-stu-id="251c6-220">To support all of this, there are two types of 3D poses provided for both hand tracking and motion controllers.</span></span>  <span data-ttu-id="251c6-221">Il primo è posa triangolo di ridimensionamento, che rappresenta la posizione dell'utente mano.</span><span class="sxs-lookup"><span data-stu-id="251c6-221">The first is grip pose, which represents the user's hand position.</span></span>  <span data-ttu-id="251c6-222">Il secondo fa posa, che rappresenta un raggio di puntamento provenienti da parte dell'utente o un controller.</span><span class="sxs-lookup"><span data-stu-id="251c6-222">The second is pointing pose, which represents a pointing ray originating from the user's hand or controller.</span></span> <span data-ttu-id="251c6-223">Pertanto, se si desidera eseguire il rendering **manuale dell'utente** oppure **mantenuto un oggetto a disposizione dell'utente**, ad esempio un doppio taglio o gun, utilizzare posa il triangolo di ridimensionamento.</span><span class="sxs-lookup"><span data-stu-id="251c6-223">So, if you want to render **the user's hand** or **an object held in the user's hand**, such as a sword or gun, use the grip pose.</span></span> <span data-ttu-id="251c6-224">Se si desidera raycast dal controller o manualmente, ad esempio quando l'utente sta **che punta all'interfaccia utente** , usare il puntamento posa.</span><span class="sxs-lookup"><span data-stu-id="251c6-224">If you want to raycast from the controller or hand, for example when the user is **pointing at UI** , use the pointing pose.</span></span>

<span data-ttu-id="251c6-225">È possibile accedere la **posa triangolo** tramite [SpatialInteractionSourceState::Properties::TryGetLocation(...) ](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourceproperties.trygetlocation#Windows_UI_Input_Spatial_SpatialInteractionSourceProperties_TryGetLocation_Windows_Perception_Spatial_SpatialCoordinateSystem_).  Viene definito come segue:</span><span class="sxs-lookup"><span data-stu-id="251c6-225">You can access the **grip pose** through [SpatialInteractionSourceState::Properties::TryGetLocation(...)](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourceproperties.trygetlocation#Windows_UI_Input_Spatial_SpatialInteractionSourceProperties_TryGetLocation_Windows_Perception_Spatial_SpatialCoordinateSystem_).  It is defined as follows:</span></span>
* <span data-ttu-id="251c6-226">Il **afferrare posizione**: Il centroide palm quando tenendo naturalmente, il controller è regolato sinistro o destro da allineare al centro la posizione all'interno del triangolo di ridimensionamento.</span><span class="sxs-lookup"><span data-stu-id="251c6-226">The **grip position**: The palm centroid when holding the controller naturally, adjusted left or right to center the position within the grip.</span></span>
* <span data-ttu-id="251c6-227">Il **afferrare asse a destra dell'orientamento**: Quando si apre completamente la mano per formare una posa flat con un dito di 5, il raggio è normale che palm (in avanti dal palmo a sinistra, con le versioni precedenti dal palmo a destra)</span><span class="sxs-lookup"><span data-stu-id="251c6-227">The **grip orientation's Right axis**: When you completely open your hand to form a flat 5-finger pose, the ray that is normal to your palm (forward from left palm, backward from right palm)</span></span>
* <span data-ttu-id="251c6-228">Il **afferrare asse diretta dell'orientamento**: Quando si chiude la mano parzialmente (come se che contiene il controller), il raggio che punta "forward" tramite il tubo costituita dalle dita non thumb.</span><span class="sxs-lookup"><span data-stu-id="251c6-228">The **grip orientation's Forward axis**: When you close your hand partially (as if holding the controller), the ray that points "forward" through the tube formed by your non-thumb fingers.</span></span>
* <span data-ttu-id="251c6-229">Il **afferrare orientamento di asse**: L'asse verticale in cui è inclusa per le definizioni di destra e l'inoltro.</span><span class="sxs-lookup"><span data-stu-id="251c6-229">The **grip orientation's Up axis**: The Up axis implied by the Right and Forward definitions.</span></span>

<span data-ttu-id="251c6-230">È possibile accedere la **puntatore posa** attraverso [SpatialInteractionSourceState::Properties::TryGetLocation (...):: SourcePointerPose](https://docs.microsoft.com/uwp/api/windows.ui.input.spatial.spatialinteractionsourcelocation#Windows_UI_Input_Spatial_SpatialInteractionSourceLocation_SourcePointerPose) o [SpatialInteractionSourceState:: TryGetPointerPose (...):: TryGetInteractionSourcePose](https://docs.microsoft.com/uwp/api/windows.ui.input.spatial.spatialpointerpose#Windows_UI_Input_Spatial_SpatialPointerPose_TryGetInteractionSourcePose_Windows_UI_Input_Spatial_SpatialInteractionSource_).</span><span class="sxs-lookup"><span data-stu-id="251c6-230">You can access the **pointer pose** through [SpatialInteractionSourceState::Properties::TryGetLocation(...)::SourcePointerPose](https://docs.microsoft.com/uwp/api/windows.ui.input.spatial.spatialinteractionsourcelocation#Windows_UI_Input_Spatial_SpatialInteractionSourceLocation_SourcePointerPose) or [SpatialInteractionSourceState::TryGetPointerPose(...)::TryGetInteractionSourcePose](https://docs.microsoft.com/uwp/api/windows.ui.input.spatial.spatialpointerpose#Windows_UI_Input_Spatial_SpatialPointerPose_TryGetInteractionSourcePose_Windows_UI_Input_Spatial_SpatialInteractionSource_).</span></span>

## <a name="controller-specific-input-properties"></a><span data-ttu-id="251c6-231">Proprietà di input specifici dei controller</span><span class="sxs-lookup"><span data-stu-id="251c6-231">Controller-specific input properties</span></span>
<span data-ttu-id="251c6-232">Per i controller, il SpatialInteractionSource ha una proprietà di Controller con funzionalità aggiuntive.</span><span class="sxs-lookup"><span data-stu-id="251c6-232">For controllers, the SpatialInteractionSource has a Controller property with additional capabilities.</span></span>
* <span data-ttu-id="251c6-233">**HasThumbstick:** Se true, il controller ha una levetta.</span><span class="sxs-lookup"><span data-stu-id="251c6-233">**HasThumbstick:** If true, the controller has a thumbstick.</span></span> <span data-ttu-id="251c6-234">Esaminare i [ControllerProperties](https://docs.microsoft.com/uwp/api/windows.ui.input.spatial.spatialinteractioncontrollerproperties) proprietà SpatialInteractionSourceState per acquisire il thumbstick x e i valori y (ThumbstickX e ThumbstickY), nonché lo stato di premuto (IsThumbstickPressed).</span><span class="sxs-lookup"><span data-stu-id="251c6-234">Inspect the [ControllerProperties](https://docs.microsoft.com/uwp/api/windows.ui.input.spatial.spatialinteractioncontrollerproperties) property of the SpatialInteractionSourceState to acquire the thumbstick x and y values (ThumbstickX and ThumbstickY), as well as its pressed state (IsThumbstickPressed).</span></span>
* <span data-ttu-id="251c6-235">**HasTouchpad:** Se true, il controller ha il touchpad.</span><span class="sxs-lookup"><span data-stu-id="251c6-235">**HasTouchpad:** If true, the controller has a touchpad.</span></span> <span data-ttu-id="251c6-236">Esaminare la proprietà ControllerProperties di SpatialInteractionSourceState per acquisire il touchpad x e y (TouchpadX e TouchpadY), i valori e per sapere se l'utente tocca il riquadro (IsTouchpadTouched) e se essi sono premendo il touchpad verso il basso ( IsTouchpadPressed).</span><span class="sxs-lookup"><span data-stu-id="251c6-236">Inspect the ControllerProperties property of the SpatialInteractionSourceState to acquire the touchpad x and y values (TouchpadX and TouchpadY), and to know if the user is touching the pad (IsTouchpadTouched) and if they are pressing the touchpad down (IsTouchpadPressed).</span></span>
* <span data-ttu-id="251c6-237">**SimpleHapticsController:** L'API SimpleHapticsController per il controller consente di esaminare le funzionalità haptics del controller e permette anche di controllare l'implementazione del feedback aptico.</span><span class="sxs-lookup"><span data-stu-id="251c6-237">**SimpleHapticsController:** The SimpleHapticsController API for the controller allows you to inspect the haptics capabilities of the controller, and it also allows you to control haptic feedback.</span></span>

<span data-ttu-id="251c6-238">Si noti che l'intervallo per touchpad e thumbstick è -1 e 1 per entrambi gli assi (dal basso verso l'alto e da sinistra a destra).</span><span class="sxs-lookup"><span data-stu-id="251c6-238">Note that the range for touchpad and thumbstick is -1 to 1 for both axes (from bottom to top, and from left to right).</span></span> <span data-ttu-id="251c6-239">L'intervallo per il trigger analogico, che è possibile accedere tramite la proprietà SpatialInteractionSourceState::SelectPressedValue, ha un intervallo di 0 e 1.</span><span class="sxs-lookup"><span data-stu-id="251c6-239">The range for the analog trigger, which is accessed using the SpatialInteractionSourceState::SelectPressedValue property, has a range of 0 to 1.</span></span> <span data-ttu-id="251c6-240">Un valore di 1 è correlata con IsSelectPressed quali uguale a true. qualsiasi altro valore mette in correlazione con IsSelectPressed quali uguale a false.</span><span class="sxs-lookup"><span data-stu-id="251c6-240">A value of 1 correlates with IsSelectPressed being equal to true; any other value correlates with IsSelectPressed being equal to false.</span></span>

## <a name="articulated-hand-tracking"></a><span data-ttu-id="251c6-241">Mano articolati e rilevamento</span><span class="sxs-lookup"><span data-stu-id="251c6-241">Articulated hand tracking</span></span>
<span data-ttu-id="251c6-242">L'API di realtà mista di Windows fornisce supporto completo per le mani articolati e rilevamento, ad esempio in 2 HoloLens.</span><span class="sxs-lookup"><span data-stu-id="251c6-242">The Windows Mixed Reality API provides full support for articulated hand tracking, for example on HoloLens 2.</span></span> <span data-ttu-id="251c6-243">Mano articolati e di rilevamento è utilizzabile per implementare i modelli di input di punto di commit e manipolazione diretta nelle applicazioni.</span><span class="sxs-lookup"><span data-stu-id="251c6-243">Articulated hand tracking can be used to implement direct manipulation and point-and-commit input models in your applications.</span></span> <span data-ttu-id="251c6-244">Può essere utilizzato anche per creare interazioni completamente personalizzate.</span><span class="sxs-lookup"><span data-stu-id="251c6-244">It can also be used to author fully custom interactions.</span></span>

### <a name="hand-skeleton"></a><span data-ttu-id="251c6-245">Scheletro di mano</span><span class="sxs-lookup"><span data-stu-id="251c6-245">Hand skeleton</span></span>
<span data-ttu-id="251c6-246">Mano articolati e di rilevamento fornisce una struttura comune 25 che consente a molti tipi diversi di interazioni.</span><span class="sxs-lookup"><span data-stu-id="251c6-246">Articulated hand tracking provides a 25 joint skeleton that enables many different types of interactions.</span></span>  <span data-ttu-id="251c6-247">Lo scheletro fornisce giunti a 5 per l'indice/intermedio/anello/little dita giunti a 4 per il controllo thumb e 1 polso giunto.</span><span class="sxs-lookup"><span data-stu-id="251c6-247">The skeleton provides 5 joints for the index/middle/ring/little fingers, 4 joints for the thumb, and 1 wrist joint.</span></span>  <span data-ttu-id="251c6-248">La giunzione polso funge da base della gerarchia.</span><span class="sxs-lookup"><span data-stu-id="251c6-248">The wrist joint serves as the base of the hierarchy.</span></span> <span data-ttu-id="251c6-249">L'immagine seguente illustra il layout della struttura.</span><span class="sxs-lookup"><span data-stu-id="251c6-249">The following picture illustrates the layout of the skeleton.</span></span>

![Scheletro di mano](images/hand-skeleton.png)

<span data-ttu-id="251c6-251">Nella maggior parte dei casi, ogni attività di collaborazione è denominato base ossa da essa rappresentato.</span><span class="sxs-lookup"><span data-stu-id="251c6-251">In most cases, each joint is named based on the bone that it represents.</span></span>  <span data-ttu-id="251c6-252">Poiché sono presenti due ossa in ogni attività di collaborazione, usiamo una convenzione di denominazione ogni attività di collaborazione basata su ossa figlio nel percorso specificato.</span><span class="sxs-lookup"><span data-stu-id="251c6-252">Since there are two bones at every joint, we use a convention of naming each joint based on the child bone at that location.</span></span>  <span data-ttu-id="251c6-253">Ossa figlio viene definito come ossa distante polso.</span><span class="sxs-lookup"><span data-stu-id="251c6-253">The child bone is defined as the bone further from the wrist.</span></span>  <span data-ttu-id="251c6-254">Ad esempio, è il "indice Proximal" joint contiene la posizione iniziale dell'ossa proximal indice e l'orientamento di tale ossa.</span><span class="sxs-lookup"><span data-stu-id="251c6-254">For example, the "Index Proximal" joint contains the beginning position of the index proximal bone, and the orientation of that bone.</span></span>  <span data-ttu-id="251c6-255">Non contiene la posizione finale di ossa.</span><span class="sxs-lookup"><span data-stu-id="251c6-255">It does not contain the ending position of the bone.</span></span>  <span data-ttu-id="251c6-256">Se è necessario che, si otterrebbe lo dal successivo comune nella gerarchia, il "indice intermedio" comune.</span><span class="sxs-lookup"><span data-stu-id="251c6-256">If you need that, you'd get it from the next joint in the hierarchy, the "Index Intermediate" joint.</span></span>

<span data-ttu-id="251c6-257">Oltre i 25 giunti gerarchici, il sistema fornisce un joint palm.</span><span class="sxs-lookup"><span data-stu-id="251c6-257">In addition to the 25 hierarchical joints, the system provides a palm joint.</span></span>  <span data-ttu-id="251c6-258">Palmo non è in genere considerato parte della struttura di base.</span><span class="sxs-lookup"><span data-stu-id="251c6-258">The palm is not typically considered part of the skeletal structure.</span></span>  <span data-ttu-id="251c6-259">Viene fornito solo come un modo pratico per ottenere una posizione e l'orientamento complessivo la mano.</span><span class="sxs-lookup"><span data-stu-id="251c6-259">It is provided only as a convenient way to get the hand's overall position and orientation.</span></span>

<span data-ttu-id="251c6-260">Le informazioni seguenti viene fornite per ogni attività di collaborazione:</span><span class="sxs-lookup"><span data-stu-id="251c6-260">The following information is provided for each joint:</span></span>

| <span data-ttu-id="251c6-261">Nome</span><span class="sxs-lookup"><span data-stu-id="251c6-261">Name</span></span> | <span data-ttu-id="251c6-262">Descrizione</span><span class="sxs-lookup"><span data-stu-id="251c6-262">Description</span></span> |
|--- |--- |
|<span data-ttu-id="251c6-263">Posizione</span><span class="sxs-lookup"><span data-stu-id="251c6-263">Position</span></span> | <span data-ttu-id="251c6-264">3D posizione del punto di giunzione, disponibile in qualsiasi sistema di coordinate richiesta.</span><span class="sxs-lookup"><span data-stu-id="251c6-264">3D position of the joint, available in any requested coordinate system.</span></span> |
|<span data-ttu-id="251c6-265">Orientation</span><span class="sxs-lookup"><span data-stu-id="251c6-265">Orientation</span></span> | <span data-ttu-id="251c6-266">Orientamento 3D di ossa, disponibile in qualsiasi richiesta del sistema di coordinate.</span><span class="sxs-lookup"><span data-stu-id="251c6-266">3D orientation of the bone, available in any requested coordinate system.</span></span> |
|<span data-ttu-id="251c6-267">Raggio</span><span class="sxs-lookup"><span data-stu-id="251c6-267">Radius</span></span> | <span data-ttu-id="251c6-268">Distanza all'area dell'interfaccia in corrispondenza della posizione comune.</span><span class="sxs-lookup"><span data-stu-id="251c6-268">Distance to surface of the skin at the joint position.</span></span> <span data-ttu-id="251c6-269">È utile per l'ottimizzazione di interazioni dirette o visualizzazioni che si basano sulla larghezza di un dito.</span><span class="sxs-lookup"><span data-stu-id="251c6-269">Useful for tuning direct interactions or visualizations that rely on finger width.</span></span> |
|<span data-ttu-id="251c6-270">Precisione</span><span class="sxs-lookup"><span data-stu-id="251c6-270">Accuracy</span></span> | <span data-ttu-id="251c6-271">Fornisce un suggerimento su quanta fiducia scelga di sistema sulle informazioni della giunzione.</span><span class="sxs-lookup"><span data-stu-id="251c6-271">Provides a hint on how confident the system feels about this joint's information.</span></span> |

<span data-ttu-id="251c6-272">È possibile accedere ai dati scheletro manualmente tramite una funzione nel [SpatialInteractionSourceState](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate).</span><span class="sxs-lookup"><span data-stu-id="251c6-272">You can access the hand skeleton data through a function on the [SpatialInteractionSourceState](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate).</span></span>  <span data-ttu-id="251c6-273">La funzione viene chiamata [TryGetHandPose](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.trygethandpose#Windows_UI_Input_Spatial_SpatialInteractionSourceState_TryGetHandPose), e restituisce un oggetto denominato [HandPose](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.handpose).</span><span class="sxs-lookup"><span data-stu-id="251c6-273">The function is called [TryGetHandPose](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.trygethandpose#Windows_UI_Input_Spatial_SpatialInteractionSourceState_TryGetHandPose), and it returns an object called [HandPose](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.handpose).</span></span>  <span data-ttu-id="251c6-274">Se l'origine non supporta le mani articolati e, questa funzione restituirà null.</span><span class="sxs-lookup"><span data-stu-id="251c6-274">If the source does not support articulated hands, then this function will return null.</span></span>  <span data-ttu-id="251c6-275">Dopo aver creato un HandPose, è possibile ottenere dati joint correnti chiamando [TryGetJoint](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.handpose.trygetjoint#Windows_Perception_People_HandPose_TryGetJoint_Windows_Perception_Spatial_SpatialCoordinateSystem_Windows_Perception_People_HandJointKind_Windows_Perception_People_JointPose__), con il nome dell'attività di collaborazione si è interessati.</span><span class="sxs-lookup"><span data-stu-id="251c6-275">Once you have a HandPose, you can get current joint data by calling [TryGetJoint](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.handpose.trygetjoint#Windows_Perception_People_HandPose_TryGetJoint_Windows_Perception_Spatial_SpatialCoordinateSystem_Windows_Perception_People_HandJointKind_Windows_Perception_People_JointPose__), with the name of the joint you are interested in.</span></span>  <span data-ttu-id="251c6-276">I dati vengono restituiti come una [JointPose](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.jointpose) struttura.</span><span class="sxs-lookup"><span data-stu-id="251c6-276">The data is returned as a [JointPose](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.jointpose) structure.</span></span>  <span data-ttu-id="251c6-277">Il codice seguente ottiene la posizione del suggerimento dito indice.</span><span class="sxs-lookup"><span data-stu-id="251c6-277">The following code gets the position of the index finger tip.</span></span> <span data-ttu-id="251c6-278">La variabile *currentState* rappresenta un'istanza di [SpatialInteractionSourceState](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate).</span><span class="sxs-lookup"><span data-stu-id="251c6-278">The variable *currentState* represents an instance of [SpatialInteractionSourceState](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate).</span></span>

```cpp
using namespace winrt::Windows::Perception::People;
using namespace winrt::Windows::Foundation::Numerics;

auto handPose = currentState.TryGetHandPose();
if (handPose)
{
    JointPose joint;
    if (handPose.TryGetJoint(desiredCoordinateSystem, HandJointKind::IndexTip, joint))
    {
        float3 indexTipPosition = joint.Position;

        // Do something with the index tip position
    }
}
```

### <a name="hand-mesh"></a><span data-ttu-id="251c6-279">Rete mesh di mano</span><span class="sxs-lookup"><span data-stu-id="251c6-279">Hand mesh</span></span>

<span data-ttu-id="251c6-280">L'icona della mano articolati e API di rilevamento consente una mesh di mano completamente deformabile triangolare.</span><span class="sxs-lookup"><span data-stu-id="251c6-280">The articulated hand tracking API allows for a fully deformable triangle hand mesh.</span></span>  <span data-ttu-id="251c6-281">Questa trama può deform in tempo reale con lo scheletro di mano e risulta utile per la visualizzazione, nonché le tecniche avanzate fisica.</span><span class="sxs-lookup"><span data-stu-id="251c6-281">This mesh can deform in real time along with the hand skeleton, and is useful for visualization as well as advanced physics techniques.</span></span>  <span data-ttu-id="251c6-282">Per accedere a mesh manualmente, è necessario creare prima di tutto una [HandMeshObserver](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.handmeshobserver) oggetto chiamando [TryCreateHandMeshObserverAsync](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsource.trycreatehandmeshobserverasync) sul [SpatialInteractionSource](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsource).</span><span class="sxs-lookup"><span data-stu-id="251c6-282">To access the hand mesh, you need to first create a [HandMeshObserver](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.handmeshobserver) object by calling [TryCreateHandMeshObserverAsync](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsource.trycreatehandmeshobserverasync) on the [SpatialInteractionSource](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsource).</span></span>  <span data-ttu-id="251c6-283">Ciò è sufficiente essere eseguito una volta per ogni origine, in genere la prima volta che viene visualizzato.</span><span class="sxs-lookup"><span data-stu-id="251c6-283">This only needs to be done once per source, typically the first time you see it.</span></span>  <span data-ttu-id="251c6-284">Ciò significa che è possibile chiamare questa funzione per creare un oggetto HandMeshObserver ogni volta che una mano passa il campo di visualizzazione.</span><span class="sxs-lookup"><span data-stu-id="251c6-284">That means you'll call this function to create a HandMeshObserver object whenever a hand enters the FOV.</span></span>  <span data-ttu-id="251c6-285">Si tratta di una funzione asincrona, pertanto sarà necessario gestire un po' di concorrenza qui.</span><span class="sxs-lookup"><span data-stu-id="251c6-285">Note that this is an async function, so you'll have to deal with a bit of concurrency here.</span></span>  <span data-ttu-id="251c6-286">Una volta disponibile, è possibile porre l'oggetto HandMeshObserver per il buffer di triangolo indice chiamando [GetTriangleIndices](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.handmeshobserver.gettriangleindices#Windows_Perception_People_HandMeshObserver_GetTriangleIndices_System_UInt16___).</span><span class="sxs-lookup"><span data-stu-id="251c6-286">Once available, you can ask the HandMeshObserver object for the triangle index buffer by calling [GetTriangleIndices](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.handmeshobserver.gettriangleindices#Windows_Perception_People_HandMeshObserver_GetTriangleIndices_System_UInt16___).</span></span>  <span data-ttu-id="251c6-287">Gli indici di non modificare frame tramite cornice, pertanto è possibile ottenerle una sola volta e memorizzarli nella cache per la durata dell'origine.</span><span class="sxs-lookup"><span data-stu-id="251c6-287">Indices don't change frame over frame, so you can get those once and cache them for the lifetime of the source.</span></span>  <span data-ttu-id="251c6-288">Gli indici sono disponibili nell'ordine dei vertici in senso orario.</span><span class="sxs-lookup"><span data-stu-id="251c6-288">Indices are provided in clockwise winding order.</span></span>

<span data-ttu-id="251c6-289">Il codice seguente attiva un std::thread scollegato per creare l'osservatore mesh ed estrae l'index buffer dopo l'osservatore mesh è disponibile.</span><span class="sxs-lookup"><span data-stu-id="251c6-289">The following code spins up a detached std::thread to create the mesh observer and extracts the index buffer once the mesh observer is available.</span></span>  <span data-ttu-id="251c6-290">Viene avviato da una variabile denominata *currentState*, che è un'istanza del [SpatialInteractionSourceState](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate) che rappresenta una mano rilevata.</span><span class="sxs-lookup"><span data-stu-id="251c6-290">It starts from a variable called *currentState*, which is an instance of [SpatialInteractionSourceState](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate) representing a tracked hand.</span></span>

```cpp
using namespace Windows::Perception::People;

std::thread createObserverThread([this, currentState]()
{
    HandMeshObserver newHandMeshObserver = currentState.Source().TryCreateHandMeshObserverAsync().get();
    if (newHandMeshObserver)
    {
        unsigned indexCount = newHandMeshObserver.TriangleIndexCount();
        vector<unsigned short> indices(indexCount);
        newHandMeshObserver.GetTriangleIndices(indices);

        // Save the indices and handMeshObserver for later use - and use a mutex to synchronize access if needed!
     }
});
createObserverThread.detach();
```
<span data-ttu-id="251c6-291">Avvio di un thread scollegato è solo un'opzione per la gestione delle chiamate async.</span><span class="sxs-lookup"><span data-stu-id="251c6-291">Starting a detached thread is just one option for handling async calls.</span></span>  <span data-ttu-id="251c6-292">In alternativa, è possibile usare le nuove [co_await](https://docs.microsoft.com/en-us/windows/uwp/cpp-and-winrt-apis/concurrency) funzionalità supportate da C++/WinRT.</span><span class="sxs-lookup"><span data-stu-id="251c6-292">Alternatively, you could use the new [co_await](https://docs.microsoft.com/en-us/windows/uwp/cpp-and-winrt-apis/concurrency) functionality supported by C++/WinRT.</span></span>

<span data-ttu-id="251c6-293">Dopo aver creato un oggetto HandMeshObserver, è consigliabile tenere premuto su di esso per tutta la durata relativa SpatialInteractionSource corrispondente è attivo.</span><span class="sxs-lookup"><span data-stu-id="251c6-293">Once you have a HandMeshObserver object, you should hold onto it for the duration that its corresponding SpatialInteractionSource is active.</span></span>  <span data-ttu-id="251c6-294">Quindi ogni fotogramma, è possibile richiedere il buffer dei vertici più recente che rappresenta l'icona della mano chiamando [GetVertexStateForPose](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.handmeshobserver.getvertexstateforpose) e passando un [HandPose](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.handpose) istanza che rappresenta la posa che si desidera che i vertici per.</span><span class="sxs-lookup"><span data-stu-id="251c6-294">Then each frame, you can ask it for the latest vertex buffer that represents the hand by calling [GetVertexStateForPose](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.handmeshobserver.getvertexstateforpose) and passing in a [HandPose](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.handpose) instance that represents the pose that you want vertices for.</span></span>  <span data-ttu-id="251c6-295">Ogni vertice nel buffer con una posizione e una normale.</span><span class="sxs-lookup"><span data-stu-id="251c6-295">Each vertex in the buffer has a position and a normal.</span></span>  <span data-ttu-id="251c6-296">Ecco un esempio di come ottenere il set corrente di vertici per una rete mesh di mano.</span><span class="sxs-lookup"><span data-stu-id="251c6-296">Here's an example of how to get the current set of vertices for a hand mesh.</span></span>  <span data-ttu-id="251c6-297">Come in precedenza, il *currentState* variabile rappresenta un'istanza di [SpatialInteractionSourceState](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate).</span><span class="sxs-lookup"><span data-stu-id="251c6-297">Just as before, the *currentState* variable represents an instance of [SpatialInteractionSourceState](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate).</span></span>

```cpp
using namespace winrt::Windows::Perception::People;

auto handPose = currentState.TryGetHandPose();
if (handPose)
{
    std::vector<HandMeshVertex> vertices(handMeshObserver.VertexCount());
    auto vertexState = handMeshObserver.GetVertexStateForPose(handPose);
    vertexState.GetVertices(vertices);

    auto meshTransform = vertexState.CoordinateSystem().TryGetTransformTo(desiredCoordinateSystem);
    if (meshTransform != nullptr)
    {
        // Do something with the vertices and mesh transform, along with the indices that you saved earlier
    }
}
```

<span data-ttu-id="251c6-298">A differenza delle scheletro giunzioni, l'API di rete mesh di disponibilità non consentono di specificare un sistema di coordinate per i vertici.</span><span class="sxs-lookup"><span data-stu-id="251c6-298">In contrast to skeleton joints, the hand mesh API does not allow you to specify a coordinate system for the vertices.</span></span>  <span data-ttu-id="251c6-299">Al contrario, il [HandMeshVertexState](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.handmeshvertexstate) specifica il sistema di coordinate dei vertici forniti in.</span><span class="sxs-lookup"><span data-stu-id="251c6-299">Instead, the [HandMeshVertexState](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.handmeshvertexstate) specifies the coordinate system that the vertices are provided in.</span></span>  <span data-ttu-id="251c6-300">È quindi possibile ottenere una trasformazione mesh chiamando [TryGetTransformTo](https://docs.microsoft.com/en-us/uwp/api/windows.perception.spatial.spatialcoordinatesystem.trygettransformto#Windows_Perception_Spatial_SpatialCoordinateSystem_TryGetTransformTo_Windows_Perception_Spatial_SpatialCoordinateSystem_) e specifica il sistema di coordinate desiderato.</span><span class="sxs-lookup"><span data-stu-id="251c6-300">You can then get a mesh transform by calling [TryGetTransformTo](https://docs.microsoft.com/en-us/uwp/api/windows.perception.spatial.spatialcoordinatesystem.trygettransformto#Windows_Perception_Spatial_SpatialCoordinateSystem_TryGetTransformTo_Windows_Perception_Spatial_SpatialCoordinateSystem_) and specifying your desired coordinate system.</span></span>  <span data-ttu-id="251c6-301">È necessario usare questa trasformazione mesh ogni volta che procede con i vertici.</span><span class="sxs-lookup"><span data-stu-id="251c6-301">You'll need to use this mesh transform whenever you work with the vertices.</span></span>  <span data-ttu-id="251c6-302">Questo approccio riduce il sovraccarico della CPU, in particolare se si usa solo il mesh per scopi di rendering.</span><span class="sxs-lookup"><span data-stu-id="251c6-302">This approach reduces CPU overhead, especially if you are only using the mesh for rendering purposes.</span></span>

## <a name="gaze-and-commit-composite-gestures"></a><span data-ttu-id="251c6-303">Estasiati ed eseguire il Commit i movimenti compositi</span><span class="sxs-lookup"><span data-stu-id="251c6-303">Gaze and Commit composite gestures</span></span>
<span data-ttu-id="251c6-304">Per le applicazioni usando il modello di input sguardo e commit, in particolare su HoloLens (gen primo), l'API di Input spaziali fornisce facoltativo [SpatialGestureRecognizer](https://msdn.microsoft.com/library/windows/apps/windows.ui.input.spatial.spatialgesturerecognizer.aspx) che può essere utilizzato per abilitare i movimenti compositi costruita basati su di 'select' evento.</span><span class="sxs-lookup"><span data-stu-id="251c6-304">For applications using the gaze-and-commit input model, particularly on HoloLens (first gen), the Spatial Input API provides an optional [SpatialGestureRecognizer](https://msdn.microsoft.com/library/windows/apps/windows.ui.input.spatial.spatialgesturerecognizer.aspx) that can be used to to enable composite gestures built on top of the 'select' event.</span></span>  <span data-ttu-id="251c6-305">Dal routine interazioni dal SpatialInteractionManager a SpatialGestureRecognizer di ologramma, le app possono rilevare gli eventi di tocco, tenere premuto, manipolazione e navigazione in modo uniforme tra le mani, voce e spaziali dispositivi di input, senza dovere gestire le pressioni e rilascia manualmente.</span><span class="sxs-lookup"><span data-stu-id="251c6-305">By routing interactions from the SpatialInteractionManager to a hologram's SpatialGestureRecognizer, apps can detect Tap, Hold, Manipulation, and Navigation events uniformly across hands, voice, and spatial input devices, without having to handle presses and releases manually.</span></span>

<span data-ttu-id="251c6-306">SpatialGestureRecognizer esegue solo la minima risoluzione dell'ambiguità tra il set di gesti richiesti.</span><span class="sxs-lookup"><span data-stu-id="251c6-306">SpatialGestureRecognizer performs only the minimal disambiguation between the set of gestures that you request.</span></span> <span data-ttu-id="251c6-307">Ad esempio, se vengono richiesti solo tocco, l'utente può tenere premuto il dito, purché che desiderano e tocco continueranno a essere eseguiti.</span><span class="sxs-lookup"><span data-stu-id="251c6-307">For example, if you request just Tap, the user may hold their finger down as long as they like and a Tap will still occur.</span></span> <span data-ttu-id="251c6-308">Se si richiede sia toccare e tenere premuto, dopo circa un secondo di tenendo premuto il dito, l'azione alzerà di livello a un'esenzione e una scelta non verrà più eseguita.</span><span class="sxs-lookup"><span data-stu-id="251c6-308">If you request both Tap and Hold, after about a second of holding down their finger, the gesture will promote to a Hold and a Tap will no longer occur.</span></span>

<span data-ttu-id="251c6-309">Per usare SpatialGestureRecognizer, gestire il SpatialInteractionManager [InteractionDetected](https://msdn.microsoft.com/library/windows/apps/xaml/Windows.UI.Input.Spatial.SpatialInteractionManager.InteractionDetected) evento e il SpatialPointerPose esposte sono quadratini di ridimensionamento.</span><span class="sxs-lookup"><span data-stu-id="251c6-309">To use SpatialGestureRecognizer, handle the SpatialInteractionManager's [InteractionDetected](https://msdn.microsoft.com/library/windows/apps/xaml/Windows.UI.Input.Spatial.SpatialInteractionManager.InteractionDetected) event and grab the SpatialPointerPose exposed there.</span></span> <span data-ttu-id="251c6-310">Usare ray head sguardo dell'utente da questo posa da intersecare con l'ologrammi e trame area nelle vicinanze dell'utente, per poter determinare ciò che l'utente non sia progettata per interagire con.</span><span class="sxs-lookup"><span data-stu-id="251c6-310">Use the user's head gaze ray from this pose to intersect with the holograms and surface meshes in the user's surroundings, in order to determine what the user is intending to interact with.</span></span> <span data-ttu-id="251c6-311">Quindi, instradare il SpatialInteraction negli argomenti di evento per SpatialGestureRecognizer del ologrammi destinazione, con relativi [CaptureInteraction](http://msdn.microsoft.com/library/windows/apps/xaml/Windows.UI.Input.Spatial.SpatialGestureRecognizer.CaptureInteraction) (metodo).</span><span class="sxs-lookup"><span data-stu-id="251c6-311">Then, route the SpatialInteraction in the event arguments to the target hologram's SpatialGestureRecognizer, using its [CaptureInteraction](http://msdn.microsoft.com/library/windows/apps/xaml/Windows.UI.Input.Spatial.SpatialGestureRecognizer.CaptureInteraction) method.</span></span> <span data-ttu-id="251c6-312">Verrà avviata l'interpretazione di questa interazione in base al [SpatialGestureSettings](https://msdn.microsoft.com/library/windows/apps/xaml/Windows.UI.Input.Spatial.SpatialGestureSettings) impostata su tale riconoscimento al momento della creazione - o da [TrySetGestureSettings](http://msdn.microsoft.com/library/windows/apps/xaml/Windows.UI.Input.Spatial.SpatialGestureRecognizer.TrySetGestureSettings).</span><span class="sxs-lookup"><span data-stu-id="251c6-312">This starts interpreting that interaction according to the [SpatialGestureSettings](https://msdn.microsoft.com/library/windows/apps/xaml/Windows.UI.Input.Spatial.SpatialGestureSettings) set on that recognizer at creation time - or by [TrySetGestureSettings](http://msdn.microsoft.com/library/windows/apps/xaml/Windows.UI.Input.Spatial.SpatialGestureRecognizer.TrySetGestureSettings).</span></span>

<span data-ttu-id="251c6-313">Su HoloLens (prima di tutto di generazione), le interazioni e movimenti in genere devono derivare il targeting da sguardo head dell'utente, piuttosto che tentare per eseguire il rendering o interagire direttamente nella posizione dell'icona della mano.</span><span class="sxs-lookup"><span data-stu-id="251c6-313">On HoloLens (first gen), interactions and gestures should generally derive their targeting from the user's head gaze, rather than trying to render or interact at the hand's location directly.</span></span> <span data-ttu-id="251c6-314">Dopo aver avviato un'interazione, relativi movimenti della mano consente di controllare il movimento, come con il movimento di manipolazione o la navigazione.</span><span class="sxs-lookup"><span data-stu-id="251c6-314">Once an interaction has started, relative motions of the hand may be used to control the gesture, as with the Manipulation or Navigation gesture.</span></span>

## <a name="see-also"></a><span data-ttu-id="251c6-315">Vedere anche</span><span class="sxs-lookup"><span data-stu-id="251c6-315">See also</span></span>
* [<span data-ttu-id="251c6-316">Testa e occhio estasiati DirectX</span><span class="sxs-lookup"><span data-stu-id="251c6-316">Head and eye gaze in DirectX</span></span>](gaze-in-directx.md)
* [<span data-ttu-id="251c6-317">Modello di input di manipolazione diretta</span><span class="sxs-lookup"><span data-stu-id="251c6-317">Direct manipulation input model</span></span>](direct-manipulation.md)
* [<span data-ttu-id="251c6-318">Modello di input di punto di commit</span><span class="sxs-lookup"><span data-stu-id="251c6-318">Point-and-commit input model</span></span>](point-and-commit.md)
* [<span data-ttu-id="251c6-319">Modello di input sguardo ed eseguire il commit</span><span class="sxs-lookup"><span data-stu-id="251c6-319">Gaze and commit input model</span></span>](gaze-and-commit.md)
* [<span data-ttu-id="251c6-320">Controller del movimento</span><span class="sxs-lookup"><span data-stu-id="251c6-320">Motion controllers</span></span>](motion-controllers.md)
