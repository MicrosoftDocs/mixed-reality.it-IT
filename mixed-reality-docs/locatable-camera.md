---
title: Fotocamera individuabile
description: Informazioni generali sulla fotocamera HoloLens front-end, il suo funzionamento e i profili e le risoluzioni disponibili per gli sviluppatori.
author: cdedmonds
ms.author: wguyman
ms.date: 06/12/2019
ms.topic: article
keywords: fotocamera, hololens, fotocamera a colori, anteriore, hololens 2, CV, visione artificiale, fiduciale, marcatori, codice a matrice, QR, foto, video
ms.openlocfilehash: b8e9d926db09d277b3fde7572dd68257599c8d5e
ms.sourcegitcommit: 09d9fa153cd9072f60e33a5f83ced8167496fcd7
ms.translationtype: MT
ms.contentlocale: it-IT
ms.lasthandoff: 05/18/2020
ms.locfileid: "83520016"
---
# <a name="locatable-camera"></a><span data-ttu-id="3c1f9-104">Fotocamera individuabile</span><span class="sxs-lookup"><span data-stu-id="3c1f9-104">Locatable camera</span></span>

<span data-ttu-id="3c1f9-105">HoloLens include una fotocamera riguardante il mondo montata sulla parte anteriore del dispositivo, che consente alle app di visualizzare i dati visualizzati dall'utente.</span><span class="sxs-lookup"><span data-stu-id="3c1f9-105">HoloLens includes a world-facing camera mounted on the front of the device, which enables apps to see what the user sees.</span></span> <span data-ttu-id="3c1f9-106">Gli sviluppatori possono accedere e controllare la fotocamera, proprio come per le fotocamere a colori su smartphone, portatili o desktop.</span><span class="sxs-lookup"><span data-stu-id="3c1f9-106">Developers have access to and control of the camera, just as they would for color cameras on smartphones, portables, or desktops.</span></span> <span data-ttu-id="3c1f9-107">Le stesse API Windows [Media Capture](https://msdn.microsoft.com/library/windows/apps/windows.media.capture.mediacapture.aspx) e Windows Media Foundation che funzionano su lavoro per dispositivi mobili e desktop in HoloLens.</span><span class="sxs-lookup"><span data-stu-id="3c1f9-107">The same universal windows [media capture](https://msdn.microsoft.com/library/windows/apps/windows.media.capture.mediacapture.aspx) and windows media foundation APIs that work on mobile and desktop work on HoloLens.</span></span> <span data-ttu-id="3c1f9-108">Unity [ha inoltre eseguito il wrapper di queste API Windows](locatable-camera-in-unity.md) per astrarre un semplice utilizzo della fotocamera in HoloLens per attività quali l'esecuzione di foto e video regolari (con o senza ologrammi) e l'individuazione della posizione della fotocamera in e della prospettiva sulla scena.</span><span class="sxs-lookup"><span data-stu-id="3c1f9-108">Unity [has also wrapped these windows APIs](locatable-camera-in-unity.md) to abstract simple usage of the camera on HoloLens for tasks such as taking regular photos and videos (with or without holograms) and locating the camera's position in and perspective on the scene.</span></span>

## <a name="device-camera-information"></a><span data-ttu-id="3c1f9-109">Informazioni sulla fotocamera del dispositivo</span><span class="sxs-lookup"><span data-stu-id="3c1f9-109">Device camera information</span></span>

### <a name="hololens-first-generation"></a><span data-ttu-id="3c1f9-110">HoloLens (prima generazione)</span><span class="sxs-lookup"><span data-stu-id="3c1f9-110">HoloLens (first-generation)</span></span>

* <span data-ttu-id="3c1f9-111">Fotocamera fissa foto/video (PV) con bilanciamento del carico automatico, esposizione automatica e pipeline per l'elaborazione di immagini complete.</span><span class="sxs-lookup"><span data-stu-id="3c1f9-111">Fixed focus photo/video (PV) camera with auto white balance, auto exposure, and full image processing pipeline.</span></span>
* <span data-ttu-id="3c1f9-112">Il LED per la privacy bianca per il mondo si illuminerà ogni volta che la fotocamera è attiva</span><span class="sxs-lookup"><span data-stu-id="3c1f9-112">White Privacy LED facing the world will illuminate whenever the camera is active</span></span>
* <span data-ttu-id="3c1f9-113">La videocamera supporta le modalità seguenti (tutte le modalità sono 16:9 proporzioni) a 30, 24, 20, 15 e 5 fps:</span><span class="sxs-lookup"><span data-stu-id="3c1f9-113">The camera supports the following modes (all modes are 16:9 aspect ratio) at 30, 24, 20, 15, and 5 fps:</span></span>

  |  <span data-ttu-id="3c1f9-114">Video</span><span class="sxs-lookup"><span data-stu-id="3c1f9-114">Video</span></span>  |  <span data-ttu-id="3c1f9-115">Anteprima</span><span class="sxs-lookup"><span data-stu-id="3c1f9-115">Preview</span></span>  |  <span data-ttu-id="3c1f9-116">Ancora</span><span class="sxs-lookup"><span data-stu-id="3c1f9-116">Still</span></span>  |  <span data-ttu-id="3c1f9-117">Campo di visualizzazione orizzontale (H-FOV)</span><span class="sxs-lookup"><span data-stu-id="3c1f9-117">Horizontal Field of View (H-FOV)</span></span> |  <span data-ttu-id="3c1f9-118">Utilizzo suggerito</span><span class="sxs-lookup"><span data-stu-id="3c1f9-118">Suggested usage</span></span> | 
  |----------|----------|----------|----------|----------|
  |  <span data-ttu-id="3c1f9-119">1280x720</span><span class="sxs-lookup"><span data-stu-id="3c1f9-119">1280x720</span></span> |  <span data-ttu-id="3c1f9-120">1280x720</span><span class="sxs-lookup"><span data-stu-id="3c1f9-120">1280x720</span></span> |  <span data-ttu-id="3c1f9-121">1280x720</span><span class="sxs-lookup"><span data-stu-id="3c1f9-121">1280x720</span></span> |  <span data-ttu-id="3c1f9-122">45deg</span><span class="sxs-lookup"><span data-stu-id="3c1f9-122">45deg</span></span>  |  <span data-ttu-id="3c1f9-123">(modalità predefinita con stabilizzazione video)</span><span class="sxs-lookup"><span data-stu-id="3c1f9-123">(default mode with video stabilization)</span></span> | 
  |  <span data-ttu-id="3c1f9-124">N/D</span><span class="sxs-lookup"><span data-stu-id="3c1f9-124">N/A</span></span> |  <span data-ttu-id="3c1f9-125">N/D</span><span class="sxs-lookup"><span data-stu-id="3c1f9-125">N/A</span></span> |  <span data-ttu-id="3c1f9-126">2048x1152</span><span class="sxs-lookup"><span data-stu-id="3c1f9-126">2048x1152</span></span> |  <span data-ttu-id="3c1f9-127">67deg</span><span class="sxs-lookup"><span data-stu-id="3c1f9-127">67deg</span></span> |  <span data-ttu-id="3c1f9-128">Immagine ancora a risoluzione massima</span><span class="sxs-lookup"><span data-stu-id="3c1f9-128">Highest resolution still image</span></span> | 
  |  <span data-ttu-id="3c1f9-129">1408x792</span><span class="sxs-lookup"><span data-stu-id="3c1f9-129">1408x792</span></span> |  <span data-ttu-id="3c1f9-130">1408x792</span><span class="sxs-lookup"><span data-stu-id="3c1f9-130">1408x792</span></span> |  <span data-ttu-id="3c1f9-131">1408x792</span><span class="sxs-lookup"><span data-stu-id="3c1f9-131">1408x792</span></span> |  <span data-ttu-id="3c1f9-132">48deg</span><span class="sxs-lookup"><span data-stu-id="3c1f9-132">48deg</span></span> |  <span data-ttu-id="3c1f9-133">Risoluzione Overscan (riempimento) prima della stabilizzazione del video</span><span class="sxs-lookup"><span data-stu-id="3c1f9-133">Overscan (padding) resolution before video stabilization</span></span> | 
  |  <span data-ttu-id="3c1f9-134">1344x756</span><span class="sxs-lookup"><span data-stu-id="3c1f9-134">1344x756</span></span> |  <span data-ttu-id="3c1f9-135">1344x756</span><span class="sxs-lookup"><span data-stu-id="3c1f9-135">1344x756</span></span> |  <span data-ttu-id="3c1f9-136">1344x756</span><span class="sxs-lookup"><span data-stu-id="3c1f9-136">1344x756</span></span> |  <span data-ttu-id="3c1f9-137">67deg</span><span class="sxs-lookup"><span data-stu-id="3c1f9-137">67deg</span></span> |  <span data-ttu-id="3c1f9-138">Modalità video FOV grande con overscan</span><span class="sxs-lookup"><span data-stu-id="3c1f9-138">Large FOV video mode with overscan</span></span> | 
  |  <span data-ttu-id="3c1f9-139">896x504</span><span class="sxs-lookup"><span data-stu-id="3c1f9-139">896x504</span></span> |  <span data-ttu-id="3c1f9-140">896x504</span><span class="sxs-lookup"><span data-stu-id="3c1f9-140">896x504</span></span> |  <span data-ttu-id="3c1f9-141">896x504</span><span class="sxs-lookup"><span data-stu-id="3c1f9-141">896x504</span></span> |  <span data-ttu-id="3c1f9-142">48deg</span><span class="sxs-lookup"><span data-stu-id="3c1f9-142">48deg</span></span> |  <span data-ttu-id="3c1f9-143">Bassa potenza/modalità di risoluzione bassa per le attività di elaborazione delle immagini</span><span class="sxs-lookup"><span data-stu-id="3c1f9-143">Low power / Low resolution mode for image processing tasks</span></span> | 

### <a name="hololens-2"></a><span data-ttu-id="3c1f9-144">HoloLens 2</span><span class="sxs-lookup"><span data-stu-id="3c1f9-144">HoloLens 2</span></span>

* <span data-ttu-id="3c1f9-145">Fotocamera con messa a fuoco automatica per foto/video (PV) con bilanciamento del carico automatico, esposizione automatica e pipeline per l'elaborazione di immagini complete.</span><span class="sxs-lookup"><span data-stu-id="3c1f9-145">Auto-focus photo/video (PV) camera with auto white balance, auto exposure, and full image processing pipeline.</span></span>
* <span data-ttu-id="3c1f9-146">Il LED per la privacy bianca per il mondo si illuminerà ogni volta che la fotocamera è attiva.</span><span class="sxs-lookup"><span data-stu-id="3c1f9-146">White Privacy LED facing the world will illuminate whenever the camera is active.</span></span>
* <span data-ttu-id="3c1f9-147">HoloLens 2 supporta diversi profili fotocamera.</span><span class="sxs-lookup"><span data-stu-id="3c1f9-147">HoloLens 2 supports different camera profiles.</span></span> <span data-ttu-id="3c1f9-148">Informazioni su come [individuare e selezionare le funzionalità della fotocamera](https://docs.microsoft.com//windows/uwp/audio-video-camera/camera-profiles).</span><span class="sxs-lookup"><span data-stu-id="3c1f9-148">Learn how to [discover and select camera capabilities](https://docs.microsoft.com//windows/uwp/audio-video-camera/camera-profiles).</span></span>
* <span data-ttu-id="3c1f9-149">La videocamera supporta i profili e le risoluzioni seguenti (tutte le modalità video sono 16:9 proporzioni):</span><span class="sxs-lookup"><span data-stu-id="3c1f9-149">The camera supports the following profiles and resolutions (all video modes are 16:9 aspect ratio):</span></span>
  
  | <span data-ttu-id="3c1f9-150">Profilo</span><span class="sxs-lookup"><span data-stu-id="3c1f9-150">Profile</span></span>                                         | <span data-ttu-id="3c1f9-151">Video</span><span class="sxs-lookup"><span data-stu-id="3c1f9-151">Video</span></span>     | <span data-ttu-id="3c1f9-152">Anteprima</span><span class="sxs-lookup"><span data-stu-id="3c1f9-152">Preview</span></span>   | <span data-ttu-id="3c1f9-153">Ancora</span><span class="sxs-lookup"><span data-stu-id="3c1f9-153">Still</span></span>     | <span data-ttu-id="3c1f9-154">Frequenza fotogrammi</span><span class="sxs-lookup"><span data-stu-id="3c1f9-154">Frame rates</span></span> | <span data-ttu-id="3c1f9-155">Campo di visualizzazione orizzontale (H-FOV)</span><span class="sxs-lookup"><span data-stu-id="3c1f9-155">Horizontal Field of View (H-FOV)</span></span> | <span data-ttu-id="3c1f9-156">Utilizzo suggerito</span><span class="sxs-lookup"><span data-stu-id="3c1f9-156">Suggested usage</span></span>                             |
  |-------------------------------------------------|-----------|-----------|-----------|-------------|----------------------------------|---------------------------------------------|
  | <span data-ttu-id="3c1f9-157">Legacy, 0 BalancedVideoAndPhoto, 100</span><span class="sxs-lookup"><span data-stu-id="3c1f9-157">Legacy,0  BalancedVideoAndPhoto,100</span></span>             | <span data-ttu-id="3c1f9-158">2272x1278</span><span class="sxs-lookup"><span data-stu-id="3c1f9-158">2272x1278</span></span> | <span data-ttu-id="3c1f9-159">2272x1278</span><span class="sxs-lookup"><span data-stu-id="3c1f9-159">2272x1278</span></span> |           | <span data-ttu-id="3c1f9-160">15, 30</span><span class="sxs-lookup"><span data-stu-id="3c1f9-160">15,30</span></span>       | <span data-ttu-id="3c1f9-161">64,69</span><span class="sxs-lookup"><span data-stu-id="3c1f9-161">64.69</span></span>                            | <span data-ttu-id="3c1f9-162">Registrazione video di alta qualità</span><span class="sxs-lookup"><span data-stu-id="3c1f9-162">High quality video recording</span></span>                |
  | <span data-ttu-id="3c1f9-163">Legacy, 0 BalancedVideoAndPhoto, 100</span><span class="sxs-lookup"><span data-stu-id="3c1f9-163">Legacy,0  BalancedVideoAndPhoto,100</span></span>             | <span data-ttu-id="3c1f9-164">896x504</span><span class="sxs-lookup"><span data-stu-id="3c1f9-164">896x504</span></span>   | <span data-ttu-id="3c1f9-165">896x504</span><span class="sxs-lookup"><span data-stu-id="3c1f9-165">896x504</span></span>   |           | <span data-ttu-id="3c1f9-166">15, 30</span><span class="sxs-lookup"><span data-stu-id="3c1f9-166">15,30</span></span>       | <span data-ttu-id="3c1f9-167">64,69</span><span class="sxs-lookup"><span data-stu-id="3c1f9-167">64.69</span></span>                            | <span data-ttu-id="3c1f9-168">Flusso di anteprima per acquisizione foto di alta qualità</span><span class="sxs-lookup"><span data-stu-id="3c1f9-168">Preview stream for high quality photo capture</span></span> |
  | <span data-ttu-id="3c1f9-169">Legacy, 0 BalancedVideoAndPhoto, 100</span><span class="sxs-lookup"><span data-stu-id="3c1f9-169">Legacy,0  BalancedVideoAndPhoto,100</span></span>             |           |           | <span data-ttu-id="3c1f9-170">3904x2196</span><span class="sxs-lookup"><span data-stu-id="3c1f9-170">3904x2196</span></span> |             | <span data-ttu-id="3c1f9-171">64,69</span><span class="sxs-lookup"><span data-stu-id="3c1f9-171">64.69</span></span>                            | <span data-ttu-id="3c1f9-172">Acquisizione foto di alta qualità</span><span class="sxs-lookup"><span data-stu-id="3c1f9-172">High quality photo capture</span></span>                  |
  | <span data-ttu-id="3c1f9-173">BalancedVideoAndPhoto, 120</span><span class="sxs-lookup"><span data-stu-id="3c1f9-173">BalancedVideoAndPhoto,120</span></span>                       | <span data-ttu-id="3c1f9-174">1952x1100</span><span class="sxs-lookup"><span data-stu-id="3c1f9-174">1952x1100</span></span> | <span data-ttu-id="3c1f9-175">1952x1100</span><span class="sxs-lookup"><span data-stu-id="3c1f9-175">1952x1100</span></span> | <span data-ttu-id="3c1f9-176">1952x1100</span><span class="sxs-lookup"><span data-stu-id="3c1f9-176">1952x1100</span></span> | <span data-ttu-id="3c1f9-177">15, 30</span><span class="sxs-lookup"><span data-stu-id="3c1f9-177">15,30</span></span>       | <span data-ttu-id="3c1f9-178">64,69</span><span class="sxs-lookup"><span data-stu-id="3c1f9-178">64.69</span></span>                            | <span data-ttu-id="3c1f9-179">Scenari a lunga durata</span><span class="sxs-lookup"><span data-stu-id="3c1f9-179">Long duration scenarios</span></span>                     |
  | <span data-ttu-id="3c1f9-180">BalancedVideoAndPhoto, 120</span><span class="sxs-lookup"><span data-stu-id="3c1f9-180">BalancedVideoAndPhoto,120</span></span>                       | <span data-ttu-id="3c1f9-181">1504x846</span><span class="sxs-lookup"><span data-stu-id="3c1f9-181">1504x846</span></span>  | <span data-ttu-id="3c1f9-182">1504x846</span><span class="sxs-lookup"><span data-stu-id="3c1f9-182">1504x846</span></span>  |           | <span data-ttu-id="3c1f9-183">15, 30</span><span class="sxs-lookup"><span data-stu-id="3c1f9-183">15,30</span></span>       | <span data-ttu-id="3c1f9-184">64,69</span><span class="sxs-lookup"><span data-stu-id="3c1f9-184">64.69</span></span>                            | <span data-ttu-id="3c1f9-185">Scenari a lunga durata</span><span class="sxs-lookup"><span data-stu-id="3c1f9-185">Long duration scenarios</span></span>                     |
  | <span data-ttu-id="3c1f9-186">Videoconferenza, 100</span><span class="sxs-lookup"><span data-stu-id="3c1f9-186">VideoConferencing,100</span></span>                           | <span data-ttu-id="3c1f9-187">1952x1100</span><span class="sxs-lookup"><span data-stu-id="3c1f9-187">1952x1100</span></span> | <span data-ttu-id="3c1f9-188">1952x1100</span><span class="sxs-lookup"><span data-stu-id="3c1f9-188">1952x1100</span></span> | <span data-ttu-id="3c1f9-189">1952x1100</span><span class="sxs-lookup"><span data-stu-id="3c1f9-189">1952x1100</span></span> | <span data-ttu-id="3c1f9-190">15, 30, 60</span><span class="sxs-lookup"><span data-stu-id="3c1f9-190">15,30,60</span></span>    | <span data-ttu-id="3c1f9-191">64,69</span><span class="sxs-lookup"><span data-stu-id="3c1f9-191">64.69</span></span>                            | <span data-ttu-id="3c1f9-192">Conferenze video, scenari con lunga durata</span><span class="sxs-lookup"><span data-stu-id="3c1f9-192">Video conferencing, long duration scenarios</span></span> |
  | <span data-ttu-id="3c1f9-193">Videoconferenza, 100</span><span class="sxs-lookup"><span data-stu-id="3c1f9-193">Videoconferencing,100</span></span>                           | <span data-ttu-id="3c1f9-194">1504x846</span><span class="sxs-lookup"><span data-stu-id="3c1f9-194">1504x846</span></span>  | <span data-ttu-id="3c1f9-195">1504x846</span><span class="sxs-lookup"><span data-stu-id="3c1f9-195">1504x846</span></span>  |           | <span data-ttu-id="3c1f9-196">5, 15, 30, 60</span><span class="sxs-lookup"><span data-stu-id="3c1f9-196">5,15,30,60</span></span>  | <span data-ttu-id="3c1f9-197">64,69</span><span class="sxs-lookup"><span data-stu-id="3c1f9-197">64.69</span></span>                            | <span data-ttu-id="3c1f9-198">Conferenze video, scenari con lunga durata</span><span class="sxs-lookup"><span data-stu-id="3c1f9-198">Video conferencing, long duration scenarios</span></span> |
  | <span data-ttu-id="3c1f9-199">Videoconferenza, 100 BalancedVideoAndPhoto, 120</span><span class="sxs-lookup"><span data-stu-id="3c1f9-199">Videoconferencing,100 BalancedVideoAndPhoto,120</span></span> | <span data-ttu-id="3c1f9-200">1920x1080</span><span class="sxs-lookup"><span data-stu-id="3c1f9-200">1920x1080</span></span> | <span data-ttu-id="3c1f9-201">1920x1080</span><span class="sxs-lookup"><span data-stu-id="3c1f9-201">1920x1080</span></span> | <span data-ttu-id="3c1f9-202">1920x1080</span><span class="sxs-lookup"><span data-stu-id="3c1f9-202">1920x1080</span></span> | <span data-ttu-id="3c1f9-203">15, 30</span><span class="sxs-lookup"><span data-stu-id="3c1f9-203">15,30</span></span>       | <span data-ttu-id="3c1f9-204">64,69</span><span class="sxs-lookup"><span data-stu-id="3c1f9-204">64.69</span></span>                            | <span data-ttu-id="3c1f9-205">Conferenze video, scenari con lunga durata</span><span class="sxs-lookup"><span data-stu-id="3c1f9-205">Video conferencing, long duration scenarios</span></span> |
  | <span data-ttu-id="3c1f9-206">Videoconferenza, 100 BalancedVideoAndPhoto, 120</span><span class="sxs-lookup"><span data-stu-id="3c1f9-206">Videoconferencing,100 BalancedVideoAndPhoto,120</span></span> | <span data-ttu-id="3c1f9-207">1280x720</span><span class="sxs-lookup"><span data-stu-id="3c1f9-207">1280x720</span></span>  | <span data-ttu-id="3c1f9-208">1280x720</span><span class="sxs-lookup"><span data-stu-id="3c1f9-208">1280x720</span></span>  | <span data-ttu-id="3c1f9-209">1280x720</span><span class="sxs-lookup"><span data-stu-id="3c1f9-209">1280x720</span></span>  | <span data-ttu-id="3c1f9-210">15, 30</span><span class="sxs-lookup"><span data-stu-id="3c1f9-210">15,30</span></span>       | <span data-ttu-id="3c1f9-211">64,69</span><span class="sxs-lookup"><span data-stu-id="3c1f9-211">64.69</span></span>                            | <span data-ttu-id="3c1f9-212">Conferenze video, scenari con lunga durata</span><span class="sxs-lookup"><span data-stu-id="3c1f9-212">Video conferencing, long duration scenarios</span></span> |
  | <span data-ttu-id="3c1f9-213">Videoconferenza, 100 BalancedVideoAndPhoto, 120</span><span class="sxs-lookup"><span data-stu-id="3c1f9-213">Videoconferencing,100 BalancedVideoAndPhoto,120</span></span> | <span data-ttu-id="3c1f9-214">1128x636</span><span class="sxs-lookup"><span data-stu-id="3c1f9-214">1128x636</span></span>  |           |           | <span data-ttu-id="3c1f9-215">15, 30</span><span class="sxs-lookup"><span data-stu-id="3c1f9-215">15,30</span></span>       | <span data-ttu-id="3c1f9-216">64,69</span><span class="sxs-lookup"><span data-stu-id="3c1f9-216">64.69</span></span>                            | <span data-ttu-id="3c1f9-217">Conferenze video, scenari con lunga durata</span><span class="sxs-lookup"><span data-stu-id="3c1f9-217">Video conferencing, long duration scenarios</span></span> |
  | <span data-ttu-id="3c1f9-218">Videoconferenza, 100 BalancedVideoAndPhoto, 120</span><span class="sxs-lookup"><span data-stu-id="3c1f9-218">Videoconferencing,100 BalancedVideoAndPhoto,120</span></span> | <span data-ttu-id="3c1f9-219">960x540</span><span class="sxs-lookup"><span data-stu-id="3c1f9-219">960x540</span></span>   |           |           | <span data-ttu-id="3c1f9-220">15, 30</span><span class="sxs-lookup"><span data-stu-id="3c1f9-220">15,30</span></span>       | <span data-ttu-id="3c1f9-221">64,69</span><span class="sxs-lookup"><span data-stu-id="3c1f9-221">64.69</span></span>                            | <span data-ttu-id="3c1f9-222">Conferenze video, scenari con lunga durata</span><span class="sxs-lookup"><span data-stu-id="3c1f9-222">Video conferencing, long duration scenarios</span></span> |
  | <span data-ttu-id="3c1f9-223">Videoconferenza, 100 BalancedVideoAndPhoto, 120</span><span class="sxs-lookup"><span data-stu-id="3c1f9-223">Videoconferencing,100 BalancedVideoAndPhoto,120</span></span> | <span data-ttu-id="3c1f9-224">760x428</span><span class="sxs-lookup"><span data-stu-id="3c1f9-224">760x428</span></span>   |           |           | <span data-ttu-id="3c1f9-225">15, 30</span><span class="sxs-lookup"><span data-stu-id="3c1f9-225">15,30</span></span>       | <span data-ttu-id="3c1f9-226">64,69</span><span class="sxs-lookup"><span data-stu-id="3c1f9-226">64.69</span></span>                            | <span data-ttu-id="3c1f9-227">Conferenze video, scenari con lunga durata</span><span class="sxs-lookup"><span data-stu-id="3c1f9-227">Video conferencing, long duration scenarios</span></span> |
  | <span data-ttu-id="3c1f9-228">Videoconferenza, 100 BalancedVideoAndPhoto, 120</span><span class="sxs-lookup"><span data-stu-id="3c1f9-228">Videoconferencing,100 BalancedVideoAndPhoto,120</span></span> | <span data-ttu-id="3c1f9-229">640x360</span><span class="sxs-lookup"><span data-stu-id="3c1f9-229">640x360</span></span>   |           |           | <span data-ttu-id="3c1f9-230">15, 30</span><span class="sxs-lookup"><span data-stu-id="3c1f9-230">15,30</span></span>       | <span data-ttu-id="3c1f9-231">64,69</span><span class="sxs-lookup"><span data-stu-id="3c1f9-231">64.69</span></span>                            | <span data-ttu-id="3c1f9-232">Conferenze video, scenari con lunga durata</span><span class="sxs-lookup"><span data-stu-id="3c1f9-232">Video conferencing, long duration scenarios</span></span> |
  | <span data-ttu-id="3c1f9-233">Videoconferenza, 100 BalancedVideoAndPhoto, 120</span><span class="sxs-lookup"><span data-stu-id="3c1f9-233">Videoconferencing,100 BalancedVideoAndPhoto,120</span></span> | <span data-ttu-id="3c1f9-234">500x282</span><span class="sxs-lookup"><span data-stu-id="3c1f9-234">500x282</span></span>   |           |           | <span data-ttu-id="3c1f9-235">15, 30</span><span class="sxs-lookup"><span data-stu-id="3c1f9-235">15,30</span></span>       | <span data-ttu-id="3c1f9-236">64,69</span><span class="sxs-lookup"><span data-stu-id="3c1f9-236">64.69</span></span>                            | <span data-ttu-id="3c1f9-237">Conferenze video, scenari con lunga durata</span><span class="sxs-lookup"><span data-stu-id="3c1f9-237">Video conferencing, long duration scenarios</span></span> |
  | <span data-ttu-id="3c1f9-238">Videoconferenza, 100 BalancedVideoAndPhoto, 120</span><span class="sxs-lookup"><span data-stu-id="3c1f9-238">Videoconferencing,100 BalancedVideoAndPhoto,120</span></span> | <span data-ttu-id="3c1f9-239">424x240</span><span class="sxs-lookup"><span data-stu-id="3c1f9-239">424x240</span></span>   |           |           | <span data-ttu-id="3c1f9-240">15, 30</span><span class="sxs-lookup"><span data-stu-id="3c1f9-240">15,30</span></span>       | <span data-ttu-id="3c1f9-241">64,69</span><span class="sxs-lookup"><span data-stu-id="3c1f9-241">64.69</span></span>                            | <span data-ttu-id="3c1f9-242">Conferenze video, scenari con lunga durata</span><span class="sxs-lookup"><span data-stu-id="3c1f9-242">Video conferencing, long duration scenarios</span></span> |

>[!NOTE]
><span data-ttu-id="3c1f9-243">I clienti possono sfruttare la funzionalità di [acquisizione di realtà mista](mixed-reality-capture.md) per scattare video o foto dell'app, tra cui ologrammi e stabilizzazione video.</span><span class="sxs-lookup"><span data-stu-id="3c1f9-243">Customers can leverage [mixed reality capture](mixed-reality-capture.md) to take videos or photos of your app, which include holograms and video stabilization.</span></span>
>
><span data-ttu-id="3c1f9-244">In qualità di sviluppatore, è necessario tenere conto di quando si crea l'app se si vuole che l'app risulti più adatta possibile quando un cliente acquisisce il contenuto.</span><span class="sxs-lookup"><span data-stu-id="3c1f9-244">As a developer, there are considerations you should take into account when creating your app if you want it to look as good as possible when a customer captures content.</span></span> <span data-ttu-id="3c1f9-245">È anche possibile abilitare e personalizzare l'acquisizione di realtà mista direttamente dall'interno dell'app.</span><span class="sxs-lookup"><span data-stu-id="3c1f9-245">You can also enable (and customize) mixed reality capture from directly within your app.</span></span> <span data-ttu-id="3c1f9-246">Scopri di più su [acquisizione di realtà mista per gli sviluppatori](mixed-reality-capture-for-developers.md).</span><span class="sxs-lookup"><span data-stu-id="3c1f9-246">Learn more at [mixed reality capture for developers](mixed-reality-capture-for-developers.md).</span></span>

## <a name="locating-the-device-camera-in-the-world"></a><span data-ttu-id="3c1f9-247">Individuazione della fotocamera del dispositivo nel mondo</span><span class="sxs-lookup"><span data-stu-id="3c1f9-247">Locating the Device Camera in the World</span></span>

<span data-ttu-id="3c1f9-248">Quando HoloLens acquisisce foto e video, i frame acquisiti includono il percorso della fotocamera nel mondo, oltre al modello di obiettivo della fotocamera.</span><span class="sxs-lookup"><span data-stu-id="3c1f9-248">When HoloLens takes photos and videos, the captured frames include the location of the camera in the world, as well as the lens model of the camera.</span></span> <span data-ttu-id="3c1f9-249">Questo consente alle applicazioni di ragionare sulla posizione della fotocamera nel mondo reale per gli scenari di creazione di immagini potenziati.</span><span class="sxs-lookup"><span data-stu-id="3c1f9-249">This allows applications to reason about the position of the camera in the real world for augmented imaging scenarios.</span></span> <span data-ttu-id="3c1f9-250">Gli sviluppatori possono eseguire il Rolling dei propri scenari in modo creativo usando l'elaborazione di immagini preferite o librerie personalizzate per la visione del computer.</span><span class="sxs-lookup"><span data-stu-id="3c1f9-250">Developers can creatively roll their own scenarios using their favorite image processing or custom computer vision libraries.</span></span>

<span data-ttu-id="3c1f9-251">"La fotocamera" altrove nella documentazione di HoloLens può riferirsi alla "fotocamera virtuale del gioco" (tronco a cui viene eseguito il rendering dell'app).</span><span class="sxs-lookup"><span data-stu-id="3c1f9-251">"Camera" elsewhere in HoloLens documentation may refer to the "virtual game camera" (the frustum the app renders to).</span></span> <span data-ttu-id="3c1f9-252">Se non indicato diversamente, "camera" in questa pagina si riferisce alla fotocamera a colori RGB del mondo reale.</span><span class="sxs-lookup"><span data-stu-id="3c1f9-252">Unless denoted otherwise, "camera" on this page refers to the real-world RGB color camera.</span></span>

### <a name="using-unity"></a><span data-ttu-id="3c1f9-253">Uso di Unity</span><span class="sxs-lookup"><span data-stu-id="3c1f9-253">Using Unity</span></span>

<span data-ttu-id="3c1f9-254">Per passare da "CameraIntrinsics" e "CameraCoordinateSystem" al sistema di coordinate dell'applicazione o del mondo, seguire le istruzioni riportate nell'articolo sulla [fotocamera di locatable in Unity](locatable-camera-in-unity.md) .</span><span class="sxs-lookup"><span data-stu-id="3c1f9-254">To go from the 'CameraIntrinsics' and 'CameraCoordinateSystem' to your application/world coordinate system, follow the instructions in the [Locatable camera in Unity](locatable-camera-in-unity.md) article.</span></span>  <span data-ttu-id="3c1f9-255">CameraToWorldMatrix viene fornito automaticamente dalla classe PhotoCaptureFrame e pertanto non è necessario preoccuparsi delle trasformazioni CameraCoordinateSystem descritte di seguito.</span><span class="sxs-lookup"><span data-stu-id="3c1f9-255">CameraToWorldMatrix is automatically provided by PhotoCaptureFrame class, and so you don't need to worry about the CameraCoordinateSystem transforms discussed below.</span></span>

### <a name="using-mediaframereference"></a><span data-ttu-id="3c1f9-256">Uso di MediaFrameReference</span><span class="sxs-lookup"><span data-stu-id="3c1f9-256">Using MediaFrameReference</span></span>

<span data-ttu-id="3c1f9-257">Queste istruzioni si applicano se si usa la classe [MediaFrameReference](https://docs.microsoft.com//uwp/api/windows.media.capture.frames.mediaframereference) per leggere i frame immagine dalla fotocamera.</span><span class="sxs-lookup"><span data-stu-id="3c1f9-257">These instructions apply if you are using the [MediaFrameReference](https://docs.microsoft.com//uwp/api/windows.media.capture.frames.mediaframereference) class to read image frames from the camera.</span></span>

<span data-ttu-id="3c1f9-258">Ogni fotogramma immagine (foto o video) include un [SpatialCoordinateSystem](https://docs.microsoft.com//uwp/api/windows.perception.spatial.spatialcoordinatesystem) radice alla fotocamera al momento dell'acquisizione, a cui è possibile accedere usando la proprietà [CoordinateSystem](https://docs.microsoft.com//uwp/api/windows.media.capture.frames.mediaframereference.coordinatesystem#Windows_Media_Capture_Frames_MediaFrameReference_CoordinateSystem) di [MediaFrameReference](https://docs.microsoft.com//uwp/api/Windows.Media.Capture.Frames.MediaFrameReference).</span><span class="sxs-lookup"><span data-stu-id="3c1f9-258">Each image frame (whether photo or video) includes a [SpatialCoordinateSystem](https://docs.microsoft.com//uwp/api/windows.perception.spatial.spatialcoordinatesystem) rooted at the camera at the time of capture, which can be accessed using the [CoordinateSystem](https://docs.microsoft.com//uwp/api/windows.media.capture.frames.mediaframereference.coordinatesystem#Windows_Media_Capture_Frames_MediaFrameReference_CoordinateSystem) property of your [MediaFrameReference](https://docs.microsoft.com//uwp/api/Windows.Media.Capture.Frames.MediaFrameReference).</span></span> <span data-ttu-id="3c1f9-259">Ogni frame contiene inoltre una descrizione del modello di obiettivo della fotocamera, che è possibile trovare nella proprietà [CameraIntrinsics](https://docs.microsoft.com//uwp/api/windows.media.capture.frames.videomediaframe.cameraintrinsics#Windows_Media_Capture_Frames_VideoMediaFrame_CameraIntrinsics) .</span><span class="sxs-lookup"><span data-stu-id="3c1f9-259">In addition, each frame contains a description of the camera lens model, which can be found in the [CameraIntrinsics](https://docs.microsoft.com//uwp/api/windows.media.capture.frames.videomediaframe.cameraintrinsics#Windows_Media_Capture_Frames_VideoMediaFrame_CameraIntrinsics) property.</span></span> <span data-ttu-id="3c1f9-260">Insieme, queste trasformazioni definiscono per ogni pixel un raggio nello spazio 3D che rappresenta il percorso utilizzato dai fotoni che hanno prodotto il pixel.</span><span class="sxs-lookup"><span data-stu-id="3c1f9-260">Together, these transforms define for each pixel a ray in 3D space representing the path taken by the photons that produced the pixel.</span></span> <span data-ttu-id="3c1f9-261">Questi raggi possono essere correlati ad altro contenuto nell'app ottenendo la trasformazione dal sistema di coordinate del frame a un altro sistema di coordinate, ad esempio da un [frame di riferimento](coordinate-systems.md#stationary-frame-of-reference)fisso.</span><span class="sxs-lookup"><span data-stu-id="3c1f9-261">These rays can be related to other content in the app by obtaining the transform from the frame's coordinate system to some other coordinate system (e.g. from a [stationary frame of reference](coordinate-systems.md#stationary-frame-of-reference)).</span></span> <span data-ttu-id="3c1f9-262">Per riepilogare, ogni frame dell'immagine offre quanto segue:</span><span class="sxs-lookup"><span data-stu-id="3c1f9-262">To summarize, each image frame provides the following:</span></span>
* <span data-ttu-id="3c1f9-263">Dati pixel (in formato RGB/NV12/JPEG/ecc.)</span><span class="sxs-lookup"><span data-stu-id="3c1f9-263">Pixel Data (in RGB/NV12/JPEG/etc. format)</span></span>
* <span data-ttu-id="3c1f9-264">[SpatialCoordinateSystem](https://docs.microsoft.com//uwp/api/windows.perception.spatial.spatialcoordinatesystem) dalla posizione di acquisizione</span><span class="sxs-lookup"><span data-stu-id="3c1f9-264">A [SpatialCoordinateSystem](https://docs.microsoft.com//uwp/api/windows.perception.spatial.spatialcoordinatesystem) from the location of capture</span></span>
* <span data-ttu-id="3c1f9-265">Classe [CameraIntrinsics](https://docs.microsoft.com//uwp/api/windows.media.capture.frames.videomediaframe.cameraintrinsics#Windows_Media_Capture_Frames_VideoMediaFrame_CameraIntrinsics) che contiene la modalità Lens della fotocamera</span><span class="sxs-lookup"><span data-stu-id="3c1f9-265">A [CameraIntrinsics](https://docs.microsoft.com//uwp/api/windows.media.capture.frames.videomediaframe.cameraintrinsics#Windows_Media_Capture_Frames_VideoMediaFrame_CameraIntrinsics) class containing the lens mode of the camera</span></span>

<span data-ttu-id="3c1f9-266">Nell' [esempio HolographicFaceTracking](https://github.com/Microsoft/Windows-universal-samples/tree/master/Samples/HolographicFaceTracking) viene illustrato il modo piuttosto semplice per eseguire una query per la trasformazione tra il sistema di coordinate della fotocamera e i sistemi di coordinate dell'applicazione.</span><span class="sxs-lookup"><span data-stu-id="3c1f9-266">The [HolographicFaceTracking sample](https://github.com/Microsoft/Windows-universal-samples/tree/master/Samples/HolographicFaceTracking) shows the fairly straightforward way to query for the transform between the camera's coordinate system and your own application coordinate systems.</span></span>

### <a name="using-media-foundation"></a><span data-ttu-id="3c1f9-267">Utilizzo di Media Foundation</span><span class="sxs-lookup"><span data-stu-id="3c1f9-267">Using Media Foundation</span></span>

<span data-ttu-id="3c1f9-268">Se si usa direttamente Media Foundation per leggere i frame di immagini dalla fotocamera, è possibile usare l' [attributo MFSampleExtension_CameraExtrinsics](https://docs.microsoft.com/windows/win32/medfound/mfsampleextension-cameraextrinsics) di ogni frame e [MFSampleExtension_PinholeCameraIntrinsics attributo](https://docs.microsoft.com/windows/win32/medfound/mfsampleextension-pinholecameraintrinsics) per individuare i frame della fotocamera rispetto agli altri sistemi di coordinate dell'applicazione, come illustrato nel codice di esempio seguente:</span><span class="sxs-lookup"><span data-stu-id="3c1f9-268">If you are using Media Foundation directly to read image frames from the camera, you can use each frame's [MFSampleExtension_CameraExtrinsics attribute](https://docs.microsoft.com/windows/win32/medfound/mfsampleextension-cameraextrinsics) and [MFSampleExtension_PinholeCameraIntrinsics attribute](https://docs.microsoft.com/windows/win32/medfound/mfsampleextension-pinholecameraintrinsics) to locate camera frames relative to your application's other coordinate systems, as shown in this sample code:</span></span>

```cpp
#include <winrt/windows.perception.spatial.preview.h>
#include <mfapi.h>
#include <mfidl.h>
 
using namespace winrt::Windows::Foundation;
using namespace winrt::Windows::Foundation::Numerics;
using namespace winrt::Windows::Perception;
using namespace winrt::Windows::Perception::Spatial;
using namespace winrt::Windows::Perception::Spatial::Preview;
 
class CameraFrameLocator
{
public:
    struct CameraFrameLocation
    {
        SpatialCoordinateSystem CoordinateSystem;
        float4x4 CameraViewToCoordinateSytemTransform;
        MFPinholeCameraIntrinsics Intrinsics;
    };
 
    std::optional<CameraFrameLocation> TryLocateCameraFrame(IMFSample* pSample)
    {
        MFCameraExtrinsics cameraExtrinsics;
        MFPinholeCameraIntrinsics cameraIntrinsics;
        UINT32 sizeCameraExtrinsics = 0;
        UINT32 sizeCameraIntrinsics = 0;
        UINT64 sampleTimeQpc = 0;
 
        // query sample for calibration and validate
        if (FAILED(pSample->GetUINT64(MFSampleExtension_DeviceTimestamp, &sampleTimeQpc)) ||
            FAILED(pSample->GetBlob(MFSampleExtension_CameraExtrinsics, (UINT8*)& cameraExtrinsics, sizeof(cameraExtrinsics), &sizeCameraExtrinsics)) ||
            FAILED(pSample->GetBlob(MFSampleExtension_PinholeCameraIntrinsics, (UINT8*)& cameraIntrinsics, sizeof(cameraIntrinsics), &sizeCameraIntrinsics)) ||
            (sizeCameraExtrinsics != sizeof(cameraExtrinsics)) ||
            (sizeCameraIntrinsics != sizeof(cameraIntrinsics)) ||
            (cameraExtrinsics.TransformCount == 0))
        {
            return std::nullopt;
        }
 
        // compute extrinsic transform
        const auto& calibratedTransform = cameraExtrinsics.CalibratedTransforms[0];
        const GUID& dynamicNodeId = calibratedTransform.CalibrationId;
        const float4x4 cameraToDynamicNode =
            make_float4x4_from_quaternion(quaternion{ calibratedTransform.Orientation.x, calibratedTransform.Orientation.y, calibratedTransform.Orientation.z, calibratedTransform.Orientation.w }) *
            make_float4x4_translation(calibratedTransform.Position.x, calibratedTransform.Position.y, calibratedTransform.Position.z);
 
        // update locator cache for dynamic node
        if (dynamicNodeId != m_currentDynamicNodeId || !m_locator)
        {
            m_locator = SpatialGraphInteropPreview::CreateLocatorForNode(dynamicNodeId);
            if (!m_locator)
            {
                return std::nullopt;
            }
 
            m_frameOfReference = m_locator.CreateAttachedFrameOfReferenceAtCurrentHeading();
            m_currentDynamicNodeId = dynamicNodeId;
        }
 
        // locate dynamic node
        auto timestamp = PerceptionTimestampHelper::FromSystemRelativeTargetTime(TimeSpanFrodmQpcTicks(sampleTimeQpc));
        auto coordinateSystem = m_frameOfReference.GetStationaryCoordinateSystemAtTimestamp(timestamp);
        auto location = m_locator.TryLocateAtTimestamp(timestamp, coordinateSystem);
        if (!location)
        {
            return std::nullopt;
        }
 
        const float4x4 dynamicNodeToCoordinateSystem = make_float4x4_from_quaternion(location.Orientation()) * make_float4x4_translation(location.Position());
 
        return CameraFrameLocation{ coordinateSystem, cameraToDynamicNode * dynamicNodeToCoordinateSystem, cameraIntrinsics };
    }
 
private:
    GUID m_currentDynamicNodeId{ GUID_NULL };
    SpatialLocator m_locator{ nullptr };
    SpatialLocatorAttachedFrameOfReference m_frameOfReference{ nullptr };
 
    // Convert a duration value from a source tick frequency to a destination tick frequency.
    static inline int64_t SourceDurationTicksToDestDurationTicks(int64_t sourceDurationInTicks, int64_t sourceTicksPerSecond, int64_t destTicksPerSecond)
    {
        int64_t whole = (sourceDurationInTicks / sourceTicksPerSecond) * destTicksPerSecond;                          // 'whole' is rounded down in the target time units.
        int64_t part = (sourceDurationInTicks % sourceTicksPerSecond) * destTicksPerSecond / sourceTicksPerSecond;    // 'part' is the remainder in the target time units.
        return whole + part;
    }
 
    static inline TimeSpan TimeSpanFromQpcTicks(int64_t qpcTicks)
    {
        static const int64_t qpcFrequency = []
        {
            LARGE_INTEGER frequency;
            QueryPerformanceFrequency(&frequency);
            return frequency.QuadPart;
        }();
 
        return TimeSpan{ SourceDurationTicksToDestDurationTicks(qpcTicks, qpcFrequency, winrt::clock::period::den) / winrt::clock::period::num };
    }
};
```

### <a name="distortion-error"></a><span data-ttu-id="3c1f9-269">Errore di distorsione</span><span class="sxs-lookup"><span data-stu-id="3c1f9-269">Distortion Error</span></span>

<span data-ttu-id="3c1f9-270">In HoloLens il video e i flussi di immagini ancora non sono distorti nella pipeline di elaborazione delle immagini del sistema prima che i frame siano resi disponibili per l'applicazione (il flusso di anteprima contiene i frame distorti originali).</span><span class="sxs-lookup"><span data-stu-id="3c1f9-270">On HoloLens, the video and still image streams are undistorted in the system's image processing pipeline before the frames are made available to the application (the preview stream contains the original distorted frames).</span></span> <span data-ttu-id="3c1f9-271">Poiché vengono resi disponibili solo i CameraIntrinsics, le applicazioni devono presupporre che i fotogrammi immagine rappresentino una fotocamera pinhole perfetta.</span><span class="sxs-lookup"><span data-stu-id="3c1f9-271">Because only the CameraIntrinsics are made available, applications must assume image frames represent a perfect pinhole camera.</span></span>

<span data-ttu-id="3c1f9-272">In HoloLens (prima generazione) la funzione di disdistorsione nel processore di immagini può comunque lasciare un errore fino a 10 pixel quando si usa il CameraIntrinsics nei metadati del frame.</span><span class="sxs-lookup"><span data-stu-id="3c1f9-272">On HoloLens (first-generation), the undistortion function in the image processor may still leave an error of up to 10 pixels when using the CameraIntrinsics in the frame metadata.</span></span> <span data-ttu-id="3c1f9-273">In molti casi d'uso, questo errore non è rilevante, ma se si allineano gli ologrammi a manifesti/marcatori reali, ad esempio, si nota un <offset 10px (approssimativamente 11mm per gli ologrammi posizionati a 2 metri), questo errore di distorsione potrebbe essere la ragione.</span><span class="sxs-lookup"><span data-stu-id="3c1f9-273">In many use cases, this error will not matter, but if you are aligning holograms to real world posters/markers, for example, and you notice a <10px offset (roughly 11mm for holograms positioned 2 meters away), this distortion error could be the cause.</span></span> 

## <a name="locatable-camera-usage-scenarios"></a><span data-ttu-id="3c1f9-274">Scenari di utilizzo della fotocamera locatable</span><span class="sxs-lookup"><span data-stu-id="3c1f9-274">Locatable Camera Usage Scenarios</span></span>

### <a name="show-a-photo-or-video-in-the-world-where-it-was-captured"></a><span data-ttu-id="3c1f9-275">Mostra una foto o un video nel mondo in cui è stato acquisito</span><span class="sxs-lookup"><span data-stu-id="3c1f9-275">Show a photo or video in the world where it was captured</span></span>

<span data-ttu-id="3c1f9-276">I frame della fotocamera del dispositivo presentano una trasformazione "da fotocamera a mondo", che può essere usata per visualizzare esattamente il punto in cui si trovava il dispositivo quando l'immagine è stata acquisita.</span><span class="sxs-lookup"><span data-stu-id="3c1f9-276">The Device Camera frames come with a "Camera To World" transform, that can be used to show exactly where the device was when the image was taken.</span></span> <span data-ttu-id="3c1f9-277">Ad esempio, è possibile posizionare una piccola icona olografica in questa posizione (CameraToWorld. MultiplyPoint (Vector3. zero)) e persino creare una piccola freccia nella direzione della fotocamera (CameraToWorld. MultiplyVector (Vector3. avanti)).</span><span class="sxs-lookup"><span data-stu-id="3c1f9-277">For example, you could position a small holographic icon at this location (CameraToWorld.MultiplyPoint(Vector3.zero)) and even draw a little arrow in the direction that the camera was facing (CameraToWorld.MultiplyVector(Vector3.forward)).</span></span>

### <a name="tag--pattern--poster--object-tracking"></a><span data-ttu-id="3c1f9-278">Rilevamento di Tag/modelli/poster/oggetti</span><span class="sxs-lookup"><span data-stu-id="3c1f9-278">Tag / Pattern / Poster / Object Tracking</span></span>

<span data-ttu-id="3c1f9-279">Molte applicazioni di realtà mista usano un'immagine riconoscibile o un modello visivo per creare un punto di rilevamento nello spazio.</span><span class="sxs-lookup"><span data-stu-id="3c1f9-279">Many mixed reality applications use a recognizable image or visual pattern to create a trackable point in space.</span></span> <span data-ttu-id="3c1f9-280">Questa operazione viene quindi utilizzata per eseguire il rendering degli oggetti relativi a tale punto o creare un percorso noto.</span><span class="sxs-lookup"><span data-stu-id="3c1f9-280">This is then used to render objects relative to that point or create a known location.</span></span> <span data-ttu-id="3c1f9-281">Alcuni usi per HoloLens includono la ricerca di un oggetto reale con tag fiducials (ad esempio, un monitor TV con codice a matrice), il posizionamento di ologrammi su fiducials e l'associazione visiva di dispositivi non HoloLens come i tablet che sono stati impostati per comunicare con HoloLens tramite Wi-Fi.</span><span class="sxs-lookup"><span data-stu-id="3c1f9-281">Some uses for HoloLens include finding a real world object tagged with fiducials (e.g. a TV monitor with a QR code), placing holograms over fiducials, and visually pairing with non-HoloLens devices like tablets that have been setup to communicate with HoloLens via Wi-Fi.</span></span>

<span data-ttu-id="3c1f9-282">Per riconoscere un modello visivo e quindi inserire l'oggetto nello spazio globale delle applicazioni, è necessario eseguire alcune operazioni:</span><span class="sxs-lookup"><span data-stu-id="3c1f9-282">To recognize a visual pattern, and then place that object in the applications world space, you'll need a few things:</span></span>
1. <span data-ttu-id="3c1f9-283">Un toolkit di riconoscimento delle immagini, ad esempio codice a matrice, tag AR, ricerca viso, Tracker Circle, OCR e così via.</span><span class="sxs-lookup"><span data-stu-id="3c1f9-283">An image pattern recognition toolkit, such as QR code, AR tags, face finder, circle trackers, OCR etc.</span></span>
2. <span data-ttu-id="3c1f9-284">Raccogliere i frame dell'immagine in fase di esecuzione e passarli al livello di riconoscimento</span><span class="sxs-lookup"><span data-stu-id="3c1f9-284">Collect image frames at runtime, and pass them to the recognition layer</span></span>
3. <span data-ttu-id="3c1f9-285">Riportare i percorsi delle immagini nelle posizioni internazionali o nei possibili raggi internazionali.</span><span class="sxs-lookup"><span data-stu-id="3c1f9-285">Unproject their image locations back into world positions, or likely world rays.</span></span> 
4. <span data-ttu-id="3c1f9-286">Posizionare i modelli virtuali in queste posizioni internazionali</span><span class="sxs-lookup"><span data-stu-id="3c1f9-286">Position your virtual models over these world locations</span></span>

<span data-ttu-id="3c1f9-287">Alcuni collegamenti importanti per l'elaborazione delle immagini:</span><span class="sxs-lookup"><span data-stu-id="3c1f9-287">Some important image processing links:</span></span>
* [<span data-ttu-id="3c1f9-288">OpenCV</span><span class="sxs-lookup"><span data-stu-id="3c1f9-288">OpenCV</span></span>](https://opencv.org/)
* [<span data-ttu-id="3c1f9-289">Tag QR</span><span class="sxs-lookup"><span data-stu-id="3c1f9-289">QR Tags</span></span>](https://en.wikipedia.org/wiki/QR_code)
* [<span data-ttu-id="3c1f9-290">FaceSDK</span><span class="sxs-lookup"><span data-stu-id="3c1f9-290">FaceSDK</span></span>](https://research.microsoft.com/projects/facesdk/)
* [<span data-ttu-id="3c1f9-291">Microsoft Translator</span><span class="sxs-lookup"><span data-stu-id="3c1f9-291">Microsoft Translator</span></span>](https://www.microsoft.com/translator/business)

<span data-ttu-id="3c1f9-292">Mantenere una frequenza dei fotogrammi dell'applicazione interattiva è fondamentale, soprattutto quando si gestiscono algoritmi di riconoscimento delle immagini con esecuzione prolungata.</span><span class="sxs-lookup"><span data-stu-id="3c1f9-292">Keeping an interactive application frame-rate is critical, especially when dealing with long-running image recognition algorithms.</span></span> <span data-ttu-id="3c1f9-293">Per questo motivo, viene comunemente usato il modello seguente:</span><span class="sxs-lookup"><span data-stu-id="3c1f9-293">For this reason, we commonly use the following pattern:</span></span>
1. <span data-ttu-id="3c1f9-294">Thread principale: gestisce l'oggetto fotocamera</span><span class="sxs-lookup"><span data-stu-id="3c1f9-294">Main Thread: manages the camera object</span></span>
2. <span data-ttu-id="3c1f9-295">Thread principale: richieste nuovi frame (asincrono)</span><span class="sxs-lookup"><span data-stu-id="3c1f9-295">Main Thread: requests new frames (async)</span></span>
3. <span data-ttu-id="3c1f9-296">Thread principale: passa nuovi frame al thread di rilevamento</span><span class="sxs-lookup"><span data-stu-id="3c1f9-296">Main Thread: pass new frames to tracking thread</span></span>
4. <span data-ttu-id="3c1f9-297">Thread di rilevamento: elabora l'immagine per raccogliere punti chiave</span><span class="sxs-lookup"><span data-stu-id="3c1f9-297">Tracking Thread: processes image to collect key points</span></span>
5. <span data-ttu-id="3c1f9-298">Thread principale: sposta il modello virtuale in modo che corrisponda ai punti chiave trovati</span><span class="sxs-lookup"><span data-stu-id="3c1f9-298">Main Thread: moves virtual model to match found key points</span></span>
6. <span data-ttu-id="3c1f9-299">Thread principale: ripetere il passaggio 2</span><span class="sxs-lookup"><span data-stu-id="3c1f9-299">Main Thread: repeat from step 2</span></span>

<span data-ttu-id="3c1f9-300">Alcuni sistemi di marcatori di immagini forniscono solo una posizione in un singolo pixel (altri forniscono la trasformazione completa, nel qual caso questa sezione non sarà necessaria), che corrisponde a un raggio di posizioni possibili.</span><span class="sxs-lookup"><span data-stu-id="3c1f9-300">Some image marker systems only provide a single pixel location (others provide the full transform in which case this section will not be needed), which equates to a ray of possible locations.</span></span> <span data-ttu-id="3c1f9-301">Per accedere a una singola posizione 3D, è possibile sfruttare più raggi e trovare il risultato finale in base all'intersezione approssimativa.</span><span class="sxs-lookup"><span data-stu-id="3c1f9-301">To get to a single 3d location, we can then leverage multiple rays and find the final result by their approximate intersection.</span></span> <span data-ttu-id="3c1f9-302">A tale scopo è necessario:</span><span class="sxs-lookup"><span data-stu-id="3c1f9-302">To do this, you'll need to:</span></span>
1. <span data-ttu-id="3c1f9-303">Ottenere un ciclo per la raccolta di più immagini della fotocamera</span><span class="sxs-lookup"><span data-stu-id="3c1f9-303">Get a loop going collecting multiple camera images</span></span>
2. <span data-ttu-id="3c1f9-304">Individuare i punti di funzionalità associati e i relativi raggi internazionali</span><span class="sxs-lookup"><span data-stu-id="3c1f9-304">Find the associated feature points, and their world rays</span></span>
3. <span data-ttu-id="3c1f9-305">Quando si dispone di un dizionario di funzionalità, ognuna con più raggi internazionali, è possibile usare il codice seguente per risolvere l'intersezione dei raggi:</span><span class="sxs-lookup"><span data-stu-id="3c1f9-305">When you have a dictionary of features, each with multiple world rays, you can use the following code to solve for the intersection of those rays:</span></span>

```
public static Vector3 ClosestPointBetweenRays(
   Vector3 point1, Vector3 normalizedDirection1,
   Vector3 point2, Vector3 normalizedDirection2) {
   float directionProjection = Vector3.Dot(normalizedDirection1, normalizedDirection2);
   if (directionProjection == 1) {
     return point1; // parallel lines
   }
   float projection1 = Vector3.Dot(point2 - point1, normalizedDirection1);
   float projection2 = Vector3.Dot(point2 - point1, normalizedDirection2);
   float distanceAlongLine1 = (projection1 - directionProjection * projection2) / (1 - directionProjection * directionProjection);
   float distanceAlongLine2 = (projection2 - directionProjection * projection1) / (directionProjection * directionProjection - 1);
   Vector3 pointOnLine1 = point1 + distanceAlongLine1 * normalizedDirection1;
   Vector3 pointOnLine2 = point2 + distanceAlongLine2 * normalizedDirection2;
   return Vector3.Lerp(pointOnLine2, pointOnLine1, 0.5f);
 }
```

<span data-ttu-id="3c1f9-306">Date due o più posizioni dei tag rilevati, è possibile posizionare una scena modellata in modo da adattarsi allo scenario corrente dell'utente.</span><span class="sxs-lookup"><span data-stu-id="3c1f9-306">Given two or more tracked tag locations, you can position a modelled scene to fit the user's current scenario.</span></span> <span data-ttu-id="3c1f9-307">Se non è possibile presupporre gravità, saranno necessari tre percorsi di tag.</span><span class="sxs-lookup"><span data-stu-id="3c1f9-307">If you can't assume gravity, then you'll need three tag locations.</span></span> <span data-ttu-id="3c1f9-308">In molti casi, si usa una combinazione di colori semplice in cui le sfere bianche rappresentano posizioni dei tag rilevati in tempo reale e le sfere blu rappresentano i percorsi dei tag modellati.</span><span class="sxs-lookup"><span data-stu-id="3c1f9-308">In many cases, we use a simple color scheme where white spheres represent real-time tracked tag locations, and blue spheres represent modelled tag locations.</span></span> <span data-ttu-id="3c1f9-309">Ciò consente all'utente di misurare visivamente la qualità dell'allineamento.</span><span class="sxs-lookup"><span data-stu-id="3c1f9-309">This allows the user to visually gauge the alignment quality.</span></span> <span data-ttu-id="3c1f9-310">Si presuppone che la configurazione seguente sia in tutte le applicazioni:</span><span class="sxs-lookup"><span data-stu-id="3c1f9-310">We assume the following setup in all our applications:</span></span>
* <span data-ttu-id="3c1f9-311">Due o più percorsi di tag modellati</span><span class="sxs-lookup"><span data-stu-id="3c1f9-311">Two or more modelled tag locations</span></span>
* <span data-ttu-id="3c1f9-312">Uno "spazio di calibrazione" che nella scena è l'elemento padre dei tag</span><span class="sxs-lookup"><span data-stu-id="3c1f9-312">One 'calibration space' which in the scene is the parent of the tags</span></span>
* <span data-ttu-id="3c1f9-313">Identificatore funzionalità fotocamera</span><span class="sxs-lookup"><span data-stu-id="3c1f9-313">Camera feature identifier</span></span>
* <span data-ttu-id="3c1f9-314">Comportamento che sposta lo spazio di calibrazione per allineare i tag modellati con i tag in tempo reale (è necessario spostare lo spazio padre, non i marcatori modellati in modo autonomo, perché altre connessioni sono posizioni relative a esse).</span><span class="sxs-lookup"><span data-stu-id="3c1f9-314">Behavior which moves the calibration space to align the modelled tags with the real-time tags (we are careful to move the parent space, not the modelled markers themselves, because other connect is positions relative to them).</span></span>

```
// In the two tags case:
 Vector3 idealDelta = (realTags[1].EstimatedWorldPos - realTags[0].EstimatedWorldPos);
 Vector3 curDelta = (modelledTags[1].transform.position - modelledTags[0].transform.position);
 if (IsAssumeGravity) {
   idealDelta.y = 0;
   curDelta.y = 0;
 }
 Quaternion deltaRot = Quaternion.FromToRotation(curDelta, idealDelta);
 trans.rotation = Quaternion.LookRotation(deltaRot * trans.forward, trans.up);
 trans.position += realTags[0].EstimatedWorldPos - modelledTags[0].transform.position;
```

### <a name="track-or-identify-tagged-stationary-or-moving-real-world-objectsfaces-using-leds-or-other-recognizer-libraries"></a><span data-ttu-id="3c1f9-315">Tenere traccia o identificare gli oggetti o i visi del mondo reale con tag con i LED o altre librerie di riconoscimento</span><span class="sxs-lookup"><span data-stu-id="3c1f9-315">Track or Identify Tagged Stationary or Moving real-world objects/faces using LEDs or other recognizer libraries</span></span>

<span data-ttu-id="3c1f9-316">Esempi:</span><span class="sxs-lookup"><span data-stu-id="3c1f9-316">Examples:</span></span>
* <span data-ttu-id="3c1f9-317">Robot industriali con LED (o codici a matrice per oggetti mobili più lenti)</span><span class="sxs-lookup"><span data-stu-id="3c1f9-317">Industrial robots with LEDs (or QR codes for slower moving objects)</span></span>
* <span data-ttu-id="3c1f9-318">Identificare e riconoscere gli oggetti nella chat room</span><span class="sxs-lookup"><span data-stu-id="3c1f9-318">Identify and recognize objects in the room</span></span>
* <span data-ttu-id="3c1f9-319">Identificare e riconoscere persone nella stanza (ad esempio, inserire schede di contatto olografiche sui visi)</span><span class="sxs-lookup"><span data-stu-id="3c1f9-319">Identify and recognize people in the room (e.g. place holographic contact cards over faces)</span></span>

## <a name="see-also"></a><span data-ttu-id="3c1f9-320">Vedere anche</span><span class="sxs-lookup"><span data-stu-id="3c1f9-320">See also</span></span>
* [<span data-ttu-id="3c1f9-321">Esempio di fotocamera locatable</span><span class="sxs-lookup"><span data-stu-id="3c1f9-321">Locatable camera sample</span></span>](https://github.com/Microsoft/Windows-universal-samples/tree/master/Samples/HolographicFaceTracking)
* [<span data-ttu-id="3c1f9-322">Fotocamera individuabile in Unity</span><span class="sxs-lookup"><span data-stu-id="3c1f9-322">Locatable camera in Unity</span></span>](locatable-camera-in-unity.md)
* [<span data-ttu-id="3c1f9-323">Acquisizione realtà mista</span><span class="sxs-lookup"><span data-stu-id="3c1f9-323">Mixed reality capture</span></span>](mixed-reality-capture.md)
* [<span data-ttu-id="3c1f9-324">Acquisizione realtà mista per sviluppatori</span><span class="sxs-lookup"><span data-stu-id="3c1f9-324">Mixed reality capture for developers</span></span>](mixed-reality-capture-for-developers.md)
* [<span data-ttu-id="3c1f9-325">Introduzione a Media Capture</span><span class="sxs-lookup"><span data-stu-id="3c1f9-325">Media capture introduction</span></span>](https://msdn.microsoft.com/library/windows/apps/mt243896.aspx)
* [<span data-ttu-id="3c1f9-326">Esempio di rilevamento facciale olografico</span><span class="sxs-lookup"><span data-stu-id="3c1f9-326">Holographic face tracking sample</span></span>](https://github.com/Microsoft/Windows-universal-samples/tree/master/Samples/HolographicFaceTracking)
