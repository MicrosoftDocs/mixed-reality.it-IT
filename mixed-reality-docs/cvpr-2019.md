---
title: Applicazioni per computer Vision per workshop auricolari realtà mista a CVPR 2019
description: Panoramica e la pianificazione delle applicazioni Computer Vision per workshop auricolari realtà mista, per essere recapitati in occasione della conferenza CVPR giugno 2019.
author: fbogo
ms.author: febogo
ms.date: 1/9/2019
ms.topic: article
keywords: evento, la modalità di ricerca, cvpr, visione artificiale, ricerca, HoloLens
ms.openlocfilehash: df3d9f3efbba9657b5710b235f771a923e8ca6e5
ms.sourcegitcommit: 150d258a23130026c8792da383a3993657841fb4
ms.translationtype: MT
ms.contentlocale: it-IT
ms.lasthandoff: 06/12/2019
ms.locfileid: "67024546"
---
# <a name="computer-vision-applications-for-mixed-reality-headsets"></a><span data-ttu-id="06fde-104">Applicazioni per computer Vision per realtà mista cuffie</span><span class="sxs-lookup"><span data-stu-id="06fde-104">Computer Vision Applications for Mixed Reality Headsets</span></span>

<span data-ttu-id="06fde-105">Organizzati in combinazione con [CVPR 2019](http://cvpr2019.thecvf.com/)</span><span class="sxs-lookup"><span data-stu-id="06fde-105">Organized in conjunction with [CVPR 2019](http://cvpr2019.thecvf.com/)</span></span>

<span data-ttu-id="06fde-106">Prolungata Beach (CA)</span><span class="sxs-lookup"><span data-stu-id="06fde-106">Long Beach (CA)</span></span>

<span data-ttu-id="06fde-107">Giugno da 17, 2019 pomeriggio) - Hyatt Regency F</span><span class="sxs-lookup"><span data-stu-id="06fde-107">June 17, 2019 (Afternoon) - Hyatt Regency F</span></span>


## <a name="organizers"></a><span data-ttu-id="06fde-108">Organizzatori della</span><span class="sxs-lookup"><span data-stu-id="06fde-108">Organizers</span></span>
* <span data-ttu-id="06fde-109">Marc Pollefeys</span><span class="sxs-lookup"><span data-stu-id="06fde-109">Marc Pollefeys</span></span>
* <span data-ttu-id="06fde-110">Federica Bogo</span><span class="sxs-lookup"><span data-stu-id="06fde-110">Federica Bogo</span></span>
* <span data-ttu-id="06fde-111">Johannes Schönberger</span><span class="sxs-lookup"><span data-stu-id="06fde-111">Johannes Schönberger</span></span>
* <span data-ttu-id="06fde-112">Osman Ulusoy</span><span class="sxs-lookup"><span data-stu-id="06fde-112">Osman Ulusoy</span></span>

## <a name="overview"></a><span data-ttu-id="06fde-113">Panoramica</span><span class="sxs-lookup"><span data-stu-id="06fde-113">Overview</span></span>

![Immagini teaser](images/cvpr2019_teaser2.jpg)

<span data-ttu-id="06fde-115">Realtà mista auricolari, ad esempio il Microsoft HoloLens stanno diventando piattaforme potente per lo sviluppo di applicazioni per computer vision.</span><span class="sxs-lookup"><span data-stu-id="06fde-115">Mixed reality headsets such as the Microsoft HoloLens are becoming powerful platforms to develop computer vision applications.</span></span> <span data-ttu-id="06fde-116">La modalità HoloLens Research Abilita ricerca sulla visione artificiale nel dispositivo fornendo l'accesso a tutti i flussi di sensore immagine non elaborata, tra cui profondità e runtime di integrazione.</span><span class="sxs-lookup"><span data-stu-id="06fde-116">HoloLens Research Mode enables computer vision research on device by providing access to all raw image sensor streams -- including depth and IR.</span></span> <span data-ttu-id="06fde-117">Come modalità di ricerca è ora disponibile dal mese di maggio 2018, è iniziata visualizzare le demo e le applicazioni in fase di sviluppo per HoloLens interessanti.</span><span class="sxs-lookup"><span data-stu-id="06fde-117">As Research Mode is now available since May 2018, we are starting to see several interesting demos and applications being developed for HoloLens.</span></span> 

<span data-ttu-id="06fde-118">L'obiettivo di questo workshop è raggruppare studenti e ricercatori interessati alla visione artificiale per le applicazioni di realtà mista.</span><span class="sxs-lookup"><span data-stu-id="06fde-118">The goal of this workshop is to bring together students and researchers interested in computer vision for mixed reality applications.</span></span> <span data-ttu-id="06fde-119">Il workshop fornirà una sede di eventi per condividere le demo e le applicazioni e imparare da loro per compilare o trasportare le applicazioni di realtà mista.</span><span class="sxs-lookup"><span data-stu-id="06fde-119">The workshop will provide a venue to share demos and applications, and learn from each other to build or port applications to mixed reality.</span></span> 

<span data-ttu-id="06fde-120">Ti consigliamo di invii sugli argomenti di riconoscimento dell'oggetto (ego incentrato), manualmente e di rilevamento utente, riconoscimento delle attività, SLAM, ricostruzione 3D, comprensione scena, basati su sensori; localizzazione, navigazione e altro ancora.</span><span class="sxs-lookup"><span data-stu-id="06fde-120">We encourage submissions on the topics of (ego-centric) object recognition, hand and user tracking, activity recognition, SLAM, 3D reconstruction, scene understanding, sensor-based localization, navigation and more.</span></span>

## <a name="paper-submission"></a><span data-ttu-id="06fde-121">Invio di documento</span><span class="sxs-lookup"><span data-stu-id="06fde-121">Paper Submission</span></span>
* <span data-ttu-id="06fde-122">Carta data di scadenza: 17 maggio</span><span class="sxs-lookup"><span data-stu-id="06fde-122">Paper submission deadline: May 17</span></span>
* <span data-ttu-id="06fde-123">Notifica agli autori: 24 maggio</span><span class="sxs-lookup"><span data-stu-id="06fde-123">Notification to authors: May 24</span></span>

<span data-ttu-id="06fde-124">Gli invii di documento devono usare il modello CVPR e sono limitati ai 4 pagine oltre a riferimenti.</span><span class="sxs-lookup"><span data-stu-id="06fde-124">Paper submissions should use the CVPR template and are limited to 4 pages plus references.</span></span> <span data-ttu-id="06fde-125">Inoltre, invitiamo gli autori per inviare un video che presenta la propria applicazione.</span><span class="sxs-lookup"><span data-stu-id="06fde-125">In addition, we encourage the authors to submit a video showcasing their application.</span></span>
<span data-ttu-id="06fde-126">Si noti che gli invii di lavoro pubblicata in precedenza sono consentiti (inclusi lavoro accettato per la conferenza CVPR 2019 principale).</span><span class="sxs-lookup"><span data-stu-id="06fde-126">Note that submissions of previously published work are allowed (including work accepted to the main CVPR 2019 conference).</span></span> 

<span data-ttu-id="06fde-127">Gli invii possono essere caricati in CMT: https://cmt3.research.microsoft.com/CVFORMR2019</span><span class="sxs-lookup"><span data-stu-id="06fde-127">Submissions can be uploaded to the CMT: https://cmt3.research.microsoft.com/CVFORMR2019</span></span>

<span data-ttu-id="06fde-128">Presentazione orali presso il workshop verrà selezionato un subset di documenti.</span><span class="sxs-lookup"><span data-stu-id="06fde-128">A subset of papers will be selected for oral presentation at the workshop.</span></span> <span data-ttu-id="06fde-129">Tuttavia, ti invitiamo tutti gli autori per presentare il proprio lavoro durante la sessione di demo.</span><span class="sxs-lookup"><span data-stu-id="06fde-129">However, we strongly encourage all the authors to present their work during the demo session.</span></span>


## <a name="schedule"></a><span data-ttu-id="06fde-130">Pianificazione</span><span class="sxs-lookup"><span data-stu-id="06fde-130">Schedule</span></span>
* <span data-ttu-id="06fde-131">13:30-13:45: Sezione Osservazioni di benvenuto e di apertura.</span><span class="sxs-lookup"><span data-stu-id="06fde-131">13:30-13:45: Welcome and Opening Remarks.</span></span>
* <span data-ttu-id="06fde-132">13:45-14:15: **Intervento su talk**: Prof Marc Pollefeys, ETH Zurigo/Microsoft.</span><span class="sxs-lookup"><span data-stu-id="06fde-132">13:45-14:15: **Keynote talk**: Prof. Marc Pollefeys, ETH Zurich/Microsoft.</span></span> <span data-ttu-id="06fde-133">titolo: Visione artificiale egocentric su HoloLens.</span><span class="sxs-lookup"><span data-stu-id="06fde-133">Title: Egocentric Computer Vision on HoloLens.</span></span>
* <span data-ttu-id="06fde-134">14:15-14:45: **Intervento su talk**: Prof. Kris Kitani, Carnegie Mellon University.</span><span class="sxs-lookup"><span data-stu-id="06fde-134">14:15-14:45: **Keynote talk**: Prof. Kris Kitani, Carnegie Mellon University.</span></span> <span data-ttu-id="06fde-135">titolo: Attività egocentric e posa previsione.</span><span class="sxs-lookup"><span data-stu-id="06fde-135">Title: Egocentric Activity and Pose Forecasting.</span></span>
* <span data-ttu-id="06fde-136">14:45-15:15: **Intervento su talk**: Dr. Yang Liu, California Institute of Technology.</span><span class="sxs-lookup"><span data-stu-id="06fde-136">14:45-15:15: **Keynote talk**: Dr. Yang Liu, California Institute of Technology.</span></span> <span data-ttu-id="06fde-137">titolo: Potenziamento di un Assistente di Cognitive for the Blind con realtà aumentata.</span><span class="sxs-lookup"><span data-stu-id="06fde-137">Title: Powering a Cognitive Assistant for the Blind with Augmented Reality.</span></span>
* <span data-ttu-id="06fde-138">15:15-16:15: Caffè e demo.</span><span class="sxs-lookup"><span data-stu-id="06fde-138">15:15-16:15: Coffee break and demos.</span></span>
* <span data-ttu-id="06fde-139">16:15-16:45: **Intervento su talk**: Prof Kristen Grauman, università del Texas a ricerca di intelligenza artificiale Austin/Facebook.</span><span class="sxs-lookup"><span data-stu-id="06fde-139">16:15-16:45: **Keynote talk**: Prof. Kristen Grauman, University of Texas at Austin/Facebook AI Research.</span></span> <span data-ttu-id="06fde-140">titolo: TBD.</span><span class="sxs-lookup"><span data-stu-id="06fde-140">Title: TBD.</span></span>
* <span data-ttu-id="06fde-141">16:45-17:15: Orali.</span><span class="sxs-lookup"><span data-stu-id="06fde-141">16:45-17:15: Oral presentations.</span></span>
* <span data-ttu-id="06fde-142">17:15-17:30: Sezione Osservazioni finale.</span><span class="sxs-lookup"><span data-stu-id="06fde-142">17:15-17:30: Final Remarks.</span></span>
