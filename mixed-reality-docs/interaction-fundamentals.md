---
title: Panoramica di interazione multimodale
description: Panoramica dell'interazione multimodale
author: shengkait
ms.author: shengkait
ms.date: 04/11/2019
ms.topic: article
ms.localizationpriority: high
keywords: Mista realtà, sguardo, sguardo targeting, interazione, progettare, hololens, MMR, multimodali
ms.openlocfilehash: 9d0e639d7474c7e8728282acfa8d288cfeec7043
ms.sourcegitcommit: c20563b8195c0c374a927b96708d958b127ffc8f
ms.translationtype: MT
ms.contentlocale: it-IT
ms.lasthandoff: 05/21/2019
ms.locfileid: "65974910"
---
# <a name="introducing-instinctual-interactions"></a><span data-ttu-id="a5258-104">Introduzione a instinctual interazioni</span><span class="sxs-lookup"><span data-stu-id="a5258-104">Introducing instinctual interactions</span></span>

<span data-ttu-id="a5258-105">La filosofia di interazioni semplice, instinctual sperimentare tutta la piattaforma di realtà mista Microsoft (MMR), dal software di hardware.</span><span class="sxs-lookup"><span data-stu-id="a5258-105">The philosophy of simple, instinctual interactions is woven throughout the Microsoft Mixed Reality (MMR) platform, from hardware to software.</span></span>

<span data-ttu-id="a5258-106">Tali interazioni instinctual usano tutte le tecnologie di input disponibili, tra cui rilevamento interno a esterno, mano di rilevamento, sotto controllo di rilevamento e il linguaggio naturale, nei modelli di interazione multimodale invisibile.</span><span class="sxs-lookup"><span data-stu-id="a5258-106">These instinctual interactions utilize all available input technologies, including inside-out tracking, hand tracking, eye tracking, and natural language, in seamless multimodal interaction models.</span></span> <span data-ttu-id="a5258-107">Basato su ricerca, progettazione e sviluppo multimodals e non si basa sui singoli input, è fondamentale durante la creazione di esperienze instinctive.</span><span class="sxs-lookup"><span data-stu-id="a5258-107">Based on our research, designing and developing multimodals, and not based on single inputs, is critical when creating instinctive experiences.</span></span>

<span data-ttu-id="a5258-108">I modelli di interazione Instinctual Allinea inoltre naturalmente a tipi di dispositivo.</span><span class="sxs-lookup"><span data-stu-id="a5258-108">The Instinctual Interaction models also naturally align across device types.</span></span>  <span data-ttu-id="a5258-109">Distante interazione in un visore VR immersivi con un 6 gradi di controller di libertà e interazione distante su 2 HoloLens, ad esempio, usare la stessa affordance, modelli e i comportamenti.</span><span class="sxs-lookup"><span data-stu-id="a5258-109">For example, far interaction on an immersive headset with a 6 degrees of freedom (DoF) controller and far interaction on a HoloLens 2 use the same affordances, patterns, and behaviors.</span></span>  <span data-ttu-id="a5258-110">È non solo questo utile per gli sviluppatori e progettisti, ma è scontata agli utenti finali.</span><span class="sxs-lookup"><span data-stu-id="a5258-110">Not only is this convenient for developers and designers, but it feels natural to end users.</span></span>


<span data-ttu-id="a5258-111">Infine, anche se è possibile riconoscere che sono presenti migliaia di validità, coinvolgenti e interazioni magiche presenti possibili in MR, si è constatato che utilizza intenzionalmente un modello di sola interazione end-to-end in un'applicazione è il modo migliore per assicurarsi che gli utenti hanno esito positivo e avere un'esperienza ottimale.</span><span class="sxs-lookup"><span data-stu-id="a5258-111">Lastly, while we recognize that there are thousands of effective, engaging, and magical interactions possible in MR, we have found that intentionally employing a single interaction model end to end in an application is the best way to ensure users are successful and have a great experience.</span></span>  <span data-ttu-id="a5258-112">A tale scopo, sono state incluse tre operazioni in questo materiale sussidiario interazione:</span><span class="sxs-lookup"><span data-stu-id="a5258-112">To that end, we've included three things in this interaction guidance:</span></span>
* <span data-ttu-id="a5258-113">È stata strutturata questo materiale sussidiario i tre modelli di interazione principale e i componenti e i modelli necessari per ogni</span><span class="sxs-lookup"><span data-stu-id="a5258-113">We've structured this guidance around the three primary interaction models and the components and patterns required for each</span></span>
* <span data-ttu-id="a5258-114">Sono state incluse istruzioni aggiuntive su altri vantaggi che la nostra piattaforma di fornisce</span><span class="sxs-lookup"><span data-stu-id="a5258-114">We've included supplemental guidance on other benefits that our platform provides</span></span>
* <span data-ttu-id="a5258-115">Sono incluse indicazioni per consentire di selezionare il modello di interazione appropriato per lo scenario</span><span class="sxs-lookup"><span data-stu-id="a5258-115">We've included guidance to help select the appropriate interaction model for your scenario</span></span>

## <a name="multimodal-interaction-models"></a><span data-ttu-id="a5258-116">Modelli di interazione multimodale</span><span class="sxs-lookup"><span data-stu-id="a5258-116">Multimodal interaction models</span></span>

<span data-ttu-id="a5258-117">A seconda della ricerca e il lavoro con i clienti a oggi, abbiamo scoperto tre modelli di interazione principale che soddisfare la maggior parte delle esperienze di realtà mista.</span><span class="sxs-lookup"><span data-stu-id="a5258-117">Based on our research and work with customers to date, we've discovered three primary interaction models that suit the majority of Mixed Reality experiences.</span></span>  

<span data-ttu-id="a5258-118">Questi modelli di interazione può essere paragonato a modello mentale dell'utente per il completamento dei flussi.</span><span class="sxs-lookup"><span data-stu-id="a5258-118">Think of these interaction models as the user's mental model for completing their flows.</span></span>

<span data-ttu-id="a5258-119">Ognuno di questi modelli di interazione è conveniente, efficiente ed utilizzabile in sé e tutte sono ottimizzate per una serie di esigenze dei clienti.</span><span class="sxs-lookup"><span data-stu-id="a5258-119">Each of these interaction models is convenient, powerful, and usable in its own right, and all are optimized for a set of customer needs.</span></span> <span data-ttu-id="a5258-120">Visualizzare il grafico seguente, per gli scenari, esempi e i vantaggi di ogni modello di interazione.</span><span class="sxs-lookup"><span data-stu-id="a5258-120">View the chart below, for scenarios, examples, and benefits of each interaction model.</span></span>  

<span data-ttu-id="a5258-121">**Modello**</span><span class="sxs-lookup"><span data-stu-id="a5258-121">**Model**</span></span> | <span data-ttu-id="a5258-122">**[Strumenti e le mani](https://docs.microsoft.com/en-us/windows/mixed-reality/hands-and-tools)**</span><span class="sxs-lookup"><span data-stu-id="a5258-122">**[Hands and Tools](https://docs.microsoft.com/en-us/windows/mixed-reality/hands-and-tools)**</span></span> | <span data-ttu-id="a5258-123">**[Mani libere](https://docs.microsoft.com/en-us/windows/mixed-reality/hands-free)**</span><span class="sxs-lookup"><span data-stu-id="a5258-123">**[Hands free](https://docs.microsoft.com/en-us/windows/mixed-reality/hands-free)**</span></span> | <span data-ttu-id="a5258-124">**[Estasiati ed eseguire il Commit](https://docs.microsoft.com/en-us/windows/mixed-reality/gaze-and-commit?)**</span><span class="sxs-lookup"><span data-stu-id="a5258-124">**[Gaze and Commit](https://docs.microsoft.com/en-us/windows/mixed-reality/gaze-and-commit?)**</span></span>
|--------- | --------------| ------------| ---------|
<span data-ttu-id="a5258-125">**Scenari di esempio**</span><span class="sxs-lookup"><span data-stu-id="a5258-125">**Example Scenarios**</span></span> | <span data-ttu-id="a5258-126">Del contenuto 3D esperienze spaziali, ad esempio spatial layout e progettazione, modifica o simulazione</span><span class="sxs-lookup"><span data-stu-id="a5258-126">3D spatial experiences, e.g. spatial layout and design, content manipulation, or simulation</span></span> | <span data-ttu-id="a5258-127">Esperienze contestuale in cui sono occupate mani dell'utente, ad esempio, nella formazione, la manutenzione del processo</span><span class="sxs-lookup"><span data-stu-id="a5258-127">Contextual experiences where a user's hands are occupied, e.g. on the-job learning, maintenance</span></span>| <span data-ttu-id="a5258-128">Esperienze drill-through interno, ad esempio 3D presentazioni e demo</span><span class="sxs-lookup"><span data-stu-id="a5258-128">Click-through experiences, e.g. 3D presentations, demos</span></span>
<span data-ttu-id="a5258-129">**Fit**</span><span class="sxs-lookup"><span data-stu-id="a5258-129">**Fit**</span></span> | <span data-ttu-id="a5258-130">Un'ottima soluzione per i nuovi utenti, wit accoppiata vocali, dell'occhio sguardo rilevamento o head.</span><span class="sxs-lookup"><span data-stu-id="a5258-130">Great for new users, coupled wit voice, eye tracking or head gaze.</span></span> <span data-ttu-id="a5258-131">Curva di apprendimento.</span><span class="sxs-lookup"><span data-stu-id="a5258-131">Low learning curve.</span></span> <span data-ttu-id="a5258-132">Esperienza utente coerente tra mano di rilevamento e 6 controller i gradi di libertà.</span><span class="sxs-lookup"><span data-stu-id="a5258-132">Consistent UX across hand tracking and 6 DoF controllers.</span></span> | <span data-ttu-id="a5258-133">Alcuni di apprendimento obbligatorio.</span><span class="sxs-lookup"><span data-stu-id="a5258-133">Some learning required.</span></span> <span data-ttu-id="a5258-134">Se sono coppie non disponibile anche con vocali e il linguaggio naturale</span><span class="sxs-lookup"><span data-stu-id="a5258-134">If hands are unavailable pairs well with voice and natural language</span></span> | <span data-ttu-id="a5258-135">Richiede la formazione su HMDs ma non su dispositivi mobili.</span><span class="sxs-lookup"><span data-stu-id="a5258-135">Requires training on HMDs but not on mobile.</span></span> <span data-ttu-id="a5258-136">Ideale per i controller accessibili migliore per HoloLens (dal 1 ° generazione)</span><span class="sxs-lookup"><span data-stu-id="a5258-136">Best for accessible controllers Best for HoloLens (1st gen)</span></span> |
<span data-ttu-id="a5258-137">**Hardware**</span><span class="sxs-lookup"><span data-stu-id="a5258-137">**Hardware**</span></span> | <span data-ttu-id="a5258-138">HoloLens 2 Immersive auricolari</span><span class="sxs-lookup"><span data-stu-id="a5258-138">HoloLens 2 Immersive headsets</span></span> | <span data-ttu-id="a5258-139">HoloLens 2 HoloLens (dal 1 ° generazione) auricolari coinvolgenti</span><span class="sxs-lookup"><span data-stu-id="a5258-139">HoloLens 2 HoloLens (1st gen) Immersive headsets</span></span> | <span data-ttu-id="a5258-140">HoloLens 2 Immersive auricolari</span><span class="sxs-lookup"><span data-stu-id="a5258-140">HoloLens 2 Immersive headsets</span></span> | <span data-ttu-id="a5258-141">HoloLens 2 HoloLens (dal 1 ° generazione) coinvolgenti auricolari AR per dispositivi mobili</span><span class="sxs-lookup"><span data-stu-id="a5258-141">HoloLens 2 HoloLens (1st gen) Immersive headsets Mobile AR</span></span> |

<span data-ttu-id="a5258-142">Informazioni dettagliate per l'uso in perfetta sintonia, tutti gli input disponibili in ogni modello di interazione sono nelle pagine che seguono, nonché le illustrazioni e collegamenti a contenuto di esempio dal nostro MRTK di Unity.</span><span class="sxs-lookup"><span data-stu-id="a5258-142">Detailed information for using all available inputs seamlessly together in each interaction model is on the pages that follow, as well as illustrations and links to sample content from our Unity MRTK.</span></span>


## <a name="choose-an-interaction-model-for-your-customer"></a><span data-ttu-id="a5258-143">Scegliere un modello di interazione per il cliente</span><span class="sxs-lookup"><span data-stu-id="a5258-143">Choose an interaction model for your customer</span></span>


<span data-ttu-id="a5258-144">È probabile che gli sviluppatori e autori anche già alcune idee mente i tipi di esperienza di interazione che desiderano agli utenti di avere.</span><span class="sxs-lookup"><span data-stu-id="a5258-144">Most likely, developers and creators also already have some ideas in mind of the kinds of interaction experience they want their users to have.</span></span>
<span data-ttu-id="a5258-145">Per favorire un approccio incentrato sul cliente alla progettazione, è consigliabile seguendo le indicazioni seguenti per selezionare il modello di interazione che è ottimizzato per il cliente.</span><span class="sxs-lookup"><span data-stu-id="a5258-145">To encourage a customer-focused approach to design, we recommend following the guidance below to select the interaction model that's optimized for your customer.</span></span>

### <a name="why-follow-this-guidance"></a><span data-ttu-id="a5258-146">Il motivo per cui segue questo materiale sussidiario?</span><span class="sxs-lookup"><span data-stu-id="a5258-146">Why follow this guidance?</span></span>

* <span data-ttu-id="a5258-147">I modelli di interazione vengono verificati i criteri soggettivi, ad esempio fisica e cognitiva sforzo e intuitiveness learnability e obiettivo.</span><span class="sxs-lookup"><span data-stu-id="a5258-147">Our interaction models are tested for objective and subjective criteria such as physical and cognitive effort, intuitiveness, and learnability.</span></span> 
* <span data-ttu-id="a5258-148">Interazione è diverso, audio e video affordance e comportamento di tali oggetti possono anche differire tra i modelli di interazione.</span><span class="sxs-lookup"><span data-stu-id="a5258-148">Because interaction differs, visual and audio affordances and object behavior may also differ between the interaction models.</span></span>  
* <span data-ttu-id="a5258-149">Combinando le parti più modelli di interazione crea il rischio di affordance concorrenti, ad esempio rays mano simultanei e un cursore, head sguardo che sovraccaricare e confondere gli utenti.</span><span class="sxs-lookup"><span data-stu-id="a5258-149">Combining parts of multiple interaction models together creates the risk of competing affordances, such as simultaneous hand rays and a head-gaze cursor, which overwhelm and confuse users.</span></span>

<span data-ttu-id="a5258-150">Di seguito sono riportati alcuni esempi del modo in cui affordance e i comportamenti sono ottimizzati per ogni modello di interazione.</span><span class="sxs-lookup"><span data-stu-id="a5258-150">Here are some examples of how affordances and behaviors are optimized for each interaction model.</span></span>  <span data-ttu-id="a5258-151">È possibile notare spesso nuovi utenti come domande simili, ad esempio "come faccio a sapere il sistema funziona, come faccio a sapere che cosa può fare, e come si capisce se comprendere ciò che ho appena fatto?"</span><span class="sxs-lookup"><span data-stu-id="a5258-151">We often see new users as similar questions, such as "how do I know the system is working, how do I know what I can do, and how do I know if it understood what I just did?"</span></span>

<br>

<table>
    <colgroup>
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    </colgroup>
    <tr>
        <td><span data-ttu-id="a5258-152"><strong>Modello</strong></span><span class="sxs-lookup"><span data-stu-id="a5258-152"><strong>Model</strong></span></span></td>
        <td><span data-ttu-id="a5258-153"><strong>Come si capisce funziona?</strong></span><span class="sxs-lookup"><span data-stu-id="a5258-153"><strong>How do I know it's working?</strong></span></span></td>
        <td><span data-ttu-id="a5258-154"><strong>Come sapere cosa posso fare?</strong></span><span class="sxs-lookup"><span data-stu-id="a5258-154"><strong>How do I know what I can do?</strong></span></span></td>
        <td><span data-ttu-id="a5258-155"><strong>Come sapere ciò che ho appena fatto?</strong></span><span class="sxs-lookup"><span data-stu-id="a5258-155"><strong>How do I know what I just did?</strong></span></span></td>
    </tr>
    <tr>
        <td><span data-ttu-id="a5258-156"><a href="hands-and-tools.md">Strumenti e le mani</a></span><span class="sxs-lookup"><span data-stu-id="a5258-156"><a href="hands-and-tools.md">Hands and tools</a></span></span></td>
        <td><span data-ttu-id="a5258-157">Una mano mesh, vedere un intuitività punta del dito o manualmente / rays controller.</span><span class="sxs-lookup"><span data-stu-id="a5258-157">I see a hand mesh, I see a fingertip affordance or hand/ controller rays.</span></span></td>
        <td><span data-ttu-id="a5258-158">Viene visualizzato un riquadro vengono visualizzate quando la mano si avvicina o handle grabbable.</span><span class="sxs-lookup"><span data-stu-id="a5258-158">I see grabbable handles or a bounding box appear when my hand is near.</span></span></td>
        <td><span data-ttu-id="a5258-159">Posso sentire sonori e visualizzare animazioni in quadratini di ridimensionamento e il rilascio.</span><span class="sxs-lookup"><span data-stu-id="a5258-159">I hear audible tones and see animations on grab and release.</span></span></td>
    </tr>
    <tr>
        <td><span data-ttu-id="a5258-160"><a href="gaze-and-commit.md">Puntamento con la testa e commit</a></span><span class="sxs-lookup"><span data-stu-id="a5258-160"><a href="gaze-and-commit.md">Head-gaze and commit</a></span></span></td>
        <td><span data-ttu-id="a5258-161">Viene visualizzato un cursore al centro del mio campo visivo.</span><span class="sxs-lookup"><span data-stu-id="a5258-161">I see a cursor in the center of my field of view.</span></span></td>
        <td><span data-ttu-id="a5258-162">Il cursore head sguardo Cambia stato quando su determinati oggetti.</span><span class="sxs-lookup"><span data-stu-id="a5258-162">The head-gaze cursor changes state when over certain objects.</span></span></td>
        <td><span data-ttu-id="a5258-163">Posso vedere o ascolta le conferme e acustico quando intervenire.</span><span class="sxs-lookup"><span data-stu-id="a5258-163">I see/ hear visual and audible confirmations when I take action.</span></span></td>
    </tr>   
    <tr>
        <td><span data-ttu-id="a5258-164"><a href="hands-free.md">Mani libere (Head-sguardo e permanenza)</a></span><span class="sxs-lookup"><span data-stu-id="a5258-164"><a href="hands-free.md">Hands-free (Head-gaze and dwell)</a></span></span></td>
        <td><span data-ttu-id="a5258-165">Viene visualizzato un cursore al centro del mio campo visivo.</span><span class="sxs-lookup"><span data-stu-id="a5258-165">I see a cursor in the center of my field of view.</span></span></td>
        <td><span data-ttu-id="a5258-166">Viene visualizzato un indicatore di stato quando il caso di soffermarsi su un oggetto si.</span><span class="sxs-lookup"><span data-stu-id="a5258-166">I see a progress indicator when I dwell on an interactable object.</span></span></td>
        <td><span data-ttu-id="a5258-167">Posso vedere o ascolta le conferme e acustico quando intervenire.</span><span class="sxs-lookup"><span data-stu-id="a5258-167">I see/ hear visual and audible confirmations when I take action.</span></span></td>
    </tr>
    <tr>
        <td><span data-ttu-id="a5258-168"><a href="hands-free.md">Mani libere (esecuzione di comandi vocali)</a></span><span class="sxs-lookup"><span data-stu-id="a5258-168"><a href="hands-free.md">Hands-free (Voice commanding)</a></span></span></td>
        <td><span data-ttu-id="a5258-169">Viene visualizzato un indicatore di attesa e sottotitoli in lingua originale che mostra ciò che il sistema sentito parlare.</span><span class="sxs-lookup"><span data-stu-id="a5258-169">I see a listening indicator and captions that show what the system heard.</span></span></td>
        <td><span data-ttu-id="a5258-170">Ricevo messaggi vocali e suggerimenti.</span><span class="sxs-lookup"><span data-stu-id="a5258-170">I get voice prompts and hints.</span></span>  <span data-ttu-id="a5258-171">Quando dico "frasi?"</span><span class="sxs-lookup"><span data-stu-id="a5258-171">When I say "what can I say?"</span></span> <span data-ttu-id="a5258-172">Vedere commenti e suggerimenti.</span><span class="sxs-lookup"><span data-stu-id="a5258-172">I see feedback.</span></span></td>
        <td><span data-ttu-id="a5258-173">Posso vedere o ascolta le conferme e acustico quando dà un comando o ottenere disambiguazione UX quando necessario.</span><span class="sxs-lookup"><span data-stu-id="a5258-173">I see/ hear visual and audible confirmations when I give a command, or get disambiguation UX when needed.</span></span></a></td>
    </tr>
</table>

### <a name="below-are-the-questions-that-weve-found-help-teams-select-an-interaction-model"></a><span data-ttu-id="a5258-174">Di seguito sono le domande che abbiamo scoperto help teams selezionare un modello di interazione:</span><span class="sxs-lookup"><span data-stu-id="a5258-174">Below are the questions that we've found help teams select an interaction model:</span></span>
 
1.  <span data-ttu-id="a5258-175">D:  Gli utenti desiderano touch ologrammi ed eseguono manipolazioni holographic precisione?</span><span class="sxs-lookup"><span data-stu-id="a5258-175">Q:  Do my users want to touch holograms and perform precision holographic manipulations?</span></span><br><br>
<span data-ttu-id="a5258-176">R:  In questo caso, consultare il modello di interazione mani e strumenti per la selezione della precisione e manipolazione con controller di movimento o mani.</span><span class="sxs-lookup"><span data-stu-id="a5258-176">A:  If so, check out the Hands and tools interaction model for precision targeting and manipulation with hands or motion controllers.</span></span>
 
2.  <span data-ttu-id="a5258-177">D:  Gli utenti devono mantenere le mani gratuite, per le attività del mondo reale?</span><span class="sxs-lookup"><span data-stu-id="a5258-177">Q:  Do my users need to keep their hands free, for real-world tasks?</span></span><br><br>
<span data-ttu-id="a5258-178">R:  In questo caso, esaminare il modello di interazione invisibile all'utente, che offre un'esperienza ottimale invisibile all'utente tramite le interazioni basate su sguardo e vocali.</span><span class="sxs-lookup"><span data-stu-id="a5258-178">A:  If so, take a look at the Hands-free interaction model, which provides a great hands-free experience through gaze- and voice-based interactions.</span></span>
 
3.  <span data-ttu-id="a5258-179">D:  Gli utenti devono imparare a utilizzare le interazioni per la mia applicazione di realtà mista, o devono le interazioni con la curva di apprendimento più bassa possibile?</span><span class="sxs-lookup"><span data-stu-id="a5258-179">Q:  Do my users have time to learn interactions for my mixed reality application, or do they need the interactions with the lowest learning curve possible?</span></span><br><br>
<span data-ttu-id="a5258-180">R:  È consigliabile il modello mani e strumenti per la curva di apprendimento più bassa e le interazioni più intuitive, purché siano in grado di usare le mani per l'interazione con gli utenti.</span><span class="sxs-lookup"><span data-stu-id="a5258-180">A:  We recommend the Hands and Tools model for the lowest learning curve and most intuitive interactions, as long as users are able to use their hands for interaction.</span></span>
 
4.  <span data-ttu-id="a5258-181">D:  Gli utenti usano i controller di movimento per la modifica e che puntano?</span><span class="sxs-lookup"><span data-stu-id="a5258-181">Q:  Do my users use motion controllers for pointing and manipulation?</span></span><br><br>
<span data-ttu-id="a5258-182">R:  Il modello di strumenti e le mani include tutte le linee guida per un'esperienza ottimale con i controller di movimento.</span><span class="sxs-lookup"><span data-stu-id="a5258-182">A:  The Hands and tools model includes all guidance for a great experience with motion controllers.</span></span>
 
5.  <span data-ttu-id="a5258-183">D:  Gli utenti usano un controller di accessibilità o un controller Bluetooth comuni, ad esempio un clicker?</span><span class="sxs-lookup"><span data-stu-id="a5258-183">Q:  Do my users use an accessibility controller or a common Bluetooth controller, such as a clicker?</span></span><br><br>
<span data-ttu-id="a5258-184">R:  Si consiglia il modello Head sguardo ed eseguire il Commit per tutti i controller non rilevate.</span><span class="sxs-lookup"><span data-stu-id="a5258-184">A:  We recommend the Head-gaze and Commit model for all non-tracked controllers.</span></span>  <span data-ttu-id="a5258-185">È progettato per consentire a un utente attraversare un'intera esperienza con un semplice meccanico "target e commit".</span><span class="sxs-lookup"><span data-stu-id="a5258-185">It's designed to allow a user to traverse an entire experience with a simple "target and commit" mechanic.</span></span> 
 
6.  <span data-ttu-id="a5258-186">D: Gli utenti solo l'avanzamento viene eseguito tramite un'esperienza facendo clic su"tramite" (ad esempio in un ambiente simile a presentazione 3d), anziché passare ad alta densità layout dei controlli dell'interfaccia utente?</span><span class="sxs-lookup"><span data-stu-id="a5258-186">Q: Do my users only progress through an experience by "clicking through" (for example in a 3d slideshow-like environment), as opposed to navigating dense layouts of UI controls?</span></span><br><br>
<span data-ttu-id="a5258-187">R:  Se gli utenti non sono necessario controllare molti dell'interfaccia utente, Head sguardo ed eseguire il commit offrono un'opzione learnable in cui gli utenti non sono necessario preoccuparsi di destinazione.</span><span class="sxs-lookup"><span data-stu-id="a5258-187">A:  If users do not need to control a lot of UI, Head-gaze and commit offers a learnable option where users do not have to worry about targeting.</span></span> 
 
7.  <span data-ttu-id="a5258-188">D:  Gli utenti usano entrambi HoloLens (dal 1 ° generazione) e HoloLens 2 / coinvolgenti di Windows (auricolari VR)</span><span class="sxs-lookup"><span data-stu-id="a5258-188">Q:  Do my users use both HoloLens (1st gen) and HoloLens 2/ Windows Immersive (VR headsets)</span></span><br><br>
<span data-ttu-id="a5258-189">R:  Poiché Head sguardo ed eseguire il commit è il modello di interazione per HoloLens (dal 1 ° generazione), è consigliabile che gli autori che supportano HoloLens (dal 1 ° generazione) usare Head sguardo ed eseguire il commit per qualsiasi funzionalità o le modalità che gli utenti potrebbero riscontrare in un HoloLens (dal 1 ° generazione) visore Vr.</span><span class="sxs-lookup"><span data-stu-id="a5258-189">A:  Since Head-gaze and commit is the interaction model for HoloLens (1st gen), we recommend that creators who support HoloLens (1st gen) use Head-gaze and commit for any features or modes that users may experience on a HoloLens (1st gen) headset.</span></span>  <span data-ttu-id="a5258-190">Vedere la sezione seguente nel *modelli di interazione in fase di transizione* per informazioni dettagliate su come rendere una straordinaria esperienza più generazioni di HoloLens.</span><span class="sxs-lookup"><span data-stu-id="a5258-190">Please see the next section below on *Transitioning interaction models* for details on making a great experience for multiple HoloLens generations.</span></span>
 
8.  <span data-ttu-id="a5258-191">D: Per quanto riguarda per gli utenti che sono in genere per dispositivi mobili relativi a uno spazio di grandi dimensioni o lo spostamento tra gli spazi, e gli utenti tendono a funzionare in uno spazio singolo?</span><span class="sxs-lookup"><span data-stu-id="a5258-191">Q: What about for users who are generally mobile (covering a large space or moving between spaces), versus users who tend to work in a single space?</span></span><br><br>
<span data-ttu-id="a5258-192">R:  Uno dei modelli di interazione funzionerà per questi utenti.</span><span class="sxs-lookup"><span data-stu-id="a5258-192">A:  Any of the interaction models will work for these users.</span></span>  

> [!NOTE]
> <span data-ttu-id="a5258-193">Informazioni aggiuntive specifiche per la progettazione di app [presto](index.md#news-and-notes).</span><span class="sxs-lookup"><span data-stu-id="a5258-193">More guidance specific to app design [coming soon](index.md#news-and-notes).</span></span>


## <a name="transition-interaction-models"></a><span data-ttu-id="a5258-194">Modelli di interazione di transizione</span><span class="sxs-lookup"><span data-stu-id="a5258-194">Transition interaction models</span></span>
<span data-ttu-id="a5258-195">Vi sono anche casi in cui i casi d'uso richieda che utilizzano più di un modello di interazione.</span><span class="sxs-lookup"><span data-stu-id="a5258-195">There are also cases where your use cases may require that utilizing more than one interaction model.</span></span>  <span data-ttu-id="a5258-196">Ad esempio, il flusso di app"creazione" utilizza il modello di interazione mani e gli strumenti, ma si desidera utilizzare una modalità invisibile all'utente per i tecnici del campo.</span><span class="sxs-lookup"><span data-stu-id="a5258-196">For example, your app's "creation flow" utilizes the Hands and tools interaction model, but you want to employ a Hands-free mode for field technicians.</span></span>  

<span data-ttu-id="a5258-197">Se più modelli di interazione richiede l'esperienza, abbiamo scoperto che molti utenti finali potrebbero riscontrare difficoltà in fase di transizione da un modello a un'altra, in particolare gli utenti finali che hanno familiarità con MR.</span><span class="sxs-lookup"><span data-stu-id="a5258-197">If your experience does require multiple interaction models, we've found that many end users may encounter difficulty transitioning from one model to another -- especially end users who are new to MR.</span></span>

> [!Note]
> <span data-ttu-id="a5258-198">Per consentire le finestre di progettazione di Guida e gli sviluppatori attraverso le scelte che possono essere difficile in MR, stiamo lavorando su altre indicazioni per l'uso di più modelli di interazione.</span><span class="sxs-lookup"><span data-stu-id="a5258-198">To help guide designers and developers through choices that can be difficult in MR, we're working on more guidance for using multiple interaction models.</span></span>
 

## <a name="see-also"></a><span data-ttu-id="a5258-199">Vedere anche</span><span class="sxs-lookup"><span data-stu-id="a5258-199">See also</span></span>
* [<span data-ttu-id="a5258-200">Puntamento con la testa e commit</span><span class="sxs-lookup"><span data-stu-id="a5258-200">Head-gaze and commit</span></span>](gaze-and-commit.md)
* [<span data-ttu-id="a5258-201">Puntamento con la testa e attesa</span><span class="sxs-lookup"><span data-stu-id="a5258-201">Head-gaze and dwell</span></span>](gaze-and-dwell.md)
* [<span data-ttu-id="a5258-202">Manipolazione diretta con le mani</span><span class="sxs-lookup"><span data-stu-id="a5258-202">Direct manipulation with hands</span></span>](direct-manipulation.md)
* [<span data-ttu-id="a5258-203">Puntamento e commit con le mani</span><span class="sxs-lookup"><span data-stu-id="a5258-203">Point and commit with hands</span></span>](point-and-commit.md)
* [<span data-ttu-id="a5258-204">Movimenti</span><span class="sxs-lookup"><span data-stu-id="a5258-204">Gestures</span></span>](gestures.md)
* [<span data-ttu-id="a5258-205">Esecuzione di comandi vocali</span><span class="sxs-lookup"><span data-stu-id="a5258-205">Voice commanding</span></span>](voice-design.md)
* [<span data-ttu-id="a5258-206">Controller del movimento</span><span class="sxs-lookup"><span data-stu-id="a5258-206">Motion controllers</span></span>](motion-controllers.md)
* [<span data-ttu-id="a5258-207">Progettazione dell'audio spaziale</span><span class="sxs-lookup"><span data-stu-id="a5258-207">Spatial sound design</span></span>](spatial-sound-design.md)
* [<span data-ttu-id="a5258-208">Progettazione del mapping spaziale</span><span class="sxs-lookup"><span data-stu-id="a5258-208">Spatial mapping design</span></span>](spatial-mapping-design.md)
* [<span data-ttu-id="a5258-209">Comodità</span><span class="sxs-lookup"><span data-stu-id="a5258-209">Comfort</span></span>](comfort.md)

