---
title: Manipolazione diretta
description: Panoramica del modello di input di manipolazione diretta
author: caseymeekhof
ms.author: cmeekhof
ms.date: 04/02/2019
ms.topic: article
keywords: Mista realtà, sguardo, sguardo targeting, interazione, progettazione
ms.openlocfilehash: d855955d44c1cf074849992e5dd7b36b54675fdd
ms.sourcegitcommit: f5c1dedb3b9e29f27f627025b9e7613931a7ce18
ms.translationtype: MT
ms.contentlocale: it-IT
ms.lasthandoff: 04/27/2019
ms.locfileid: "64581331"
---
# <a name="direct-manipulation"></a><span data-ttu-id="58371-104">Manipolazione diretta</span><span class="sxs-lookup"><span data-stu-id="58371-104">Direct manipulation</span></span>
<span data-ttu-id="58371-105">Manipolazione diretta è un modello di input che coinvolge tocca vntana direttamente con le mani.</span><span class="sxs-lookup"><span data-stu-id="58371-105">Direct manipulation is an input model that involves touching holograms directly with your hands.</span></span> <span data-ttu-id="58371-106">L'obiettivo con manipolazione diretta è che gli oggetti si comportano come avviene nel mondo reale.</span><span class="sxs-lookup"><span data-stu-id="58371-106">The goal with direct manipulation is that objects behave just as they do in the real world.</span></span> <span data-ttu-id="58371-107">Pulsanti possono essere attivati semplicemente premendo li, gli oggetti possono essere selezionati da essi selezionandola e contenuto 2D si comporta come un touchscreen virtuale.</span><span class="sxs-lookup"><span data-stu-id="58371-107">Buttons can be activated simply by pressing them, objects can be picked up by grabbing them, and 2D content behaves like a virtual touchscreen.</span></span>  <span data-ttu-id="58371-108">Per questo motivo, è facile per gli utenti per altre manipolazione diretta, e il relativo divertimento troppo.</span><span class="sxs-lookup"><span data-stu-id="58371-108">Because of this, direct manipulation is easy for users to learn, and it's fun too.</span></span>  <span data-ttu-id="58371-109">Viene considerato un "near" modello di input, vale a dire che viene utilizzato meglio per l'interazione con contenuto che è all'interno di arms raggiungere.</span><span class="sxs-lookup"><span data-stu-id="58371-109">It is considered a "near" input model, meaning it is best used for interacting with content that is within arms reach.</span></span>

<span data-ttu-id="58371-110">Un elemento fondamentale che rende facile da imparare manipolazione diretta è che è basato su intuitività.</span><span class="sxs-lookup"><span data-stu-id="58371-110">A key ingredient that makes direct manipulation easy to learn is that it is affordance-based.</span></span> <span data-ttu-id="58371-111">Non esistono Nessun movimenti simbolici per insegnare agli utenti.</span><span class="sxs-lookup"><span data-stu-id="58371-111">There are no symbolic gestures to teach users.</span></span> <span data-ttu-id="58371-112">Tutte le interazioni devono essere create in un elemento visivo che può essere modificato o afferrato.</span><span class="sxs-lookup"><span data-stu-id="58371-112">All interactions should be built around a visual element that can be touched or grabbed.</span></span>

## <a name="device-support"></a><span data-ttu-id="58371-113">Supporto di dispositivi</span><span class="sxs-lookup"><span data-stu-id="58371-113">Device support</span></span>

<table>
    <colgroup>
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    </colgroup>
    <tr>
        <td><span data-ttu-id="58371-114"><strong>Modello di input</strong></span><span class="sxs-lookup"><span data-stu-id="58371-114"><strong>Input model</strong></span></span></td>
        <td><span data-ttu-id="58371-115"><a href="hololens-hardware-details.md"><strong>HoloLens (dal 1 ° generazione)</strong></a></span><span class="sxs-lookup"><span data-stu-id="58371-115"><a href="hololens-hardware-details.md"><strong>HoloLens (1st gen)</strong></a></span></span></td>
        <td><span data-ttu-id="58371-116"><strong>HoloLens 2</strong></span><span class="sxs-lookup"><span data-stu-id="58371-116"><strong>HoloLens 2</strong></span></span></td>
        <td><span data-ttu-id="58371-117"><a href="immersive-headset-hardware-details.md"><strong>Auricolari coinvolgenti</strong></a></span><span class="sxs-lookup"><span data-stu-id="58371-117"><a href="immersive-headset-hardware-details.md"><strong>Immersive headsets</strong></a></span></span></td>
    </tr>
     <tr>
        <td><span data-ttu-id="58371-118">Manipolazione diretta (accanto all'interazione manuale)</span><span class="sxs-lookup"><span data-stu-id="58371-118">Direct manipulation (Near hand interaction)</span></span></td>
        <td><span data-ttu-id="58371-119">❌ Non supportato</span><span class="sxs-lookup"><span data-stu-id="58371-119">❌ Not supported</span></span></td>
        <td><span data-ttu-id="58371-120">✔️ Consigliato</span><span class="sxs-lookup"><span data-stu-id="58371-120">✔️ Recommended</span></span></td>
        <td><span data-ttu-id="58371-121">Un'opzione alternativa ➕ ma <a href="point-and-commit.md">punto ed eseguire il commit (distante interazione)</a> è consigliato</span><span class="sxs-lookup"><span data-stu-id="58371-121">➕ An alternate option but <a href="point-and-commit.md">Point and commit (far interaction)</a> is recommended</span></span></td>
    </tr>
</table>

<span data-ttu-id="58371-122">Manipolazione diretta è un modello di input primario su HoloLens 2, che usano l'icona della mano articolati e nuovo sistema di registrazione.</span><span class="sxs-lookup"><span data-stu-id="58371-122">Direct manipulation is a primary input model on HoloLens 2, utilizing the new articulated hand tracking system.</span></span> <span data-ttu-id="58371-123">Il modello di input è disponibile anche su immersive auricolari tramite l'uso di controller di movimento, ma è consigliabile non significa che una replica primaria di interazione all'esterno di manipolazione dell'oggetto.</span><span class="sxs-lookup"><span data-stu-id="58371-123">The input model is also available on immersive headsets through the use of motion controllers, but is not recommended a primary means of interaction outside of object manipulation.</span></span>  <span data-ttu-id="58371-124">Manipluation diretto non è disponibile nella versione 1 di HoloLens.</span><span class="sxs-lookup"><span data-stu-id="58371-124">Direct manipluation is not available on HoloLens v1.</span></span>

## <a name="collidable-fingertip"></a><span data-ttu-id="58371-125">Collidable punta del dito</span><span class="sxs-lookup"><span data-stu-id="58371-125">Collidable fingertip</span></span>
<span data-ttu-id="58371-126">In 2 HoloLens, mani reale dell'utente vengono riconosciute e interpretate come i modelli di base di sinistra e a destra.</span><span class="sxs-lookup"><span data-stu-id="58371-126">On HoloLens 2, user's real hands are recognized and interpreted as left and right hand skeletal models.</span></span> <span data-ttu-id="58371-127">Per implementare l'idea di toccare vntana direttamente con le mani, in teoria, 5 colliders può essere collegato a 5 disposizione di ogni modello di base di mano.</span><span class="sxs-lookup"><span data-stu-id="58371-127">To implement the idea of touching holograms directly with hands, ideally, 5 colliders could be attached to 5 fingertips of each hand skeletal model.</span></span> <span data-ttu-id="58371-128">Tuttavia, in pratica, a causa della mancanza di feedback tattili, disposizione collidable 10 causano un numero elevato di collisioni impreviste e imprevedibili con vntana.</span><span class="sxs-lookup"><span data-stu-id="58371-128">However, practically, due to the lack of tactile feedback, 10 collidable fingertips cause lots of unexpected and unpredictable collisions with holograms.</span></span> <span data-ttu-id="58371-129">Di conseguenza, è consigliabile per inserire solo un collider su ogni dito indice.</span><span class="sxs-lookup"><span data-stu-id="58371-129">Hence, we suggest to only put a collider on each index finger.</span></span> <span data-ttu-id="58371-130">L'indice collidable disposizione comunque possono essere utilizzato come punti di tocco attivo per i movimenti di tocco diversi che includono altre dita, ad esempio la pressione di un 1 dito, 1 dito tocca, 2 dito premere e 5 con un dito.</span><span class="sxs-lookup"><span data-stu-id="58371-130">The collidable index fingertips can still serve as active touch points for diverse touch gestures involving other fingers, such as 1 finger press, 1 finger tap, 2 finger press and 5 finger press.</span></span>

![Immagine di collidable punta del dito](images/Collidable-Fingertip-720px.jpg)<br>

### <a name="sphere-collider"></a><span data-ttu-id="58371-132">Collider sfera</span><span class="sxs-lookup"><span data-stu-id="58371-132">Sphere collider</span></span>
<span data-ttu-id="58371-133">Invece di usare la forma generica casuale, è consigliabile usare un collider sfera e per eseguire il rendering in modo che fornisca segnali migliore per specificare come destinazione più vicino.</span><span class="sxs-lookup"><span data-stu-id="58371-133">Instead of using random generic shape, we suggest to use a sphere collider and to visually render it to provide better cues for near targeting.</span></span> <span data-ttu-id="58371-134">Diametro della sfera deve corrispondere allo spessore del dito indice per aumentare l'accuratezza di tocco.</span><span class="sxs-lookup"><span data-stu-id="58371-134">The sphere's diameter should match the thickness of the index finger to increase touch accuracy.</span></span> <span data-ttu-id="58371-135">Sarà facile recuperare la variabile dello spessore di un dito chiamando le API disponibili.</span><span class="sxs-lookup"><span data-stu-id="58371-135">It will be easy to retrieve the variable of finger thickness by calling the hand API.</span></span>

<br>

### <a name="fingertip-cursor"></a><span data-ttu-id="58371-136">Cursore punta del dito</span><span class="sxs-lookup"><span data-stu-id="58371-136">Fingertip cursor</span></span>
<span data-ttu-id="58371-137">Oltre a eseguire il rendering di una sfera collidable sulla punta del dito indice, creiamo un soluzioni avanzamento, cursore punta del dito, per ottenere migliori quasi esperienza destinata a in modo interattivo.</span><span class="sxs-lookup"><span data-stu-id="58371-137">In addition to rendering a collidable sphere on the index fingertip, we create an advance solution, fingertip cursor, to achieve better near targeting experience interactively.</span></span> <span data-ttu-id="58371-138">Si tratta di un cursore di forma di grafico ad anello collegato nella punta del dito indice.</span><span class="sxs-lookup"><span data-stu-id="58371-138">It is a donut shape cursor attached on the index fingertip.</span></span> <span data-ttu-id="58371-139">In base alla prossimità, in modo dinamico reagisce a una destinazione in termini di orientamento e la dimensione come indicato di seguito:</span><span class="sxs-lookup"><span data-stu-id="58371-139">According to proximity, it dynamically reacts to a target in term of orientation and size as below:</span></span>
* <span data-ttu-id="58371-140">Quando si sposta un dito indice verso ologramma, il cursore è sempre parallelo nell'area della finestra di ologrammi e gradualmente ridotta di conseguenza le dimensioni.</span><span class="sxs-lookup"><span data-stu-id="58371-140">When an index finger moves toward a hologram, the cursor is always parallel to the surface of the hologram and gradually shrinks its size accordingly.</span></span> 
* <span data-ttu-id="58371-141">Non appena il dito tocca l'area, il cursore si riduce in un punto e genera un evento di tocco.</span><span class="sxs-lookup"><span data-stu-id="58371-141">As soon as the finger touch the surface, the cursor shrinks into a dot and emits a touch event.</span></span>

<br> <span data-ttu-id="58371-142">Con il feedback interattivo, raggiungere ad alta precisione quasi come attività, ad esempio l'attivazione di un collegamento ipertestuale in un contenuto web o premendo un pulsante di destinazione.</span><span class="sxs-lookup"><span data-stu-id="58371-142">With the interactive feedback, users can achieve high precision near targeting tasks, such as triggering a hyperlink on a web content or pressing a button.</span></span> <br>

![Immagine del cursore punta del dito](images/Fingertip-Cursor-720px.jpg)<br>

## <a name="bounding-box-with-proximity-shader"></a><span data-ttu-id="58371-144">Rettangolo di selezione con shader prossimità</span><span class="sxs-lookup"><span data-stu-id="58371-144">Bounding box with proximity shader</span></span>
<span data-ttu-id="58371-145">Ologramma stesso richiede anche per fornire commenti e suggerimenti audio e video per compensare la mancanza di feedback tattili.</span><span class="sxs-lookup"><span data-stu-id="58371-145">The hologram itself also requires to provide both visual and audio feedbacks to compensate the lack of tactile feedback.</span></span> <span data-ttu-id="58371-146">A tal fine, viene generata il concetto del rettangolo con shader prossimità.</span><span class="sxs-lookup"><span data-stu-id="58371-146">For that, we generate the concept of bounding box with proximity shader.</span></span> <span data-ttu-id="58371-147">Un rettangolo di selezione è un'area volumetrici minime che racchiude un oggetto 3D.</span><span class="sxs-lookup"><span data-stu-id="58371-147">A bounding box is a minimun volumetric area that encloses a 3D object.</span></span> <span data-ttu-id="58371-148">Il rettangolo di selezione è un meccanismo di rendering interattiva denominato shader prossimità.</span><span class="sxs-lookup"><span data-stu-id="58371-148">The bounding box has an interactive rendering mechanism called proximity shader.</span></span> <span data-ttu-id="58371-149">Lo shader prossimità si comporta come indicato di seguito:</span><span class="sxs-lookup"><span data-stu-id="58371-149">The proximity shader behaves as below:</span></span>

* <span data-ttu-id="58371-150">Una volta il dito indice all'interno di un intervallo, viene eseguito il cast di un riflettore punta del dito sulla superficie del rettangolo di selezione.</span><span class="sxs-lookup"><span data-stu-id="58371-150">When the index finger is within a range, a fingertip spotlight is cast on the surface of bounding box.</span></span> 
* <span data-ttu-id="58371-151">Quando la punta del dito ottiene più vicino all'area, il riflettore condensa conseguenza.</span><span class="sxs-lookup"><span data-stu-id="58371-151">When the fingertip gets closer to the surface, the spotlight condenses accordingly.</span></span> 
* <span data-ttu-id="58371-152">Non appena la punta del dito tocca l'area, l'intero rettangolo di selezione cambia il colore o generare effetto visivo per riflettere lo stato di tocco.</span><span class="sxs-lookup"><span data-stu-id="58371-152">As soon as the fingertip touch the surface, the whole bounding box changes the color or generate visual effect to reflect the touch state.</span></span> 
* <span data-ttu-id="58371-153">Nel frattempo, è possibile attivare un effetto per migliorare il feedback dell'input tocco visual.</span><span class="sxs-lookup"><span data-stu-id="58371-153">Meanwhile, a sound effect can be activated to enhance the visual touch feedback.</span></span>

![Rettangolo di selezione con immagine di shader di prossimità](images/Bounding-Box-With-Proximity-Shader-720px.jpg)<br>

## <a name="pressable-button"></a><span data-ttu-id="58371-155">Pulsante pressable</span><span class="sxs-lookup"><span data-stu-id="58371-155">Pressable button</span></span>
<span data-ttu-id="58371-156">Con punta del dito collidable, gli utenti sono ora pronti per interagire con il componente fondamentale holographic dell'interfaccia utente, pulsante pressable.</span><span class="sxs-lookup"><span data-stu-id="58371-156">With a collidable fingertip, users are now ready to interact with the very fundamental holographic UI component, pressable button.</span></span> <span data-ttu-id="58371-157">Un pulsante pressable è un pulsante holographic su misura della pressione diretto con un dito.</span><span class="sxs-lookup"><span data-stu-id="58371-157">A pressable button is a holographic button tailored for direct finger press.</span></span> <span data-ttu-id="58371-158">Anche in questo caso, a causa della mancanza di feedback tattili, un pulsante pressable fornisce due meccanismi per affrontare feedback tattili problemi correlati.</span><span class="sxs-lookup"><span data-stu-id="58371-158">Again, due to the lack of tactile feedback, a pressable button equips a couple mechanisms to tackle tactile feedback related issues.</span></span> 
* <span data-ttu-id="58371-159">Il primo meccanismo è rettangolo con shader di prossimità, che sia già stato indirizzato nel paragrafo precedente.</span><span class="sxs-lookup"><span data-stu-id="58371-159">The first mechanism is bounding box with proximity shader, which has already been addressed in the foregoing paragraph.</span></span> <span data-ttu-id="58371-160">Serve a offrire idea più accurata della prossimità agli utenti di affrontare e rendere in contatto con un pulsante.</span><span class="sxs-lookup"><span data-stu-id="58371-160">It serves to provide better sense of proximity for users to approach and make contact with a button.</span></span> 
* <span data-ttu-id="58371-161">Il secondo è calo.</span><span class="sxs-lookup"><span data-stu-id="58371-161">The second one is depression.</span></span> <span data-ttu-id="58371-162">Crea assimilata press, dopo la punta del dito contatta il pulsante.</span><span class="sxs-lookup"><span data-stu-id="58371-162">It creates sense of press, after a fingertip contacts the button.</span></span> <span data-ttu-id="58371-163">Il meccanismo è che il pulsante Sposta strettamente con la punta del dito lungo l'asse di profondità.</span><span class="sxs-lookup"><span data-stu-id="58371-163">The mechanism is that the button tightly moves with the fingertip along the depth axis.</span></span> <span data-ttu-id="58371-164">Il pulsante può essere attivato non appena raggiunge una profondità designata (al clic del mouse) o lasciando la profondità (nel rilascio) dopo transita attraverso di esso.</span><span class="sxs-lookup"><span data-stu-id="58371-164">The button can be triggered as soon as reaching a designated depth (on press) or leaving the depth (on release) after passing through it.</span></span> 
* <span data-ttu-id="58371-165">L'effetto audio deve essere aggiunti per migliorare i commenti e suggerimenti, quando viene attivato il pulsante.</span><span class="sxs-lookup"><span data-stu-id="58371-165">The sound effect should be added to enhance feedback, when the button is triggered.</span></span> 

![Immagine del pulsante pressable](images/Pressable-Button-720px.jpg)<br>

## <a name="2d-slate-interaction"></a><span data-ttu-id="58371-167">Interazione dello slate 2D</span><span class="sxs-lookup"><span data-stu-id="58371-167">2D slate interaction</span></span>
<span data-ttu-id="58371-168">Uno slate 2D è un contenitore holographic hosting di contenuto dell'app 2D, ad esempio web browser.</span><span class="sxs-lookup"><span data-stu-id="58371-168">A 2D slate is a holographic container hosting 2D app contents, such as web browser.</span></span> <span data-ttu-id="58371-169">Il concetto di progettazione per l'interazione con uno slate 2D tramite manipolazione diretta consiste nello sfruttare il modello mentale di interagire con un touchscreen fisico.</span><span class="sxs-lookup"><span data-stu-id="58371-169">The design concept for interacting with a 2D slate via direct manipulation is to leverage the mental model of interacting with a physical touch screen.</span></span><br> <br>
<span data-ttu-id="58371-170">Per l'interazione con il contatto dello slate:</span><span class="sxs-lookup"><span data-stu-id="58371-170">For interacting with the slate contact:</span></span><br> 
* <span data-ttu-id="58371-171">Gli utenti usano un dito indice di premere un pulsante o un collegamento ipertestuale.</span><span class="sxs-lookup"><span data-stu-id="58371-171">Users use an index finger to press a hyperlink or a button.</span></span> 
* <span data-ttu-id="58371-172">Gli utenti utilizzano un dito indice su e giù per scorrere un contenuto dello slate.</span><span class="sxs-lookup"><span data-stu-id="58371-172">Users use an index finger to scroll a slate content up and down.</span></span> 
* <span data-ttu-id="58371-173">Gli utenti di usare due dita di indice per fare zoom avanti e indietro il contenuto dello slate in base al relativo movimento della dita.</span><span class="sxs-lookup"><span data-stu-id="58371-173">Users use two index fingers to zoom in and out the slate content according to relative motion of fingers.</span></span> 
<span data-ttu-id="58371-174">![Immagine dello slate 2D](images/2D-Slate-Interaction-720px.jpg)</span><span class="sxs-lookup"><span data-stu-id="58371-174">![2D slate image](images/2D-Slate-Interaction-720px.jpg)</span></span><br>

<br><span data-ttu-id="58371-175">Per la manipolazione 2D ardesia stesso:</span><span class="sxs-lookup"><span data-stu-id="58371-175">For manipulating the 2D slate itself:</span></span><br>
* <span data-ttu-id="58371-176">Gli utenti si avvicina le mani verso angoli e archi per rivelare i più vicino affordance di manipolazione.</span><span class="sxs-lookup"><span data-stu-id="58371-176">Users can approach their hands toward corners and edges to reveal the closest manipulation affordances.</span></span> 
* <span data-ttu-id="58371-177">Utilizzando i affordance manipolazione, gli utenti possono eseguire la scalabilità uniforme tramite affordnaces l'angolo e ridisporre tramite i affordance edge.</span><span class="sxs-lookup"><span data-stu-id="58371-177">By grabbing the manipulation affordances, users can perform uniform scaling through the corner affordnaces and reflow via the edge affordances.</span></span> 
* <span data-ttu-id="58371-178">Cattura la holobar nella parte superiore dello slate 2D possono utenti spostare lo slate intero.</span><span class="sxs-lookup"><span data-stu-id="58371-178">Grabbing the holobar at the top of the 2D slate can users move the whole slate.</span></span><br><br>

![Immagine di manipolazione dello slate](images/Manipulate-2d-slate-720px.jpg)


## <a name="3d-object-manipulation"></a><span data-ttu-id="58371-180">Modifica di oggetti 3D</span><span class="sxs-lookup"><span data-stu-id="58371-180">3D object manipulation</span></span>
<span data-ttu-id="58371-181">In 2 HoloLens, gli utenti vengono abilitati per utilizzare le mani direct modificare oggetti 3D hologramphic applicando un rettangolo a ogni oggetto 3D.</span><span class="sxs-lookup"><span data-stu-id="58371-181">In HoloLens 2, users are enabled to use their hands to direct manipulate 3D hologramphic objects by applying a bounding box to each 3D object.</span></span> <span data-ttu-id="58371-182">Il riquadro delimitatore fornisce migliori percezione di profondità tramite relativo shader prossimità.</span><span class="sxs-lookup"><span data-stu-id="58371-182">The bounding box provides better depth perception through its proximity shader.</span></span> <span data-ttu-id="58371-183">Con il rettangolo di selezione, esistono due approcci di progettazione per la manipolazione dell'oggetto 3D:</span><span class="sxs-lookup"><span data-stu-id="58371-183">With the bounding box, there are two design approaches for 3D object manipulation:</span></span>      
### <a name="affordance-based-manipulation"></a><span data-ttu-id="58371-184">Intuitività basato su Modifica:</span><span class="sxs-lookup"><span data-stu-id="58371-184">Affordance based manipulation:</span></span>
<span data-ttu-id="58371-185">È un modo per gli utenti modificare l'oggetto 3D tramite la affordance manipolazione intorno a esso e finestra di delimitazione.</span><span class="sxs-lookup"><span data-stu-id="58371-185">It is a way for users to manipulate the 3D object through bounding box and the manipulation affordances around it.</span></span> <span data-ttu-id="58371-186">Come parte dell'utente è vicino a un oggetto 3D, il rettangolo di selezione e il più vicino intuitività sono rivelati.</span><span class="sxs-lookup"><span data-stu-id="58371-186">As soon as a user's hand is close to a 3D object, the bounding box and the nearest affordance are revealed.</span></span> <span data-ttu-id="58371-187">Gli utenti possono recuperare il rettangolo di selezione per spostare l'intero oggetto, i affordance edge la rotazione e di coner affordance ridimensionare in modo uniforme.</span><span class="sxs-lookup"><span data-stu-id="58371-187">Users can grab the bounding box to move the whole object, the edge affordances to rotate and the coner affordances to scale uniformly.</span></span><br>

![Immagine di manipolazione di oggetti 3D](images/3D-Object-Manipulation-720px.jpg)<br>

### <a name="non-affordance-based-manipulation"></a><span data-ttu-id="58371-189">Non-intuitività basato su Modifica:</span><span class="sxs-lookup"><span data-stu-id="58371-189">Non-affordance based manipulation:</span></span>
<span data-ttu-id="58371-190">In questo mechanisom, nessun intuitività è associato il riquadro delimitatore.</span><span class="sxs-lookup"><span data-stu-id="58371-190">In this mechanisom, no affordance is attached to the bounding box.</span></span> <span data-ttu-id="58371-191">Gli utenti possono solo visualizzare il riquadro delimitatore, quindi interagire direttamente con esso.</span><span class="sxs-lookup"><span data-stu-id="58371-191">Users can only reveal the bounding box, then directly interact with it.</span></span> <span data-ttu-id="58371-192">Se il rettangolo di selezione dell'acquisizione con una mano, sono associati allo spostamento e l'orientamento della mano la traslazione e rotazione dell'oggetto.</span><span class="sxs-lookup"><span data-stu-id="58371-192">If the bounding box is grabbed with one hand, the translation and rotation of the object are associated to motion and orientation of the hand.</span></span> <span data-ttu-id="58371-193">Quando l'oggetto è stato afferrato con due mani, gli utenti possono tradurre, ridimensionare e ruotarla in base al relativi movimenti di due mani.</span><span class="sxs-lookup"><span data-stu-id="58371-193">When the object is grabbed with two hands, users can translate, scale and rotate it according to relative motions of two hands.</span></span><br><br> 

<br><br>
<span data-ttu-id="58371-194">Per la modifica richiede la precisione, è consigliabile manipolazione afforance basata, che fornisce elevata a livello di granularità.</span><span class="sxs-lookup"><span data-stu-id="58371-194">For manipulation requires precision, we recommend afforance based manipulation, providing high level of granularity.</span></span> <span data-ttu-id="58371-195">Per una modifica flessibile, non intuitività manipolazione sarà un'ottima scelta, offrendo esperienze immediate e circondandole agli utenti.</span><span class="sxs-lookup"><span data-stu-id="58371-195">For flexible manipulation, non-affordance manipulation will be a good choice, offering users instant and playful experiences.</span></span>


## <a name="instinctual-gestures"></a><span data-ttu-id="58371-196">Movimenti instinctual</span><span class="sxs-lookup"><span data-stu-id="58371-196">Instinctual gestures</span></span>
<span data-ttu-id="58371-197">A differenza di HoloLens (dal 1 ° generazione), gli utenti per l'insegnamento predefinito di un paio movimenti, ad esempio Bloom e tocca Air, HoloLens 2, non chiediamo agli utenti di memorizzare qualsiasi movimento simbolico.</span><span class="sxs-lookup"><span data-stu-id="58371-197">Unlike HoloLens (1st gen), teaching users a couple predefined gestures, such as Bloom and Air Tap, in HoloLens 2, we don't ask users to memorize any symbolic gesture.</span></span> <span data-ttu-id="58371-198">Tutti i movimenti che gli utenti necessari per l'interazione con ologrammi e il contenuto sono instinctual.</span><span class="sxs-lookup"><span data-stu-id="58371-198">All gestures that users need for interacting with holograms and contents are instinctual.</span></span> <span data-ttu-id="58371-199">Il modo per ottenere instinctual movimento è per guidare gli utenti per eseguire i movimenti tramite la progettazione di affordance dell'interfaccia utente.</span><span class="sxs-lookup"><span data-stu-id="58371-199">The way to achieve instinctual gesture is to guide users to perform gestures through the design of UI affordances.</span></span> <span data-ttu-id="58371-200">Ad esempio, se si consiglia agli utenti di quadratini di ridimensionamento un oggetto o un punto di controllo con zoom indietro di due dita, l'oggetto o il punto di controllo deve essere piccolo.</span><span class="sxs-lookup"><span data-stu-id="58371-200">For example, if we encourage users to grab an object or a control point with two finger pinch, the object or the control point should be small.</span></span> <span data-ttu-id="58371-201">Se si desidera agli utenti di eseguire cinque quadratini di ridimensionamento di un dito, l'oggetto o il punto di controllo deve essere relativamente grande.</span><span class="sxs-lookup"><span data-stu-id="58371-201">If we would like users to perform five finger grab, the object or the control point should be relatively big.</span></span> <span data-ttu-id="58371-202">Analogamente ai pulsanti, un piccolo pulsante limiterebbe agli utenti di premere con un singolo dito, mentre un enorme pulsante verrebbe incoraggiare gli utenti a premerlo con le mani.</span><span class="sxs-lookup"><span data-stu-id="58371-202">Similar to buttons, a tiny button would limit users to press it with a single finger, while a huge button would encourage users to press it with their palms.</span></span>
![](images/Instinctual-Gestures-720px.jpg)<br>

## <a name="symmetric-design-between-hands-and-6-dof-controllers"></a><span data-ttu-id="58371-203">Progettazione simmetrica tra le mani e controller i gradi di libertà 6</span><span class="sxs-lookup"><span data-stu-id="58371-203">Symmetric design between hands and 6 DoF controllers</span></span>
<span data-ttu-id="58371-204">Si è notato che ora sono presenti parallels interazione che è possibile trarre tra le mani nel controller AR e movimento in realtà virtuale.</span><span class="sxs-lookup"><span data-stu-id="58371-204">You may have noticed that there are now interaction parallels we can draw between hands in AR and motion controllers in VR.</span></span> <span data-ttu-id="58371-205">Entrambi gli input possono essere utilizzati per avviare manipolazioni dirette nei loro rispettivi ambienti.</span><span class="sxs-lookup"><span data-stu-id="58371-205">Both inputs can be used to trigger direct manipulations in their respective environments.</span></span> <span data-ttu-id="58371-206">In 2 HoloLens, selezionandola e trascinando con le mani una distanza Chiudi Works gran parte nello stesso modo come pulsante di quadratini di ridimensionamento non sui controller di movimento in WMR.</span><span class="sxs-lookup"><span data-stu-id="58371-206">In HoloLens 2, grabbing and dragging with hands at a close distance works much in the same way as the grab button does on the motion controllers in WMR.</span></span> <span data-ttu-id="58371-207">Ciò fornisce agli utenti la conoscenza di interazione tra le due piattaforme e possa rivelarsi utile se si dovesse decide di convertire la tua app da uno a altro.</span><span class="sxs-lookup"><span data-stu-id="58371-207">This provides your users with interaction familiarity between the two platforms and may prove useful should you ever decide to port your app from one to the other.</span></span>

## <a name="optimizing-with-eye-tracking"></a><span data-ttu-id="58371-208">L'ottimizzazione con sotto controllo di rilevamento</span><span class="sxs-lookup"><span data-stu-id="58371-208">Optimizing with eye tracking</span></span>
<span data-ttu-id="58371-209">Manipolazione diretta può risultare magici se funziona come previsto, ma può anche risultare frustrante se non è non possibile spostare più la mano ovunque senza attivare involontariamente ologramma.</span><span class="sxs-lookup"><span data-stu-id="58371-209">Direct manipulation can feel magical if it works as intended, but can also quickly become frustrating if you can’t move your hand anywhere anymore without unintentionally triggering a hologram.</span></span>
<span data-ttu-id="58371-210">Sotto controllo di rilevamento può potenzialmente offrire una migliore identificazione che cos'è l'intenzione dell'utente.</span><span class="sxs-lookup"><span data-stu-id="58371-210">Eye tracking can potentially help in better identifying what the user’s intent is.</span></span> 

* <span data-ttu-id="58371-211">**Quando**: Ridurre negando quindi attivare una risposta di manipolazione.</span><span class="sxs-lookup"><span data-stu-id="58371-211">**When**: Reduce falsely triggering a manipulation response.</span></span> <span data-ttu-id="58371-212">Occhio rilevamento consente di comprendere meglio ciò che un utente attualmente occupato con.</span><span class="sxs-lookup"><span data-stu-id="58371-212">Eye tracking allows for better understanding what a user is currently engaged with.</span></span> <span data-ttu-id="58371-213">Si supponga, ad esempio, che si legge un testo (filmato) holographic quando raggiungono oltre per ricavare è lo strumento di lavoro reali.</span><span class="sxs-lookup"><span data-stu-id="58371-213">For example, imagine you are reading through a holographic (instructional) text when reaching over to grab you real-world work tool.</span></span>
<span data-ttu-id="58371-214">In questo modo, la mano accidentalmente spostare tra alcuni pulsanti holographic interattivi che non l'aveste notato anche prima di grande successo (forse che era ancora di fuori della visualizzazione dell'utente di campi).</span><span class="sxs-lookup"><span data-stu-id="58371-214">By doing so, you accidently move your hand across some interactive holographic buttons that you hadn't even noticed before (maybe it even was outside of the user's Field-of-View).</span></span>
<span data-ttu-id="58371-215">In breve: Se l'utente non è stato esaminato ologramma per un periodo di tempo, ma è stato rilevato un evento touch o. é quindi per tale, è probabile che l'utente non è stato effettivamente prendendo in considerazione interagire con tale ologramma.</span><span class="sxs-lookup"><span data-stu-id="58371-215">Long story short: If the user hasn't looked at a hologram for a while, yet a touch or grasp event has been detected for it, it is likely that the user wasn't actually intending to interact with that hologram.</span></span> 

* <span data-ttu-id="58371-216">**Quello che**: Oltre all'indirizzamento false attivazioni positive, un altro esempio include una migliore identificazione quali vntana per ottenere o guardarsi come il punto di intersezione preciso potrebbe non essere chiaro da una prospettiva locale soprattutto se viene posizionati vntana più vicine Altro.</span><span class="sxs-lookup"><span data-stu-id="58371-216">**Which one**: Aside from addressing false positive activations, another example includes better identifying which holograms to grab or poke as the precise intersection point may not be clear from your perspective especially if several holograms are positioned close to each other.</span></span> <span data-ttu-id="58371-217">Mentre rilevamento occhio su HoloLens 2 ha una limitazione di determinate in modo accurato sulla può determinare dell'occhio sguardo, questa può comunque essere molto utile per quasi interazioni a causa dell'eterogeneità profondità durante l'interazione con mano di input.</span><span class="sxs-lookup"><span data-stu-id="58371-217">While eye tracking on HoloLens 2 has a certain limitation on how accurately it can determine you eye gaze, this can still be very helpful for near interactions due to depth disparity when interacting with hand input.</span></span> <span data-ttu-id="58371-218">Ciò significa che talvolta è difficile determinare se la mano dietro o davanti ologramma precisamente ottenere, ad esempio un widget di manipolazione.</span><span class="sxs-lookup"><span data-stu-id="58371-218">This means that it is sometimes difficult to determine whether your hand is behind or in front of a hologram to precisely grab a manipulation widget for example.</span></span>

 * <span data-ttu-id="58371-219">**La posizione in cui**: Usa informazioni relative a ciò che un utente sta guardando i movimenti generando un'eccezione rapidi.</span><span class="sxs-lookup"><span data-stu-id="58371-219">**Where to**: Use information about what a user is looking at with quick throwing gestures.</span></span> <span data-ttu-id="58371-220">Afferrare ologramma e metterla approssimativamente verso la destinazione prevista.</span><span class="sxs-lookup"><span data-stu-id="58371-220">Grab a hologram and roughly toss it toward your intended destination.</span></span> <span data-ttu-id="58371-221">Sebbene questo approccio potrebbe talvolta funzionare correttamente, eseguire rapidamente i movimenti della mano può comportare destinazioni estremamente imprecise.</span><span class="sxs-lookup"><span data-stu-id="58371-221">While this may sometimes work just fine, quickly performing hand gestures may result in highly inaccurate destinations.</span></span>
<span data-ttu-id="58371-222">Si tratta in cui sotto controllo di rilevamento può essere utile per informazioni sull'icona della mano generazione vettore nuovamente nella posizione desiderata.</span><span class="sxs-lookup"><span data-stu-id="58371-222">This is where eye tracking could help out to lean the hand throwing vector back to your intended position.</span></span>

## <a name="see-also"></a><span data-ttu-id="58371-223">Vedere anche</span><span class="sxs-lookup"><span data-stu-id="58371-223">See also</span></span>
* [<span data-ttu-id="58371-224">Sguardo ed eseguire il commit</span><span class="sxs-lookup"><span data-stu-id="58371-224">Gaze and commit</span></span>](gaze-and-commit.md)
* [<span data-ttu-id="58371-225">Punto e commit</span><span class="sxs-lookup"><span data-stu-id="58371-225">Point and commit</span></span>](point-and-commit.md)
* [<span data-ttu-id="58371-226">Concetti fondamentali delle interazioni</span><span class="sxs-lookup"><span data-stu-id="58371-226">Interaction fundamentals</span></span>](interaction-fundamentals.md)

